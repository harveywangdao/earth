1.Golang
slice切片:
只能判断slice==nil,不能slice1==slice2
扩容规则: 容量小于1024时每次扩容2倍,大于1024时每次扩大1.25倍,且遵循内存对齐规则;切片扩容机制与切片的数据类型、原本切片的容量、所需要的容量都有关系
s[:] s[i:] s[:j] s[i:j]
s[i:j:k]k代表容量,k>=j,如果没有k则默认原切片的cap长度,新切片的len=j-i,cap=k-i
从一个长的切片里截取部分数据,未使用的空间不会gc
nil切片也会分配结构体,ptr是0;空切片ptr指向固定地址

数组:
数组以arr[:]方式转成切片,切片的底层直接指向了这个数组
数组可以使用len和cap
不能append
arr2:=arr1是值复制,拷贝所有数据
可以range,会完全复制整个数组,编译器优化实际只有一份内存,有待研究?
可以直接==判断

string:
有len无cap
不可修改
对字符串进行切片操作(str[:])生成的还是字符串,不能修改值
[]byte转成string一定会拷贝内存吗,使用m[string(b)]来查找;字符串拼接;string(b) == "foo"
不能等于nil
str[0]是byte/uint8;range str返回的是rune/int32

copy:
第一个参数只能是slice,第二个参数可以是slice和string

struct:
空结构体都指向zerobase;当空结构体放到另一个结构体中的最后一个字段时会进行特殊填充
结构体可以直接==判断
继承
结构体方法调用时会先拷贝一份,所以无法改变原本结构体内部的成员值

map:
hmap
扩容: map中数据总个数/桶个数>6.5时,引发翻倍扩容 || 使用了太多的溢出桶时

sync.Map:
通过互斥锁和原子操作来实现近似无锁,空间换时间,延迟删除,删除一个键值只是打标记,只有在迁移dirty数据的时候才清理删除的数据,readOnly向dirty拷贝是遍历,不适合大数据场景
不加锁: 读/删一个存在readOnly中的key,写一个存在readOnly中的key并且没有标记删除
加锁: 增加新key会加锁,新key先放dirty,不适合频繁增加数据

chan管道:
len+cap;读写nil管道都会阻塞;close nil管道会panic;close两次管道会panic

select:
selectgo
select中没有case时会阻塞;select中所有case都阻塞就走default,没有default就阻塞;只能用于管道;case是随机执行的;两个case可以接收同一个管道

协程:
调度 GMP

内存管理:
mheap mspan mcentral mcache mstats TCMalloc
小于32KB,从P上的mcache分配mspan,不需要加锁,为每种类别的mspan维护着一个mcentral
mcentral的作用是为所有mcache提供切分好的mspan资源,每个central会持有一种特定大小的全局mspan列表,mcentral被所有的工作线程共同享有,需要加锁
当mcentral没有空闲的mspan时,会向mheap申请
而mheap没有资源时,会向操作系统申请新内存,mheap主要用于大对象的内存分配,以及管理未切割的mspan
大于32KB,会直接从堆上(mheap)上分配对应的数量的内存页(每页大小是8KB)给程序

协程栈:
每个goroutine都维护着自己的栈区,栈结构是连续栈,是一块连续的内存,栈区的初始大小是2KB,按照需要增长和收缩,最大1GB
分段栈,栈空间会以双向链表的形式串联起来,如果协程的栈几乎充满,那么任意的函数调用都会触发栈的扩容,当函数返回后又会触发栈的收缩,如果在一个循环中调用函数,栈分配释放造成巨大开销,热分裂问题
连续栈,栈空间不足时,初始化一片比旧栈大两倍的新栈并将原栈中的所有值都迁移到新的栈中,将指向旧栈对应变量的指针重新指向新栈
分配类似堆内存的分配

内存回收gc:
三色标记
开始所有对象都是白色的
遍历根节点(全局变量和栈内变量)集合里的所有根对象,把根对象引用的对象标记为灰色,从白色集合放入灰色集合
遍历灰色集合,将灰色对象引用的对象从白色集合放入灰色集合,之后将此灰色对象放入黑色集合
重复第三步,直到灰色集合中无任何对象
回收白色集合里的所有对象,本次垃圾回收结束
写屏障,在对象新增的同时给它着色为灰色,而所有新创建的对象都会被直接标记成黑色
开启写屏障前和移除写屏障前暂停应用程序
标记准备阶段,暂停程序
标记阶段,根对象入队,开启写屏障,恢复执行程序,开始扫描根对象,扫描协程栈期间会暂停当前处理器,
标记终止阶段,暂停程序
清理阶段,初始化清理状态并关闭写屏障,恢复用户程序,后台并发清理所有的内存管理单元,当goroutine申请新的内存管理单元时就会触发清理
触发时机,内存使用超过某值,超过两分钟,手动GC

内存逃逸:
go build -gcflags "-m -m" main.go 编译阶段确定;大内存优先分配在堆上/分配的大小不确定;变量在函数返回后还可能被使用,闭包,返回指针;造成gc压力变大
go tool compile -m main.go

接口interface:
eface表示空的interface{},iface表示至少带有一个函数的interface

性能优化:
pprof:
net/http/pprof runtime/pprof
go tool pprof http://localhost:6060/debug/pprof/heap
go tool pprof http://localhost:6060/debug/pprof/profile
go tool pprof http://localhost:6060/debug/pprof/goroutine
go tool pprof demo demo.prof
go tool pprof -http 0.0.0.0:8080 http://localhost:6060/debug/pprof/profile
能查到哪个函数分配的内存高
能查到哪个函数占用cpu高
火焰图
调用链,每个函数的耗时和占比

dlv:
设置断点break main.go:35
继续执行continue
查看函数参数、打印变量、单步执行、查看所有协程

Benchmark:
go test -bench .
go test -bench=. -cpuprofile=cpu.prof
go test -bench=. -memprofile=mem.prof
go tool pprof -http 0.0.0.0:8080 cpu.prof

trace:
curl -o app.trace http://localhost:6060/debug/pprof/trace
go tool trace -http 0.0.0.0:8080 performance app.trace
可以查看每个协程在哪耗时大

generate:
//go:generate stringer -type=Life

test:
go test -coverprofile=test.out
go tool cover -html=test.out -o cover.html

内存对齐:
计算机只能从4、8的倍数开始读数据,不能随便从一个地址读数据

汇编plan9:
go tool compile -N -l -S main.go //打印汇编 生成.o
go run -gcflags "-N -l" main.go
go build -gcflags "-N -l" main.go
go build -gcflags=all="-N -l" main.go
go tool objdump -s do1 main.o
go env -w GO111MODULE=on
go tool fix main.go //golang.org/x/net/context --> context
go fmt main.go
go vet main.go //检查基本错误如语法错误 fmt.Printf("%s", 12)
go tool asm main.s //.s --> .o
go tool link main.o //链接
readelf -w a.out
addr2line -e a.out
go tool nm main.o
go tool pack c file.a main.go

nil:
nil不是关键字;nil可作为变量名;nil是没有默认类型的在使用它时必须要提供足够的信息能够让编译器推断nil期望的类型
iota:
只能和const一起使用;每当const出现时都会使iota初始化为0;const中每新增一行常量声明将使iota计数一次;默认int型

反射reflect
定时器
defer
panic&recover
atomic/条件变量/mutex/rwmutex/WaitGroup/Once/sync.Pool
netpoll
gin/beego/grpc/Restful/fasthttp
unsafe&uintptr
//go:noinline //go:nosplit //go:noescape //go:linkname //go:notinheap //go:norace
cgo


2.MySQL
聚族索引和非聚族索引
覆盖索引
前缀索引
主键索引 普通索引 唯一索引 联合索引 全文索引
InnoDB和MyISAM
索引B树和B+树
B树的所有节点既存放键(key)也存放数据(data),而B+树只有叶子节点存放key和data,其他内节点只存放key
B+树的叶子节点有一条引用链指向与它相邻的叶子节点

执行流程
mvcc 快照读 当前读 ReadView
隔离级别 读取未提交 读取已提交 可重复读 可串行化

InnoDB 通过数据行的 DB_TRX_ID 和 Read View 来判断数据的可见性
DB_TRX_ID(6字节): 表示最后一次插入或更新该行的事务 id
DB_ROLL_PTR(7字节): 回滚指针，指向该行的 undo log
DB_ROW_ID(6字节): 如果没有设置主键且该表没有唯一非空索引时，InnoDB会使用该id来生成聚簇索引

redo log
undo log
binlog

Record lock 记录锁 单条索引记录上加锁
Gap lock 间隙锁 锁住一个索引区间(开区间,不包括双端端点) 防止幻读,保证索引间的不会被插入数据
Next-key lock 临键锁 = Gap Lock + Record Lock 为了解决幻读 左开右闭区间
自增锁
意向锁 意向共享锁IS 意向排它锁IX 表级别锁
插入意向锁: 间隙锁的一种,专门针对insert操作,多个事务在同一个索引同一个范围区间插入记录时候,如果插入位置不冲突,不会彼此阻塞
select ... lock in share mode  S锁 共享锁
select ... for update X锁 排他锁

ACID 原子性 一致性 隔离性 持久性

脏读
幻读
不可重复读

回表

连接器 查询缓存、分析器、优化器、执行器

Buffer Pool
redo log buffer

分库分表
主从复制
读写分离

数据库三范式: 每列保持原子性 每列都和主键相关 每一列数据都和主键直接相关而不能间接相关
MySQL死锁

TIMESTAMP: 把客户端插入的时间从当前时区转化为UTC,查询时将其又转化为客户端当前时区进行返回;'1970-01-01 00:00:01.000000'to'2038-01-19 03:14:07.999999';插入NULL会自动赋值当前时间;4个字节;相对快
DATETIME: 原样输入和输出;'1000-01-01 00:00:00.000000'to'9999-12-31 23:59:59.999999';插入NULL就是NULL;8个字节;相对慢

utf8是1字符3字节,gbk是1字符2字节
utf8mb4的编码,mb4就是most bytes 4的意思,专门用来兼容四字节的unicode,好在utf8mb4是utf8的超集,除了将编码改为utf8mb4外不需要做其他转换
CHAR: 字符数而不是字节数;最大值为255字符;长度固定;速度快;CHAR(M)每个值都占用M个字节,如果某个长度小于M就会在它的右边用空格字符补足;
VARCHAR: 字符数而不是字节数;最大值为65535字节;可变长;速度慢;VARCHAR(M)每个值只占用刚好够用的字节再加上一个用来记录其长度的字节;
TEXT: 申明时不设置最大长度;最大65535字节;最慢
BLOB: 二进制


3.NoSQL
MongoDB
LevelDB
ElasticSearch/Logstash/Kibana/filebeat/Flume Shard/Replica 倒排索引 master/data/ingest/coodrinating only
MinIO
Etcd
TiDB
Ceph
Nginx
Keepalived/Haproxy/LVS
Promethous/Grafana


4.Redis
string SDS 长度不能超过512M int编码 raw编码 embstr编码
hash hashtable ziplist(列表保存元素个数小于512个&每个元素长度小于64字节)
list linkedlist ziplist(列表保存元素个数小于512个&每个元素长度小于64字节)
set hashtable intset(集合对象中所有元素都是整数&集合对象所有元素数量不超过512)
zset skiplist&字典 ziplist(保存的元素数量小于128&每个元素长度小于64字节)

AOF
RDB 快照 save&bgsave dump.rdb
RDB在恢复大数据集时的速度比AOF的恢复速度要快

HyperLogLog
PUB/SUB
事务 MULTI EXEC DISCARD UNWATCH WATCH
Lua EVAL "return {KEYS[1],KEYS[2],ARGV[1],ARGV[2]}" 2 key1 key2 first second
Redis GEO
Redis Stream
Redis Pipeline
Redis Bitmap

redis缓存击穿(热点key不失效或加锁)、缓存穿透(不存在的key设置空value和过期时间)、缓存雪崩(key失效时间不同)

redis和mysql数据一致性保证:
强一致性 弱一致性 最终一致性
Pattern: Cache-Aside/旁路缓存模式 Read-Through/Write-Through/读写穿透 Write-Behind/异步缓存写入
延时双删: 先删除缓存 再更新数据库 休眠一会再次删除缓存
同步binlog

读操作:
读到缓存直接返回
读不到缓存,先去DB读数据,再更新到缓存,再返回
写操作:
先写DB,删除缓存
问题:
A读了数据库还未更新缓存
B修改数据库
A再去更新缓存
数据不一致
解决办法加短的过期时间


单节点
主从 replicaof 127.0.0.1 7000
redis cluster
redis cluster+主从
主从+哨兵

daemonize yes
bind 127.0.0.1
port 7000
dir /home/thomas/server/redis/data/redis-7000
pidfile /var/run/redis/redis-7000.pid
logfile /home/thomas/server/redis/log/redis-7000.log
cluster-enabled yes
cluster-config-file /home/thomas/server/redis/conf/cluster-7000.conf
cluster-node-timeout 10000

rm -rf cluster data log
mkdir cluster data log
mkdir data/redis-7000 data/redis-7001 data/redis-7002 data/redis-8000 data/redis-8001 data/redis-8002 data/sentinel-9000 data/sentinel-9001 data/sentinel-9002

./redis-server /home/thomas/server/redis/conf/redis-7000.conf
./redis-cli -p 7000
./redis-cli --cluster create 127.0.0.1:7000 127.0.0.1:7001 127.0.0.1:7002
./redis-cli -c -p 7000
./redis-cli --cluster check 127.0.0.1:7000
./redis-cli --cluster reshard 127.0.0.1:7000
./redis-cli -p 7000 cluster nodes
./redis-cli --cluster add-node 127.0.0.1:7003 127.0.0.1:7000
./redis-cli --cluster add-node 127.0.0.1:8000 127.0.0.1:7000 --cluster-slave
./redis-cli --cluster add-node 127.0.0.1:8001 127.0.0.1:7000 --cluster-slave --cluster-master-id 7f3541c3b2e8bd05226729e9889a338b341cd77e
./redis-cli --cluster del-node 127.0.0.1:7000 3adfaaeb6d60f39e70562d961fe7fae200913386

port 9000
daemonize yes
logfile /home/thomas/server/redis/log/sentinel-9000.log
pidfile /var/run/redis/sentinel-9000.pid
dir /home/thomas/server/redis/data/sentinel-9000

sentinel monitor mymaster 127.0.0.1 7000 2
sentinel down-after-milliseconds mymaster 1500
sentinel failover-timeout mymaster 30000

./redis-sentinel /home/thomas/server/redis/conf/sentinel-9000.conf
./redis-cli -p 9000
sentinel master mymaster


5.MQ 异步/解耦/削峰
Kafka
消息永久保存,定期删除
topic partition ISR/OSR/AR
pull方式消费消息

Consumer Group:
多个消费者组成一个group,组内的所有消费者协调在一起来消费订阅主题的所有分区,每个分区只能由同一个消费组内的一个consumer来消费,避免重复消费,
记录offset到__consumer_offsets kafka自带的topic(记录到具体哪个分区hash(groupID) % numPartitions)

自动提交/手动提交: enable.auto.commit = true

Rebalance:
组成员发生变更/订阅主题数发生变更/订阅主题的分区数发生变更
coordinator来执行对于consumer group的管理,从consumer group选出一个leader并且generation+1,leader生成具体消费方案,leader把生成的方案发给coordinator,coordinator再同步给所有consumer
Heartbeat请求: consumer需要定期给coordinator发送心跳来表明自己还活着
LeaveGroup请求: 主动告诉coordinator我要离开consumer group
SyncGroup请求: group leader把分配方案发给coordinator,coordinator再告诉组内所有成员
JoinGroup请求: 成员请求加入组
DescribeGroup请求: 显示组的所有信息，包括成员信息，协议名称，分配方案，订阅信息等。通常该请求是给管理员使用

生产者幂等性:
ProducerID(每个新的Producer在初始化的时候会被分配一个唯一的PID)
SequenceNumber(对于每个PID,该Producer发送数据的每个<Topic,Partition>都对应一个从0开始单调递增的SequenceNumber)
只能保证单个partition内的幂等性,只能保证Producer在单个会话内不丟不重

事务:
涉及到多个Topic-Partition的写入时,这个事务操作要么会全部成功,要么会全部失败
initTransactions beginTransaction commitTransaction/abortTransaction
transactionalID由用户提供,和ProducerID+epoch组成唯一值
TransactionCoordinator __transaction_state
isolation.level read_committed/read_uncommitted
LEO: 日志末端位移(log end offset),最后一条消息的下一条消息的位移值
HW: 水位值,HW值不会大于LEO值,小于等于HW值的所有消息都被认为是已备份的,consumer无法消费分区下leader副本中位移值大于分区HW的任何消息,Kafka使用HW值来决定副本备份的进度
LSO:

log:
每个partition都有一个目录,里面有很多segment file
partition的第一个segment从0开始,后续每个segment文件名为上一个segment文件最后一条消息的offset
.index 文件名是消息总偏移 内容: 消息偏移(每个index都从0开始,稀疏索引,不是连续的)+字节偏移offset
.log
.timeindex CreateTime表示producer创建这条消息的时间,LogAppendTime leader broker将这条消息写入到log的时间

RabbitMQ
消息消费完就删除
AMQP/高级消息队列协议
routing-key/路由
交换器/Exchange: direct/fanout/topic/headers
支持pull、push方式消费消息

消息丢失:
生产者 事务(同步阻塞慢) 发送确认(异步快)(确认成功就在数据库设置标记,否则重新发送消息,未确认的消息也可存在内存/本地磁盘/redis)
broker 持久化Exchange、Queue、Message
消费者 改为手动提交(自动提交在broker发送消息到消费端就会删除) autoAck=false

死信交换机/死信队列:
默认情况下queue中被抛弃的消息将被直接丢掉,但是可以通过设置queue的x-dead-letter-exchange参数将被抛弃的消息发送到指定的exchange中
消费方nack/reject时指定了requeue=false、消息的TTL已到、消息队列的max-length已到
设置队列中所有消息的过期时间x-message-ttl,队列最大消息数x-max-length,生产者设置单个消息的expiration
Alternate Exchange: 发送消息的时候根据routing-key没有对应的队列接受消息,这就会将此消息路由到Alternate Exchange属性指定的Exchange上了,如果mandatory=true则会将消息返回给生产者
如果发送到A消费者的消息一直不确认,只有等到A消费者与rabbitmq的连接中断,rabbitmq才会考虑将A消费者未确认的消息重新投递给另一个消费者

Ack: 确认后删除消息; Reject: 只能拒绝一个; Nack: 可以拒绝多个

Message:
expiration 消息的过期时刻
deliveryMode 1为非持久化,2为持久化
Queue:
durable 持久化
exclusive 该队列仅对首次声明他它的连接可见,并在连接断开时自动删除
autoDelete 所有与这个连接的消费者都断开时会自动删除
Exchange:
durability 持久化
autoDelete 与这个Exchange绑定的Queue或Exchange都与此解绑时,会删除本交换器

requeue重新放入队列,是立即可以再次消费还是等多长时间?
没有ack后多久可以再次消费此消息?

集群:
普通集群 队列只会存在一个节点,存在哪个节点,是固定的一个还是随机分散?
镜像队列 主从模式,针对的是队列不是节点,push操作会在主从的每个节点上执行一次,消费操作在master执行然后广播给每个slave;
        新增加一个节点需要配置才会同步master所有数据,并且同步时会阻塞

延时队列: 死信队列+ttl 插件rabbitmq-delayed-message-exchange
优先队列: 队列设置的x-max-priority,消息设置队列设置的priority,优先级越大越先消费

事务:
txSelect txComment txRollback


RocketMQ
消息永久保存,定期删除
支持pull、push方式消费消息
NameServer: 路由控制中心,NameServer之间没有数据同步,Broker上报信息到NameServer
Broker: 多主多从,只有主Broker节点才能写,当master宕机,master上的队列不可写入,但是读取依然是可以的
生产消息: SendSync/SendAsync/SendOneWay

Topic:
主题,创建topic时指定读写队列数量,可以指定broker创建也可以让集群自动分配
mqadmin updateTopic
mqadmin deleteTopic
mqadmin updateSubGroup
mqadmin deleteSubGroup
mqadmin updateTopicPerm
mqadmin consumerProgress
writeQueueNums/readQueueNum: 方便队列的缩容和扩容

Tag: 子主题
GroupName: 生产者组合或消费者组合
ProducerGroup: 
ConsumerGroup: 一个Queue最多只能分配给一个Consumer

主从:
slave向master报告自己的最大偏移量
master向slave返回偏移量后的CommitLog数据
brokerId=0表明这个broker是master,brokerId>0表明这个broker是slave
slave只负责读,rocketmq目前还不支持主从切换,需要手动切换
正常情况下consumer并不能配置从master读还是slave读,本次拉取的数据量大于物理内存的40%和当master不可用或者繁忙的时候consumer会从slave读
master可配置同步复制SYNC_MASTER/异步复制ASYNC_MASTER

Rebalance: 
订阅Topic的队列数量变化(broker宕机、队列扩容/缩容)/消费者组信息变化(消费者宕机、消费者扩容/缩容、Topic订阅信息发生变化)
一个队列最多分配给一个消费者,offset是异步提交造成重复消费,Broker端负责Rebalance元数据维护
周期性触发rebalance
同一个消费者组订阅多个Topic时可能会出现分配不均
对Topic队列/消费者各自进行排序,每个消费者需要使用相同的分配策略

广播消费:
广播模式消费位移使用本地文件存储,Rebalance过程中同一个ConsumeGroup下的consumer不会进行MessageQueue的分配,每个consumer负责订阅的topic下的所有MessageQueue

log:
commitLog存消息数据
consumeQueue存索引
config存Group/Topic/Consumer消费的offset
超时时间/磁盘占比/人工删除触发删除commitLog/consumeQueue

offset: 当消费模式为广播模式时offset使用本地模式存储;集群模式下存在config
消息堆积: 增加consumer;放到临时的topic再增加新的consumer去消费

延时队列:
生产消息时设置,只能选择1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h(可以改配置文件增加level),level从1开始;消息按照延迟时间段发送到指定的延时队列(SCHEDULE_TOPIC_XXXX)中,定时器进行轮训这些队列查看消息是否到期,如果到期就把这个消息发送到指定topic的队列中,这样的好处是同一队列中的消息延时时间是一致的,还有一个好处是这个队列中的消息是按照消息到期时间进行递增排序的,然后把延迟队列中的消息删除

死信队列:
%DLQ%+consumerGroup
消费失败自动进行消息重试,达到最大重试次数后将其发送到该消费者对应的特殊队列中,有效期与正常消息相同到期自动删除
一个死信队列对应一个GroupID

重试:
广播消息是不会重试的
生产端重试: 生产端自动重试,可设置超时时间和重试次数,异步发送重试次数只有1/0次
消费端重试: 主动返回RECONSUME_LATER消息会进入重试队列,超过最大重试次数就进入死信队列;超时重试是直接重试不需要延时,会一直重试下去;message携带重试次数消费端可以用来判断
重试队列: 先保存到SCHEDULE_TOPIC_XXXX中,再设置偏移量,后台定时任务按照对应的时间进行Delay后重新保存至%RETRY%+consumerGroup重试队列中,消费者消费重试队列

事务:
prepare阶段
commit/rollback阶段

ActiveMQ
JMS
kahadb leveldb mysql
topic
P2P: 生产者向队列投递一条消息,只有一个消费者能够监听得到这条消息
Pub/Sub: 生产者向队列投递一条消息,所有监听该队列的消费者都能够监听得到这条消息
与zookeeper进行构建主备集群模型
Network集群模型


Pulsar

优先队列
延时队列
消息丢失
重复消费 幂等
顺序消费
消息堆积
事务


6.网络/TCP/IP/UDP
物理层
数据链路层 ARP RARP
网络层 IP ICMP IGMP
传输层 TCP UDP
应用层 HTTP FTP TFTP SMTP DNS

三次握手 避免重复连接
四次挥手
粘包
DDOS
半连接队列
全连接队列

最大传输单元(MTU) 1500字节
MSS （最大报文段长度）536

SYN Flood
Syn Cache: 不直接分配TCB,使用更少的数据记录状态
Syn Cookie: 无状态的三次握手
cookie源认证: 记录sequence number,将真实客户端IP加入白名单
reset认证: reset报文,将真实客户端IP加入白名单

慢启动 慢启动门限(ssthresh) 65536 指数增长
拥塞避免 线性增长 重传了一个报文段 ssthresh=cwnd/2 cwnd=1 进入慢启动
快速重传 收到3个相同的ACK ssthresh=cwnd/2 cwnd=ssthresh 进入拥塞避免
快速恢复
窗口值的大小就代表能够发送出去的但还没有收到ACK的最大数据报文段
拥塞窗口(cwnd)
接收窗口(rwnd)


7.HTTP HTTP2 TLS/SSL
状态码:
200 请求成功
301 资源（网页等）被永久转移到其它URL

1xx 信息响应
2xx 成功响应
3xx 重定向
4xx 客户端错误
5xx 服务器错误

301 MovedPermanently 永久移动
302 Found 临时移动,与301类似,但资源只是临时被移动,客户端应继续使用原有URI

400 Bad Request
401 Unauthorized
403 Forbidden
404 请求的资源（网页等）不存在

500 InternalServerError
501 NotImplemented
502 BadGateway
503 ServiceUnavailable
504 GatewayTimeout
505 HTTPVersionNotSupported

包含请求方法、URI、HTTP版本信息
header
body

包含HTTP版本、状态码、状态码的原因短语
header
body

HTTP 2.0 和 HTTP1.1 区别
多路复用 二进制分帧层
首部压缩
HTTP2支持服务器推送

跨域CORS 同源策略 JSONP
CSRF/XSRF XSS
JWT Session Token
SSRF:
由攻击者构造形成由服务端发起请求的一个安全漏洞,一般情况下,SSRF攻击的目标是从外网无法访问的内部系统,正是因为它是由服务端发起的所以它能够请求到与它相连而与外网隔离的内部系统
形成的原因大都是由于服务端提供了从其他服务器应用获取数据的功能且没有对目标地址做过滤与限制,比如从指定URL地址获取网页文本内容,加载指定地址的图片,下载


8.Kubernetes
Pod Deployment Service DaemonSet StatefulSet ReplicaSet Job Label Namespace ConfigMap Secret Ingress
Volume PersistentVolume PersistentVolumeClaim StorageClass
kube-apiserver etcd kube-scheduler kube-controller-manager kubelet kube-proxy


9.微服务/服务网格
服务注册发现
链路追踪
Istio/Serverless


10.分布式
CAP
高并发
高可用
事务
Snowflake
限流 漏桶算法 令牌桶算法
熔断
降级
灾备
异地多活
Sentinel
秒杀
2PC/3PC/TCC
Raft/Paxos


11.操作系统
进程
线程 TCB
内存
进程间通信 管道 命名管道FIFO 共享内存 消息队列 信号 UNIX域 socket DBUS
同步 信号量 互斥量 条件变量 读写锁
IO多路复用 poll select epoll
socket


12.算法
栈/队列
排序
二叉树/红黑树
链表
动态规划
图
缓存
字符串
