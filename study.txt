1.Golang
切片
map
管道
select
协程 调度 GMP
内存回收 三色标记 白 灰 黑
内存管理 mheap mspan mcentral mcache mstats TCMalloc
内存逃逸
接口interface
反射
定时器
性能优化 pprof


2.MySQL
聚族索引和非聚族索引
覆盖索引
前缀索引
主键索引 普通索引 唯一索引 联合索引 全文索引
InnoDB和MyISAM
索引B树和B+树
B树的所有节点既存放键(key)也存放数据(data),而B+树只有叶子节点存放key和data,其他内节点只存放key
B+树的叶子节点有一条引用链指向与它相邻的叶子节点

执行流程
mvcc 快照读 当前读 ReadView
隔离级别 读取未提交 读取已提交 可重复读 可串行化

InnoDB 通过数据行的 DB_TRX_ID 和 Read View 来判断数据的可见性
DB_TRX_ID(6字节): 表示最后一次插入或更新该行的事务 id
DB_ROLL_PTR(7字节): 回滚指针，指向该行的 undo log
DB_ROW_ID(6字节): 如果没有设置主键且该表没有唯一非空索引时，InnoDB会使用该id来生成聚簇索引

redo log
undo log
binlog

Record lock 记录锁 单条索引记录上加锁
Gap lock 间隙锁 锁住一个索引区间(开区间,不包括双端端点) 防止幻读,保证索引间的不会被插入数据
Next-key lock 临键锁 = Gap Lock + Record Lock 为了解决幻读 左开右闭区间
自增锁
意向锁 意向共享锁IS 意向排它锁IX 表级别锁
插入意向锁: 间隙锁的一种,专门针对insert操作,多个事务在同一个索引同一个范围区间插入记录时候,如果插入位置不冲突,不会彼此阻塞
select ... lock in share mode  S锁 共享锁
select ... for update X锁 排他锁

ACID 原子性 一致性 隔离性 持久性

脏读
幻读
不可重复读

回表

连接器 查询缓存、分析器、优化器、执行器

Buffer Pool
redo log buffer

分库分表
主从复制
读写分离

数据库三范式: 每列保持原子性 每列都和主键相关 每一列数据都和主键直接相关而不能间接相关
MySQL死锁


3.NoSQL
MongoDB
LevelDB
ElasticSearch Shard/Replica 倒排索引 master/data/ingest/coodrinating only
MinIO

4.Redis
string SDS 长度不能超过512M int编码 raw编码 embstr编码
hash hashtable ziplist(列表保存元素个数小于512个&每个元素长度小于64字节)
list linkedlist ziplist(列表保存元素个数小于512个&每个元素长度小于64字节)
set hashtable intset(集合对象中所有元素都是整数&集合对象所有元素数量不超过512)
zset skiplist&字典 ziplist(保存的元素数量小于128&每个元素长度小于64字节)

AOF
RDB 快照 save&bgsave dump.rdb
RDB在恢复大数据集时的速度比AOF的恢复速度要快

HyperLogLog
PUB/SUB
事务 MULTI EXEC DISCARD UNWATCH WATCH
Lua EVAL "return {KEYS[1],KEYS[2],ARGV[1],ARGV[2]}" 2 key1 key2 first second
Redis GEO
Redis Stream
Redis Pipeline
Redis Bitmap

redis缓存击穿(热点key不失效或加锁)、缓存穿透(不存在的key设置空value和过期时间)、缓存雪崩(key失效时间不同)

redis和mysql数据一致性保证:
强一致性 弱一致性 最终一致性
Pattern: Cache-Aside/旁路缓存模式 Read-Through/Write-Through/读写穿透 Write-Behind/异步缓存写入
延时双删: 先删除缓存 再更新数据库 休眠一会再次删除缓存
同步binlog

读操作:
读到缓存直接返回
读不到缓存,先去DB读数据,再更新到缓存,再返回
写操作:
先写DB,删除缓存
问题:
A读了数据库还未更新缓存
B修改数据库
A再去更新缓存
数据不一致
解决办法加短的过期时间


单节点
主从 replicaof 127.0.0.1 7000
redis cluster
redis cluster+主从
主从+哨兵

daemonize yes
bind 127.0.0.1
port 7000
dir /home/thomas/server/redis/data/redis-7000
pidfile /var/run/redis/redis-7000.pid
logfile /home/thomas/server/redis/log/redis-7000.log
cluster-enabled yes
cluster-config-file /home/thomas/server/redis/conf/cluster-7000.conf
cluster-node-timeout 10000

rm -rf cluster data log
mkdir cluster data log
mkdir data/redis-7000 data/redis-7001 data/redis-7002 data/redis-8000 data/redis-8001 data/redis-8002 data/sentinel-9000 data/sentinel-9001 data/sentinel-9002

./redis-server /home/thomas/server/redis/conf/redis-7000.conf
./redis-cli -p 7000
./redis-cli --cluster create 127.0.0.1:7000 127.0.0.1:7001 127.0.0.1:7002
./redis-cli -c -p 7000
./redis-cli --cluster check 127.0.0.1:7000
./redis-cli --cluster reshard 127.0.0.1:7000
./redis-cli -p 7000 cluster nodes
./redis-cli --cluster add-node 127.0.0.1:7003 127.0.0.1:7000
./redis-cli --cluster add-node 127.0.0.1:8000 127.0.0.1:7000 --cluster-slave
./redis-cli --cluster add-node 127.0.0.1:8001 127.0.0.1:7000 --cluster-slave --cluster-master-id 7f3541c3b2e8bd05226729e9889a338b341cd77e
./redis-cli --cluster del-node 127.0.0.1:7000 3adfaaeb6d60f39e70562d961fe7fae200913386

port 9000
daemonize yes
logfile /home/thomas/server/redis/log/sentinel-9000.log
pidfile /var/run/redis/sentinel-9000.pid
dir /home/thomas/server/redis/data/sentinel-9000

sentinel monitor mymaster 127.0.0.1 7000 2
sentinel down-after-milliseconds mymaster 1500
sentinel failover-timeout mymaster 30000

./redis-sentinel /home/thomas/server/redis/conf/sentinel-9000.conf
./redis-cli -p 9000
sentinel master mymaster


5.MQ 异步/解耦/削峰
Kafka
消息永久保存,定期删除
topic partition ISR/OSR/AR
pull方式消费消息

Consumer Group:
多个消费者组成一个group,组内的所有消费者协调在一起来消费订阅主题的所有分区,每个分区只能由同一个消费组内的一个consumer来消费,避免重复消费,
记录offset到__consumer_offsets kafka自带的topic(记录到具体哪个分区hash(groupID) % numPartitions)

自动提交/手动提交: enable.auto.commit = true

Rebalance:
组成员发生变更/订阅主题数发生变更/订阅主题的分区数发生变更
coordinator来执行对于consumer group的管理,从consumer group选出一个leader并且generation+1,leader生成具体消费方案,leader把生成的方案发给coordinator,coordinator再同步给所有consumer
Heartbeat请求: consumer需要定期给coordinator发送心跳来表明自己还活着
LeaveGroup请求: 主动告诉coordinator我要离开consumer group
SyncGroup请求: group leader把分配方案发给coordinator,coordinator再告诉组内所有成员
JoinGroup请求: 成员请求加入组
DescribeGroup请求: 显示组的所有信息，包括成员信息，协议名称，分配方案，订阅信息等。通常该请求是给管理员使用

RabbitMQ
消息消费完就删除
AMQP/高级消息队列协议
routing-key/路由
交换器/Exchange: direct/fanout/topic/headers
支持pull、push方式消费消息

消息丢失:
生产者 事务(同步阻塞慢) 发送确认(异步快)(确认成功就在数据库设置标记,否则重新发送消息,未确认的消息也可存在内存/本地磁盘/redis)
broker 持久化Exchange、Queue、Message
消费者 改为手动提交(自动提交在broker发送消息到消费端就会删除) autoAck=false

死信交换机/死信队列:
默认情况下queue中被抛弃的消息将被直接丢掉,但是可以通过设置queue的x-dead-letter-exchange参数将被抛弃的消息发送到指定的exchange中
消费方nack/reject时指定了requeue=false、消息的TTL已到、消息队列的max-length已到
设置队列中所有消息的过期时间x-message-ttl,队列最大消息数x-max-length,生产者设置单个消息的expiration
Alternate Exchange: 发送消息的时候根据routing-key没有对应的队列接受消息,这就会将此消息路由到Alternate Exchange属性指定的Exchange上了,如果mandatory=true则会将消息返回给生产者
如果发送到A消费者的消息一直不确认,只有等到A消费者与rabbitmq的连接中断,rabbitmq才会考虑将A消费者未确认的消息重新投递给另一个消费者

Ack: 确认后删除消息; Reject: 只能拒绝一个; Nack: 可以拒绝多个

Message:
expiration 消息的过期时刻
deliveryMode 1为非持久化,2为持久化
Queue:
durable 持久化
exclusive 该队列仅对首次声明他它的连接可见,并在连接断开时自动删除
autoDelete 所有与这个连接的消费者都断开时会自动删除
Exchange:
durability 持久化
autoDelete 与这个Exchange绑定的Queue或Exchange都与此解绑时,会删除本交换器

requeue重新放入队列,是立即可以再次消费还是等多长时间?
没有ack后多久可以再次消费此消息?

集群:
普通集群 队列只会存在一个节点,存在哪个节点,是固定的一个还是随机分散?
镜像队列 主从模式,针对的是队列不是节点,push操作会在主从的每个节点上执行一次,消费操作在master执行然后广播给每个slave;
        新增加一个节点需要配置才会同步master所有数据,并且同步时会阻塞

延时队列: 死信队列+ttl 插件rabbitmq-delayed-message-exchange
优先队列: 队列设置的x-max-priority,消息设置队列设置的priority,优先级越大越先消费


RocketMQ
消息永久保存,定期删除
支持pull、push方式消费消息
NameServer: 路由控制中心,NameServer之间没有数据同步,Broker上报信息到NameServer
Broker: 多主多从,只有主Broker节点才能写,当master宕机,master上的队列不可写入,但是读取依然是可以的
生产消息: SendSync/SendAsync/SendOneWay

主从能否自动切换?
从节点能否消费消息?

Topic:
主题,创建topic时指定读写队列数量,可以指定broker创建也可以让集群自动分配
mqadmin updateTopic
mqadmin deleteTopic
mqadmin updateSubGroup
mqadmin deleteSubGroup
mqadmin updateTopicPerm
writeQueueNums/readQueueNum

Tag: 子主题
GroupName: 生产者组合或消费者组合
ProducerGroup: 
ConsumerGroup: 一个Queue最多只能分配给一个Consumer

主从同步:
slave向master报告自己的最大偏移量
master向slave返回偏移量后的CommitLog数据
brokerId=0表明这个broker是master,brokerId>0表明这个broker是slave
rocketmq目前还不支持主从切换,需要手动切换
正常情况下consumer并不能配置从master读还是slave读,当master不可用或者繁忙的时候consumer会被自动切换到从slave读
同步复制/异步复制



Rebalance: 
订阅Topic的队列数量变化(broker宕机、队列扩容/缩容)/消费者组信息变化(消费者宕机、消费者扩容/缩容、Topic订阅信息发生变化)
一个队列最多分配给一个消费者,offset是异步提交造成重复消费,Broker端负责Rebalance元数据维护

广播消费:
广播模式消费位移使用本地文件存储,Rebalance过程中同一个ConsumeGroup下的consumer不会进行MessageQueue的分配,每个consumer负责订阅的topic下的所有MessageQueue

log:
commitLog存消息数据
consumeQueue存索引
config存Group/Topic/Consumer消费的offset
超时时间/磁盘占比/人工删除触发删除commitLog/consumeQueue

offset: 当消费模式为广播模式时offset使用本地模式存储;集群模式下存在config
消息堆积: 增加consumer;放到临时的topic再增加新的consumer去消费

延时队列:
生产消息时设置,只能选择1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h(可以改配置文件增加level),level从1开始;消息按照延迟时间段发送到指定的延时队列(SCHEDULE_TOPIC_XXXX)中,定时器进行轮训这些队列查看消息是否到期,如果到期就把这个消息发送到指定topic的队列中,这样的好处是同一队列中的消息延时时间是一致的,还有一个好处是这个队列中的消息是按照消息到期时间进行递增排序的,然后把延迟队列中的消息删除

死信队列:
%DLQ%+consumerGroup
消费失败自动进行消息重试,达到最大重试次数后将其发送到该消费者对应的特殊队列中,有效期与正常消息相同到期自动删除
一个死信队列对应一个GroupID

重试:
广播消息是不会重试的
生产端重试: 生产端自动重试,可设置超时时间和重试次数,异步发送重试次数只有1/0次
消费端重试: 主动返回RECONSUME_LATER消息会进入重试队列,超过最大重试次数就进入死信队列;超时重试是直接重试不需要延时,会一直重试下去;message携带重试次数消费端可以用来判断
重试队列: 先保存到SCHEDULE_TOPIC_XXXX中,再设置偏移量,后台定时任务按照对应的时间进行Delay后重新保存至%RETRY%+consumerGroup重试队列中,消费者消费重试队列

事务:
prepare阶段
commit/rollback阶段

ActiveMQ
Pulsar

优先队列
延时队列
消息丢失
重复消费 幂等
顺序消费
消息堆积
事务


6.网络/TCP/IP/UDP
物理层
数据链路层 ARP RARP
网络层 IP ICMP IGMP
传输层 TCP UDP
应用层 HTTP FTP TFTP SMTP

三次握手 避免重复连接
四次挥手
粘包
DDOS
半连接队列
全连接队列

最大传输单元(MTU) 1500字节
MSS （最大报文段长度）536

SYN Flood
Syn Cache: 不直接分配TCB,使用更少的数据记录状态
Syn Cookie: 无状态的三次握手
cookie源认证: 记录sequence number,将真实客户端IP加入白名单
reset认证: reset报文,将真实客户端IP加入白名单

慢启动 慢启动门限(ssthresh) 65536 指数增长
拥塞避免 线性增长 重传了一个报文段 ssthresh=cwnd/2 cwnd=1 进入慢启动
快速重传 收到3个相同的ACK ssthresh=cwnd/2 cwnd=ssthresh 进入拥塞避免
快速恢复
窗口值的大小就代表能够发送出去的但还没有收到ACK的最大数据报文段
拥塞窗口(cwnd)
接收窗口(rwnd)


7.HTTP HTTP2 TLS/SSL
状态码:
200 请求成功
301 资源（网页等）被永久转移到其它URL

1xx 信息响应
2xx 成功响应
3xx 重定向
4xx 客户端错误
5xx 服务器错误

301 MovedPermanently 永久移动
302 Found 临时移动,与301类似,但资源只是临时被移动,客户端应继续使用原有URI

400 Bad Request
401 Unauthorized
403 Forbidden
404 请求的资源（网页等）不存在

500 InternalServerError
501 NotImplemented
502 BadGateway
503 ServiceUnavailable
504 GatewayTimeout
505 HTTPVersionNotSupported

包含请求方法、URI、HTTP版本信息
header
body

包含HTTP版本、状态码、状态码的原因短语
header
body

HTTP 2.0 和 HTTP1.1 区别
多路复用 二进制分帧层
首部压缩
HTTP2支持服务器推送

跨域CORS 同源策略 JSONP
CSRF/XSRF XSS
JWT Session Token


8.Kubernetes
Pod Deployment Service DaemonSet StatefulSet ReplicaSet Job Label Namespace ConfigMap Secret Ingress
Volume PersistentVolume PersistentVolumeClaim StorageClass
kube-apiserver etcd kube-scheduler kube-controller-manager kubelet kube-proxy


9.微服务/服务网格
服务注册发现
链路追踪

10.分布式 高并发 事务 Snowflake
限流 漏桶算法 令牌桶算法
熔断
降级
灾备
异地多活
Sentinel


11.操作系统
进程
线程 TCB
内存
进程间通信 管道 命名管道FIFO 共享内存 消息队列 信号 UNIX域 socket DBUS
同步 信号量 互斥量 条件变量 读写锁
IO多路复用 poll select epoll


12.算法
