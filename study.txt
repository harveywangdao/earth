1.Golang
slice:
只能判断slice==nil,不能slice1==slice2
扩容规则: 容量小于1024时每次扩容2倍,大于1024时每次扩大1.25倍,且遵循内存对齐规则;切片扩容机制与切片的数据类型、原本切片的容量、所需要的容量都有关系
s[:] s[i:] s[:j] s[i:j]
s[i:j:k]k代表容量,k>=j,如果没有k则默认原切片的cap长度,新切片的len=j-i,cap=k-i
从一个长的切片里截取部分数据,未使用的空间不会gc
nil切片也会分配结构体,ptr是0;空切片ptr指向固定地址
切片操作时j可以大于当前len

array:
数组以arr[:]方式转成切片,切片的底层直接指向了这个数组
数组可以使用len和cap
不能append,copy
arr2:=arr1是值复制,拷贝所有数据
可以range,会完全复制整个数组,编译器优化实际只有一份内存,有待研究?
可以直接==判断

string:
有len无cap
不可修改
对字符串进行切片操作(str[:])生成的还是字符串,不能修改值
[]byte转成string一定会拷贝内存吗,使用m[string(b)]来查找;字符串拼接;string(b) == "foo"
不能等于nil
str[0]是byte/uint8;range str返回的是rune/int32,range str时index可能是不连续的,value是unicode
[]rune(str)转成unicode,[]byte(str)转成utf-8的每个字节
常量字符串在编译阶段存在数据区,如果两个变量对应的字符串一样,那么两个变量对应的指针指向同一个地址

map:
冲突解决,开放寻址法:写入新的数据时如果发生了冲突就会将键值对写入到下一个索引为空的位置;拉链法:数组加上链表,引入红黑树以优化性能
切片/map不能作为key,但可以作为value
并发读写会panic,通过flags标志位判断
hash高8位用作tophash,底位用于计算在哪个桶
每个桶都是一个bmap,每个bucket可以存8个kv,摆放方式key1...key8/value1...value8,溢出桶通过链表链接
tophash,emptyRest表示后面没有数据了,emptyOne表示当前没有key
初始化,makemap,bucket数量一般是2的倍数,初始化时容量超过8才会分配空间,最少分配2个bucket
插入更新,mapassign,先找这个key是否已经存在,如果存在则更新value,如果不存在则找到第一个emptyOne/emptyRest插入新KV
删除,mapdelete,找到这个key,把tophash设置成emptyOne,把最后一个有key的后面所有的tophash都设置成emptyRest
查询,mapaccess1一个返回值,mapaccess2带ok的返回值,如果key不存在则返回&zeroVal[0]
遍历,mapiterinit初始化hiter结构体,起始桶和桶内的offset是随机数,mapiternext先遍历一个桶内的8个key再遍历下一个桶
扩容,map中数据总个数/桶个数>6.5时(overLoadFactor),引发翻倍扩容,或者是使用了太多的溢出桶时(tooManyOverflowBuckets)这种是同容量扩容将松散的数据聚合,因为删除操作造成太多的空洞,hashGrow开始扩容,插入/更新/删除时触发实际扩容(growWork),扩容当前的桶和一个每次递增的桶
mapextra,nextOverflow存放未使用的溢出桶,overflow/oldoverflow为了优化GC扫描而设计,当key和value均不包含指针并且都可以inline时使用,避免扫描hmap
hash函数

chan:
以通信方式共享内存,不要以共享内存方式通信
len+cap;读写nil管道都会阻塞;close nil管道会panic;close两次管道会panic
nil管道,发送/接收数据会阻塞,close会panic
往已close的管道发送数据会panic,可以接收数据第二个返回值是false
初始化,makechan,recvq/sendq存储G的接收发送队列,循环数组实现的数据队列,sendx/recvx记录队列中发送接收的位置
发送,chansend,如果recvq有等待的G会直接发送给这个G,调用goready唤醒这个G,如果队列没满就把数据放入队列,sendx加1然后返回,如果队列已经满了就把G放入sendq队列然后阻塞调用gopark,数据存在sudog上
接收,chanrecv1,chanrecv2返回值带ok,如果发送队列sendq不为空并且数据队列长度是0则直接获取阻塞G的数据并唤醒阻塞G,如果发送队列sendq不为空并且数据队列长度大于0则返回sendx位置的数据并且将阻塞G的数据放入队列,同样要唤醒阻塞G,此时队列是满的,recvx加1后,将recvx赋值给sendx,如果发送队列sendq为空并且数据队列不为空则返回sendx位置的数据,如果发送队列sendq为空并且数据队列也为空,那就将当前G放入recvq队列
close,closechan,close两次会panic,唤醒所有recv等待者,唤醒所有send等待者并且panic

select:
可用于收发多个管道,可非阻塞收发管道,可增加超时时间收发管道
select中所有case都阻塞就走default,没有default就阻塞
只能用于管道
case是随机执行的,避免饥饿问题
两个case可以接收同一个管道
超过1个case,有default,selectgo.block=false
超过1个case,无default,selectgo.block=true
0/1个case时编译器特殊处理:
只有一个读chan的case,chanrecv1
只有一个写chan的case,chansend1
只有一个读chan的case+default,selectnbrecv
只有一个写chan的case+default,selectnbsend
没有case也没有default,block
只有default,直接JMP
select recv多个管道,且这些管道都无数据,select所在G阻塞,sudog加入每个管道的recvq,其它G同时send数据给这些管道,通过g.selectDone防止所有管道同时给G发送数据

struct:
空结构体都指向zerobase;当空结构体放到另一个结构体中的最后一个字段时会进行特殊填充
结构体可以直接==判断
继承,一个结构体嵌到另一个结构体
如果一个struct嵌套了另一个匿名结构体,那么这个结构可以直接访问匿名结构体的方法从而实现继承
如果一个struct嵌套了另一个有名结构体,那么这个模式叫做组合
结构体方法调用时会先拷贝一份,所以无法改变原本结构体内部的成员值,因为接收者是结构体
结构体指针方法,把结构体赋值给接口,这时调用方法会造成编译不过,因为结构体会复制一份,当调用方法时需要取指针,这时结构体有两份拷贝编译器没有办法根据结构体找到一个唯一的指针

接口interface:
接口是一种抽象的类型,描述了一系列方法的集合,接口只定义方法名和参数而不包含具体的实现,对一系列具有联系的方法做出抽象和概括
只要实现了接口的所有方法,这个类型就实现了该接口,duck typing,不需要显式地去继承接口,编译阶段就可以发现是否实现了接口
eface表示空的interface{},有两个字段_type和data,data是指向数据的指针,_type是类型信息
iface表示至少带有一个函数的interface,有两个字段tab和data,itab表示interface和实际类型的转换信息,运行时为这一对具体的<Interface,Type>生成itab信息

协程:
pc: program counter,pc寄存器的作用是存储程序接下来运行的位置
sp: stack pointer,当前线程使用的栈的栈顶地址
systemstack: 可以由g0/gsignal/普通g调用,当由普通g调用的时候会切换到g0,调用完再切回普通g栈
mcall: 从普通g栈切换到g0栈,该函数由普通g调用,fn不能返回
stopTheWorld/startTheWorld: stopTheWorldWithSema通知所有P上的G被抢占,只设置抢占状态不保证立即被抢占,系统调用tgkill,发送信号给其它M让其停止,preemptall:循环allp调用preemptone,G正在newstack的时候要忽略停止的请求,设置G/P的preempt为true,preemptM-->signalM-->tgkill-->doSigPreempt-->asyncPreempt-->preemptPark->dropg->schedule->gcstopm->stopm->mPark;startTheWorldWithSema重新调整P大小procresize,循环所有P,绑定所有P和M,再唤醒所有M,wakep->startm如果有闲置的P那么就将P和一个闲置的M绑定,其它被唤醒的M执行schedule重新调度

lock/unlock:futexsleep/futexwakeup linux futex系统调用实现
notesleep:不带超时,g0调用
notetsleep:带超时,一般情况下被g0调用
notetsleepg:带超时,普通g调用
notewakeup:唤醒指定线程

gcstopm:stopm->mPark->notesleep
acquirep:wirep绑定M和P
releasep:解绑P和M
execute:绑定M和G
dropg:解绑M和G,G的状态改为_Grunning,调用gogo执行协程函数

throw->fatalthrow->startpanic_m+dopanic_m
gopanic->fatalpanic->startpanic_m+dopanic_m
raise->tgkill
crash->raise(SIGABRT)
exit->exit_group
LockOSThread/UnlockOSThread/FreeOSMemory/SetGCPercent/SetMaxStack/ReadGCStats/SetPanicOnFault/WriteHeapDump/SetTraceback

main:
_rt0_amd64_linux
_rt0_amd64
rt0_go
runtime.settls: 调用系统调用arch_prctl
runtime.check: 检查基础类型是否正确,如int8是不是一个字节
runtime.args: 处理参数
runtime.osinit: 获取cpu数量
runtime.schedinit: 初始化堆栈/环境变量/进程入参/gc
runtime.newproc: 创建新G运行fn=runtime.main->main_main,将G放入当前P的队列,执行wakep
runtime.mstart: 保存pc/sp,执行schedule
runtime.abort: INT $3

G:
Goroutine协程
G状态:_Grunning/_Gwaiting/_Grunnable/_Gsyscall/_Gidle/_Gdead/_Gcopystack/_Gpreempted
G存储在,LRQ本地运行队列/GRQ全局运行队列/Netpoller网络轮询器/系统调用/锁/chan receive/chan send/select,本地P运行队列没有剩余空间时会使用全局队列
GC sweep/GC scavenge/force gc/GC worker
tls: thread local storage 为线程本地存储
gsignal:signal-handling g
g0:是持有调度栈的Goroutine,参与运行时的调度过程,包括G的创建/大内存分配/CGO函数的执行
getg: 返回当前g的指针,在编译的时候才会生成该函数
newproc:创建一个新G,在g0栈里调用该函数,newproc1:从gFree里获取,如果获取不到就new一个g并分配2K栈状态设为_Gdead加到allgs上,参数放入栈,状态设为_Grunnable,goid设置成当前P上的自增值,新G放到当前P的本地队列/全局队列/当前P的下一个要执行的g,wakep->startm获取空闲P,如果没有空闲P直接返回,如果有空闲P就去获取空闲的M(mget),绑定P和M,唤醒M,如果没有空闲M就去newm
gopark/goready
gosave/gogo
gobuf
goexit:该函数地址放在栈顶,当协程函数执行完就会执行goexit,goexit1->goexit0,g状态设置成_Gdead,dropg拆解m和g的绑定,把g放到gFree上,重新schedule

M:
操作系统线程
SetMaxThreads,默认sched.maxmcount=10000
最大活跃线程数是GOMAXPROCS,非活跃线程可能阻塞在系统调用
目前并没有对闲置线程做清除处理
osyield: 线程让出cpu,调用系统调用sched_yield
procyield: 执行PAUSE指令空转
m0
startm: 获取一个闲置的M,如果没有就newm一个
newm: 创建新线程并让线程工作,newm(fn, _p_, id),allocm获取M,new一个m对象,mstartfn=mspinning,M初始化,分配g0,(解绑当前的P和M,当前P的状态设置为_Pidle),绑定空闲P和新M,newm1->newosproc->clone->mstart
allocm: 获取m结构体
newosproc: 创建系统线程
mcommoninit: M的一些初始化,创建gsignal
mexit: mstart的结尾调用,退出当前线程,释放gsignal栈,从allm移除m,(非系统栈时m对象放在sched.freem上,后期由allocm释放栈),解绑M和P,让P去找另一个M去执行,线程自然退出由OS释放资源,(非系统栈调用系统调用exit退出)
mstart: 线程开始工作,clone时传进去的函数/systemstack中有调用,mstart1,当前是g0在执行,保存pc/sp,初始化信号,acquirep->wirep正式绑定空闲P和新M,设置P的状态为_Prunning,schedule获取一个可执行的G,execute绑定M和G,G的状态设置为_Grunning,gogo执行协程的函数

P:
处理器,提供线程需要的上下文环境,调度等待队列,P本地运行队列最大256
P状态:_Pidle/_Prunning/_Psyscall/_Pgcstop/_Pdead
wakep: 获取一个闲置的P绑定M去执行

schedule:
全局运行队列sched.runq中有待执行的G时,通过schedtick保证有一定几率会从全局运行队列中查找G(globrunqget),从P本地运行队列中查找待执行的G(runqget),如果前两种方法都没有找到G,会通过findrunnable进行阻塞地查找G,网络轮询器中查找,通过runqsteal尝试从其它随机的P中窃取待运行的G,该函数还可能窃取处理器的计时器,gcstopm

netpoll:
当网络请求阻塞时,调度器会让当前阻塞的G放入网络轮询器中,由网络轮询器处理异步网络系统调用,从而让出P执行其它goroutine,
当异步网络调用由网络轮询器完成后,再由sysmon监控线程将其切换回来继续执行

sysmon:
每隔20us~10ms轮询一次,独立于GMP之外,独立的M
监控那些长时间运行的G,设置被强占的标识符,别的G就可以抢先进来执行
检查当前网络轮询器中所有G距离runtime.netpoll被调用是否超过了10ms,将其放入全局运行队列,等待下一次的继续执行
系统调用导致阻塞的话,P的状态为_Psyscall,则会让GM一起切换出去,让P重新找一个GM运行
如果垃圾回收器超过两分钟没有执行的话,sysmon监控线程也会强制进行GC
获取下一个需要被触发的计时器

内存管理:
mheap mspan mcentral mcache mstats TCMalloc
小于32KB,从P上的mcache分配mspan,不需要加锁,为每种类别的mspan维护着一个mcentral
mcentral的作用是为所有mcache提供切分好的mspan资源,每个central会持有一种特定大小的全局mspan列表,mcentral被所有的工作线程共同享有,需要加锁
当mcentral没有空闲的mspan时,会向mheap申请
而mheap没有资源时,会向操作系统申请新内存,mheap主要用于大对象的内存分配,以及管理未切割的mspan
大于32KB,会直接从堆上(mheap)上分配对应的数量的内存页(每页大小是8KB)给程序

newobject:mallocgc
mallocgc:
大于32KB直接在堆上分配,会判断是否要gc,mcache.allocLarge->mheap.alloc->mheap.allocSpan(systemstack)->pageAlloc.allocToCache,pageCache.alloc,mheap.grow,mheap.sysAlloc,linearAlloc.alloc,sysMap+sysUsed,返回mspan

小于32KB在每个P的cache free list分配,0字节直接返回zerobase地址
从P上的mcache分配,mcahce.alloc存放每个级别的mspan,如果mcache上的mspan没有可用空间则调用mcache.refill->mcentral.cacheSpan去获取新的mspan,这个mspan至少有一个未使用的对象,获取到新的mspan后放入mcache.alloc对应级别上,旧的mspan调用mcentral.uncacheSpan放入fullSwept,mheap上的mcentral也是按照级别用数组存放,如果mcentral上也没有则mcentral.grow->mheap.alloc

arena: 64MB
pageSize: 8KB
chunk: 4MB
arenaIndex spanOf *mspan
chunkIndex chunkOf *pallocData

pp.pcache pageCache
mheap.pages pageAlloc
pp.mspancache buf [128]*mspan
mheap.spanalloc fixalloc: 用于分配mspan结构体
mheap.cachealloc fixalloc: 用于分配mcache结构体
mheap.arenas []*[]*heapArena: heapArena存放arena元数据
page allocator
page cache
sweep credit
memstats

mheap.alloc: mheap.reclaim分配前先sweep即将要分配的页数,mheap.allocSpan
mheap.allocSpan: 返回全新的mspan,小内存从P上的pageCache分配,如果P上的pageCache未初始化则调用mheap.pages.allocToCache分配一个pageCache,调用pageCache.alloc分配内存,再从P上的mspancache分配mspan结构体,如果P上没有,调用mheap.pages.alloc分配内存,如果依然没有则调用mheap.grow,mheap.spanalloc.alloc分配mspan结构体,mspan结构体初始化
mheap.grow: 增加npage给heap,mheap.sysAlloc,mheap.pages.grow
mheap.sysAlloc: 返回准备状态的内存区域,分配nbytes的arena空间,更新mheap.arenas元信息,sysReserve,sysMap,更新allArenas
mheap.scavengeAll
mheap.freeSpan: mheap.pages.free释放内存,mspan结构体放回P上的mspancache,如果已满则mheap.spanalloc.free

pageAlloc.grow: pageAlloc.sysGrow
pageAlloc.sysGrow: 更新summary,sysMap
pageAlloc.alloc: 分配npages内存,pageAlloc.find寻找npages内存
pageAlloc.find: 从radix tree查找npages
pageAlloc.free: 释放npages内存
pageAlloc.allocToCache: 如果P上的pageCache是空的调用此方法分配pageCache,返回pageCache
pageCache.alloc: 从P上的pcache(pageCache)分配npages,不加锁

allocmcache
freemcache
mcache.releaseAll
mcache.allocLarge

mcentral.cacheSpan: 返回一个mspan
mcentral.uncacheSpan: 回收一个mspan
mcentral.grow: mheap.alloc从mheap上分配一个mspan

mmap/munmap/msync/mprotect/mremap/mlock/mlock2/munlockmlockall/munlockall
madvise/posix_madvise/posix_fadvise
brk/sbrk/getpagesize
malloc/calloc/realloc/free/posix_memalign/memfd_create

协程栈:
每个goroutine都维护着自己的栈区,栈结构是连续栈,是一块连续的内存,栈区的初始大小是2KB,按照需要增长和收缩,最大1GB
分段栈,栈空间会以双向链表的形式串联起来,如果协程的栈几乎充满,那么任意的函数调用都会触发栈的扩容,当函数返回后又会触发栈的收缩,如果在一个循环中调用函数,栈分配释放造成巨大开销,热分裂问题
连续栈,栈空间不足时,初始化一片比旧栈大两倍的新栈并将原栈中的所有值都迁移到新的栈中,将指向旧栈对应变量的指针重新指向新栈
分配类似堆内存的分配

newstack
stackalloc
stackfree
copystack
shrinkstack
morestack

内存回收gc:
三色标记
开始所有对象都是白色的
遍历根节点(全局变量和栈内变量)集合里的所有根对象,把根对象引用的对象标记为灰色,从白色集合放入灰色集合
遍历灰色集合,将灰色对象引用的对象从白色集合放入灰色集合,之后将此灰色对象放入黑色集合
重复第三步,直到灰色集合中无任何对象
回收白色集合里的所有对象,本次垃圾回收结束
写屏障,在对象新增的同时给它着色为灰色,而所有新创建的对象都会被直接标记成黑色
开启写屏障前和移除写屏障前暂停应用程序
标记准备阶段,暂停程序
标记阶段,根对象入队,开启写屏障,恢复执行程序,开始扫描根对象,扫描协程栈期间会暂停当前处理器,
标记终止阶段,暂停程序
清理阶段,初始化清理状态并关闭写屏障,恢复用户程序,后台并发清理所有的内存管理单元,当goroutine申请新的内存管理单元时就会触发清理
触发时机,内存使用超过某值,超过两分钟,手动GC

setGCPhase,_GCoff/_GCmark/_GCmarktermination
gcStart: 调用时机:mallocgc/runtime.GC/sysmon两分钟唤醒一次forcegchelper,将剩余未清扫的span清扫完成,启动gomaxprocs个gcBgMarkWorker,如果以前启动过就不用重复启动,stopTheWorldWithSema,gcphase设置成_GCmark,gcMarkRootPrepare栈和全局变量入队列,gcMarkTinyAllocs标记小对象为灰色,startTheWorldWithSema
gcBgMarkWorker: 执行gcDrain的协程
gcDrain: 在work buffers里扫描roots和objects,将灰色对象变黑,直到所有工作都做完,GC结束前返回,循环调用markroot,循环调用scanobject,gcFlushBgCredit
markroot: flushmcache,markrootBlock,scanblock,markrootFreeGStacks,markrootSpans,scanstack
scanobject: 调用greyobject
scanblock: 类似scanobject,scan non-heap roots,调用greyobject
scanstack: 调用前需要suspendG,调用后需要resumeG,扫描G的栈,栈上的指针都变成灰色,调用scanblock
greyobject: 通过位操作设置为灰色
gcMarkDone
gcMarkTermination: gcphase设置成_GCmarktermination,gcphase设置成_GCoff
gcMark
gcSweep: 在gcMarkTermination里调用,结尾处唤醒bgsweep
gcWaitOnMark: 等待mark阶段结束,如果当前处于mark阶段当前G就gopark,等待在gcMarkTermination里唤醒该G
sweepone: 清扫span,返回清扫的页数,没可清扫的返回^0,nextSpanForSweep找到需要sweep的span,调用mspan.sweep,如果清扫完会激活新一轮的scavenge
mspan.sweep: 清扫单个堆span
mspan.init
bgsweep: 循环调用sweepone
bgscavenge: sweep结束会唤醒此G,循环调用mheap.pages.(pageAlloc).scavenge
scanframeworker
gcAssistAlloc
stackpoolfree

sync.Map:
通过互斥锁和原子操作来实现近似无锁,空间换时间,延迟删除,删除一个键值只是打标记,只有在迁移dirty数据的时候才清理删除的数据,readOnly向dirty拷贝是遍历,不适合大数据场景
不加锁: 读/删一个存在readOnly中的key,写一个存在readOnly中的key并且没有标记删除
加锁: 增加新key会加锁,新key先放dirty,不适合频繁增加数据

sync.Mutex:
CAS+原子操作
正常模式: 等待者们以先进先出的顺序排队,排在最前面的等待者不一定能获得下一次的锁,比如在某个时刻,醒着的等待者与一个新到达的G竞争所有权,由于新到达的G一直在CPU上运行,此时这个醒着的等待者有很大的概率失去锁,在这种情况下,它就在等待队列的前面排队着,如果一个等待者没有获得锁超过1ms,就会切换到饥饿模式;正常模式会有好的性能在一个协程能多次获得一把锁,即使有阻塞的等待者
饥饿模式: 锁的所有权直接从未锁的协程推给队列前面的等待者,新到达的协程不会尝试获得锁,并且不会尝试自旋,它们会排在队列的尾端,如果一个等待者拿到了所有权,并且它看到了它是队列的最后一个或者它等待的时间小于1ms,切换到正常模式;饥饿模式是为了防止严重的尾端延迟情况
进入自旋的条件,非饥饿模式,自旋次数小于4,cpu大于1,空闲的P+自旋的M+1小于总P,当前P的runq是空的,执行PAUSE命令,自旋30次
如果不进入自旋接下来就会阻塞在信号量,放入队列,执行gopark,_Grunning->_Gwaiting,unlock时调用goready唤醒阻塞的协程,_Gwaiting->_Grunnable

sync.RWMutex:
使用Mutex和信号量实现
获得读锁,如果之前有读锁那么直接获得锁,如果之前有写锁那么阻塞在读信号量队列上,当释放写锁时唤醒读信号量队列上所有的读锁
获得写锁,如果之前有写锁那么直接阻塞在互斥量上,如果之前有读锁,那么阻塞在写信号量上,当释放最后一个读锁时唤醒写信号量

sync.Once:
CAS+mutex
首先原子判断done是不是0,如果不是0就直接返回,如果是0就代表未执行过,这时先加锁,再次判断done是不是0,不是0就代表被其它同时运行的G执行了直接退出,是0的话就执行fn再原子设置done为1

sync.WaitGroup:
Add: 支持加负数,检测到v等于0并且等待者不等于0就去释放所有等待者的信号量
Done: Add(-1)
Wait: 原子增加等待者的数量+1,协程进入信号量阻塞

sync.Cond:
用法: 先上锁,Wait,解锁
Wait: 先解锁,协程睡眠,等待被唤醒,再上锁
Signal: 唤醒单个等待者
Broadcast: 唤醒所有等待者

sync.Pool:
Get,P先去private找,如果private是空则去本地池查找,如果自己没有就去其它P偷过来一些,如果还是没有就去本地池victim取,如果都没有就New一个
Put,P操作本地池,数据放入一个双向链表,每个链表节点存储容量以2倍递增
gc前的STW执行注册的回调函数用于清理一代的缓存,原本的victim赋值nil去除对内存的引用,local赋值给victim
禁止G被抢占,false sharing问题的避免

atomic:
锁住变量的地址不允许其它cpu操作
通过指令实现原子操作,LOCK
ANDL/ORL/ANDB/ORB
StoreInt64 XCHGQ
LoadInt64 *ptr
AddInt64 XADDQ
CompareAndSwapInt64 CMPXCHGQ
SwapInt64 XCHGQ
MESI缓存一致性协议

return:
不带命名的返回参数会默认加r0...rn的名称,函数返回时需要给这些变量赋值
带命名的返回参数:
return后面什么都不加,等同于,return后面加返回值里的变量;
return后面加非返回值里的变量,先给这个函数返回值变量赋值再返回;

defer:
先进后出;defer无法改变已经return的变量,除非该变量在函数的返回值里申明
deferprocStack&deferreturn
先执行return再执行defer
defer函数的入参取决于执行到defer那一行时是什么值,入参放在deferprocStack函数入参_defer结构体的下面位置
gp._defer,defer以链表的形式存储

panic&recover:
只能recover本协程内的panic
gopanic&gorecover
数组切片越界;nil指针野指针;往已经close的chan里发送数据;并发读写相同map;interface{}断言未接收第二个返回值
gp._panic,panic以链表的形式存储
多个panic,recover的时候只返回最新的一个(链表头部)

闭包函数:
定义在一个函数内部的函数,闭包是将函数内部和函数外部连接起来的桥梁,局部变量变成全局变量

unsafe&uintptr:
unsafe.Pointer和uintptr可以相互转化
unsafe.Pointer不能加减
uintptr可以加减
uintptr对对象已经无引用,对象可能随时被回收;除非是系统调用传进去的uintptr,编译器做了处理对象不会被回收
普通变量取址也不能进行加减

copy:
第一个参数只能是slice,第二个参数可以是slice和string
nil:
nil不是关键字;nil可作为变量名;nil是没有默认类型的在使用它时必须要提供足够的信息能够让编译器推断nil期望的类型
iota:
只能和const一起使用;每当const出现时都会使iota初始化为0;const中每新增一行常量声明将使iota计数一次;默认int型

内存对齐:
不是所有的硬件平台都能访问任意地址上的任意数据,为了访问未对齐的内存,处理器需要作两次内存访问,而对齐的内存访问仅需要一次访问
计算机只能从4/8的倍数开始读数据,不能随便从一个地址读数据
结构体嵌套空结构体的情况,空结构体在最前面/中间不占字节,在最后会被填充对齐到前一个字段的大小

内存逃逸:
编译阶段确定;大内存优先分配在堆上/分配的大小不确定;变量在函数返回后还可能被使用,闭包,返回指针;造成gc压力变大
go build -gcflags "-m -m" main.go
go tool compile -m main.go

位运算:
&: 与AND
|: 或OR
^: 异或XOR,作为一元运算符时表示位反或位补,等价m^n,m所有位都是1
&^: 位清空AND NOT,运算符左边数据与右边数据相异的位保留,相同位清零,0&^0=0  0&^1=0  1&^0=1  1&^1=0;如果右侧是0,则左侧数保持不变;如果右侧是1,则左侧数一定清零
>>: 左移
<<: 右移
原码: 符号位加真值的绝对值
反码: 无符号数和正数的反码是其本身,负数的反码是将原码除符号位外的其他位按位取反,即0变1,1变0
补码: 无符号数和正数的补码是其本身,负数的补码是反码二进制加1
为了让符号位参与基本预算,产生了反码
为了解决反码运算后产生-0的问题产生了补码
计算机实际用补码参与运算,获得的结果需要转换成原码

性能优化:
pprof:
net/http/pprof runtime/pprof
go tool pprof http://localhost:6060/debug/pprof/heap
go tool pprof http://localhost:6060/debug/pprof/profile
go tool pprof http://localhost:6060/debug/pprof/goroutine
go tool pprof demo demo.prof
go tool pprof -http 0.0.0.0:8080 http://localhost:6060/debug/pprof/profile
能查到哪个函数分配的内存高
能查到哪个函数占用cpu高
火焰图
调用链,每个函数的耗时和占比

dlv:
查看函数参数、打印变量、单步执行、查看所有协程
dlv exec ./hello
设置断点
break /usr/local/go/src/runtime/os_linux.go:71
break main.go:35
打印所有断点 breakpoints
继续执行到下一个断点 continue
执行下一行 next
执行下个指令(更细) step
局部变量 locals var1
打印变量 print var1
strace -ff ./test1

Benchmark:
go test -bench .
go test -bench=. -cpuprofile=cpu.prof
go test -bench=. -memprofile=mem.prof
go tool pprof -http 0.0.0.0:8080 cpu.prof

trace:
curl -o app.trace http://localhost:6060/debug/pprof/trace
go tool trace -http 0.0.0.0:8080 performance app.trace
可以查看每个协程在哪耗时大

test:
go test -coverprofile=test.out
go tool cover -html=test.out -o cover.html
go test -run=FuzzReverse
go test -fuzz=Fuzz
go test -run=FuzzReverse/8fe4afa715c62ebbf52961c12d500dda471293a8d663e527b1f89032f1956f5f
go test -fuzz=Fuzz -fuzztime 30s

汇编plan9:
go tool compile -N -l -S main.go //打印汇编 生成.o
go run -gcflags "-N -l" main.go
go build -gcflags "-N -l" main.go
go build -gcflags=all="-N -l" main.go
go tool objdump -s do1 main.o
静态单赋值SSA GOSSAFUNC=do1 go build main.go
中间代码

tool:
go env -w GO111MODULE=on
go tool fix main.go //golang.org/x/net/context --> context
go fmt main.go
go vet main.go //检查基本错误如语法错误 fmt.Printf("%s", 12)
go tool asm main.s //.s --> .o
go tool link main.o //链接
readelf -w a.out
addr2line -e a.out
go tool nm main.o
go tool pack c file.a main.go
//go:noinline //go:nosplit //go:noescape //go:linkname //go:notinheap //go:norace
//go:generate stringer -type=Life
插件: go build -buildmode=plugin add.go

runtime
反射reflect
定时器
gin/beego/grpc/Restful/fasthttp
cgo


2.MySQL
聚族索引和非聚族索引
覆盖索引
前缀索引
主键索引 普通索引 唯一索引 联合索引 全文索引
InnoDB和MyISAM
索引B树和B+树
B树的所有节点既存放键(key)也存放数据(data),而B+树只有叶子节点存放key和data,其他内节点只存放key
B+树的叶子节点有一条引用链指向与它相邻的叶子节点

执行流程
mvcc 快照读 当前读 ReadView
隔离级别 读取未提交 读取已提交 可重复读 可串行化

InnoDB 通过数据行的 DB_TRX_ID 和 Read View 来判断数据的可见性
DB_TRX_ID(6字节): 表示最后一次插入或更新该行的事务 id
DB_ROLL_PTR(7字节): 回滚指针，指向该行的 undo log
DB_ROW_ID(6字节): 如果没有设置主键且该表没有唯一非空索引时，InnoDB会使用该id来生成聚簇索引

redo log
undo log
binlog
relay log

Record lock 记录锁 单条索引记录上加锁
Gap lock 间隙锁 锁住一个索引区间(开区间,不包括双端端点) 防止幻读,保证索引间的不会被插入数据
Next-key lock 临键锁 = Gap Lock + Record Lock 为了解决幻读 左开右闭区间
自增锁
意向锁 意向共享锁IS 意向排它锁IX 表级别锁
插入意向锁: 间隙锁的一种,专门针对insert操作,多个事务在同一个索引同一个范围区间插入记录时候,如果插入位置不冲突,不会彼此阻塞
select ... lock in share mode  S锁 共享锁
select ... for update X锁 排他锁

ACID 原子性 一致性 隔离性 持久性

脏读
幻读
不可重复读

回表

连接器 查询缓存、分析器、优化器、执行器

Buffer Pool
redo log buffer

分库分表
主从复制
读写分离

数据库三范式: 每列保持原子性 每列都和主键相关 每一列数据都和主键直接相关而不能间接相关
MySQL死锁

TIMESTAMP: 把客户端插入的时间从当前时区转化为UTC,查询时将其又转化为客户端当前时区进行返回;'1970-01-01 00:00:01.000000'to'2038-01-19 03:14:07.999999';插入NULL会自动赋值当前时间;4个字节;相对快
DATETIME: 原样输入和输出;'1000-01-01 00:00:00.000000'to'9999-12-31 23:59:59.999999';插入NULL就是NULL;8个字节;相对慢

utf8是1字符3字节,gbk是1字符2字节
utf8mb4的编码,mb4就是most bytes 4的意思,专门用来兼容四字节的unicode,好在utf8mb4是utf8的超集,除了将编码改为utf8mb4外不需要做其他转换
CHAR: 字符数而不是字节数;最大值为255字符;长度固定;速度快;CHAR(M)每个值都占用M个字节,如果某个长度小于M就会在它的右边用空格字符补足;
VARCHAR: 字符数而不是字节数;最大值为65535字节;可变长;速度慢;VARCHAR(M)每个值只占用刚好够用的字节再加上一个用来记录其长度的字节;
TEXT: 申明时不设置最大长度;最大65535字节;最慢
BLOB: 二进制

LIMIT: LIMIT offset,n; LIMIT n; LIMIT n OFFSET offset;
GROUP BY
ORDER BY ASC/DESC
INNER JOIN/LEFT JOIN/RIGHT JOIN/CROSS JOIN/OUTER JOIN
LIKE
UNION
COUNT/SUM/AVG/MAX/MIN
DISTINCT
HAVING
USING
IS NULL/IS NOT NULL
IN/NOT IN
BETWEEN
AS
EXISTS
存储过程
定时任务


3.NoSQL
MongoDB
LevelDB
TiDB

ElasticSearch:
Shard/Replica 倒排索引 master/data/ingest/coodrinating only
Logstash/Kibana/filebeat/Flume

Etcd/ZooKeeper/Nacos/Consul
Ceph
Nginx
Keepalived/Haproxy/LVS
Promethous/Grafana
MinIO


4.Redis
string SDS 长度不能超过512M int编码 raw编码 embstr编码
hash hashtable ziplist(列表保存元素个数小于512个&每个元素长度小于64字节)
list linkedlist ziplist(列表保存元素个数小于512个&每个元素长度小于64字节)
set hashtable intset(集合对象中所有元素都是整数&集合对象所有元素数量不超过512)
zset skiplist&字典 ziplist(保存的元素数量小于128&每个元素长度小于64字节)

AOF
RDB 快照 save&bgsave dump.rdb
RDB在恢复大数据集时的速度比AOF的恢复速度要快

HyperLogLog
PUB/SUB
事务 MULTI EXEC DISCARD UNWATCH WATCH
Lua EVAL "return {KEYS[1],KEYS[2],ARGV[1],ARGV[2]}" 2 key1 key2 first second
Redis GEO
Redis Stream
Redis Pipeline
Redis Bitmap

redis缓存击穿(热点key不失效或加锁)、缓存穿透(不存在的key设置空value和过期时间)、缓存雪崩(key失效时间不同)

redis和mysql数据一致性保证:
强一致性 弱一致性 最终一致性
Pattern: Cache-Aside/旁路缓存模式 Read-Through/Write-Through/读写穿透 Write-Behind/异步缓存写入
延时双删: 先删除缓存 再更新数据库 休眠一会再次删除缓存
同步binlog

读操作:
读到缓存直接返回
读不到缓存,先去DB读数据,再更新到缓存,再返回
写操作:
先写DB,删除缓存
问题:
A读了数据库还未更新缓存
B修改数据库
A再去更新缓存
数据不一致
解决办法加短的过期时间

单节点
主从 replicaof 127.0.0.1 7000
redis cluster
redis cluster+主从
主从+哨兵

daemonize yes
bind 127.0.0.1
port 7000
dir /home/thomas/server/redis/data/redis-7000
pidfile /var/run/redis/redis-7000.pid
logfile /home/thomas/server/redis/log/redis-7000.log
cluster-enabled yes
cluster-config-file /home/thomas/server/redis/conf/cluster-7000.conf
cluster-node-timeout 10000

rm -rf cluster data log
mkdir cluster data log
mkdir data/redis-7000 data/redis-7001 data/redis-7002 data/redis-8000 data/redis-8001 data/redis-8002 data/sentinel-9000 data/sentinel-9001 data/sentinel-9002

./redis-server /home/thomas/server/redis/conf/redis-7000.conf
./redis-cli -p 7000
./redis-cli --cluster create 127.0.0.1:7000 127.0.0.1:7001 127.0.0.1:7002
./redis-cli -c -p 7000
./redis-cli --cluster check 127.0.0.1:7000
./redis-cli --cluster reshard 127.0.0.1:7000
./redis-cli -p 7000 cluster nodes
./redis-cli --cluster add-node 127.0.0.1:7003 127.0.0.1:7000
./redis-cli --cluster add-node 127.0.0.1:8000 127.0.0.1:7000 --cluster-slave
./redis-cli --cluster add-node 127.0.0.1:8001 127.0.0.1:7000 --cluster-slave --cluster-master-id 7f3541c3b2e8bd05226729e9889a338b341cd77e
./redis-cli --cluster del-node 127.0.0.1:7000 3adfaaeb6d60f39e70562d961fe7fae200913386

port 9000
daemonize yes
logfile /home/thomas/server/redis/log/sentinel-9000.log
pidfile /var/run/redis/sentinel-9000.pid
dir /home/thomas/server/redis/data/sentinel-9000

sentinel monitor mymaster 127.0.0.1 7000 2
sentinel down-after-milliseconds mymaster 1500
sentinel failover-timeout mymaster 30000

./redis-sentinel /home/thomas/server/redis/conf/sentinel-9000.conf
./redis-cli -p 9000
sentinel master mymaster


5.MQ 异步/解耦/削峰
Kafka
消息永久保存,定期删除
topic partition ISR/OSR/AR
pull方式消费消息

Consumer Group:
多个消费者组成一个group,组内的所有消费者协调在一起来消费订阅主题的所有分区,每个分区只能由同一个消费组内的一个consumer来消费,避免重复消费,
记录offset到__consumer_offsets kafka自带的topic(记录到具体哪个分区hash(groupID) % numPartitions)

自动提交/手动提交: enable.auto.commit = true

Rebalance:
组成员发生变更/订阅主题数发生变更/订阅主题的分区数发生变更
coordinator来执行对于consumer group的管理,从consumer group选出一个leader并且generation+1,leader生成具体消费方案,leader把生成的方案发给coordinator,coordinator再同步给所有consumer
Heartbeat请求: consumer需要定期给coordinator发送心跳来表明自己还活着
LeaveGroup请求: 主动告诉coordinator我要离开consumer group
SyncGroup请求: group leader把分配方案发给coordinator,coordinator再告诉组内所有成员
JoinGroup请求: 成员请求加入组
DescribeGroup请求: 显示组的所有信息，包括成员信息，协议名称，分配方案，订阅信息等。通常该请求是给管理员使用

生产者幂等性:
ProducerID(每个新的Producer在初始化的时候会被分配一个唯一的PID)
SequenceNumber(对于每个PID,该Producer发送数据的每个<Topic,Partition>都对应一个从0开始单调递增的SequenceNumber)
只能保证单个partition内的幂等性,只能保证Producer在单个会话内不丟不重

事务:
涉及到多个Topic-Partition的写入时,这个事务操作要么会全部成功,要么会全部失败
initTransactions beginTransaction commitTransaction/abortTransaction
transactionalID由用户提供,和ProducerID+epoch组成唯一值
TransactionCoordinator __transaction_state
isolation.level read_committed/read_uncommitted
LEO: 日志末端位移(log end offset),最后一条消息的下一条消息的位移值
HW: 水位值,HW值不会大于LEO值,小于等于HW值的所有消息都被认为是已备份的,consumer无法消费分区下leader副本中位移值大于分区HW的任何消息,Kafka使用HW值来决定副本备份的进度
LSO:

log:
每个partition都有一个目录,里面有很多segment file
partition的第一个segment从0开始,后续每个segment文件名为上一个segment文件最后一条消息的offset
.index 文件名是消息总偏移 内容: 消息偏移(每个index都从0开始,稀疏索引,不是连续的)+字节偏移offset
.log
.timeindex CreateTime表示producer创建这条消息的时间,LogAppendTime leader broker将这条消息写入到log的时间

RabbitMQ
消息消费完就删除
AMQP/高级消息队列协议
routing-key/路由
交换器/Exchange: direct/fanout/topic/headers
支持pull、push方式消费消息

消息丢失:
生产者 事务(同步阻塞慢) 发送确认(异步快)(确认成功就在数据库设置标记,否则重新发送消息,未确认的消息也可存在内存/本地磁盘/redis)
broker 持久化Exchange、Queue、Message
消费者 改为手动提交(自动提交在broker发送消息到消费端就会删除) autoAck=false

死信交换机/死信队列:
默认情况下queue中被抛弃的消息将被直接丢掉,但是可以通过设置queue的x-dead-letter-exchange参数将被抛弃的消息发送到指定的exchange中
消费方nack/reject时指定了requeue=false、消息的TTL已到、消息队列的max-length已到
设置队列中所有消息的过期时间x-message-ttl,队列最大消息数x-max-length,生产者设置单个消息的expiration
Alternate Exchange: 发送消息的时候根据routing-key没有对应的队列接受消息,这就会将此消息路由到Alternate Exchange属性指定的Exchange上了,如果mandatory=true则会将消息返回给生产者
如果发送到A消费者的消息一直不确认,只有等到A消费者与rabbitmq的连接中断,rabbitmq才会考虑将A消费者未确认的消息重新投递给另一个消费者

Ack: 确认后删除消息; Reject: 只能拒绝一个; Nack: 可以拒绝多个

Message:
expiration 消息的过期时刻
deliveryMode 1为非持久化,2为持久化
Queue:
durable 持久化
exclusive 该队列仅对首次声明他它的连接可见,并在连接断开时自动删除
autoDelete 所有与这个连接的消费者都断开时会自动删除
Exchange:
durability 持久化
autoDelete 与这个Exchange绑定的Queue或Exchange都与此解绑时,会删除本交换器

requeue重新放入队列,是立即可以再次消费还是等多长时间?
没有ack后多久可以再次消费此消息?

集群:
普通集群 队列只会存在一个节点,存在哪个节点,是固定的一个还是随机分散?
镜像队列 主从模式,针对的是队列不是节点,push操作会在主从的每个节点上执行一次,消费操作在master执行然后广播给每个slave;
        新增加一个节点需要配置才会同步master所有数据,并且同步时会阻塞

延时队列: 死信队列+ttl 插件rabbitmq-delayed-message-exchange
优先队列: 队列设置的x-max-priority,消息设置队列设置的priority,优先级越大越先消费

事务:
txSelect txComment txRollback

RocketMQ
消息永久保存,定期删除
支持pull、push方式消费消息
NameServer: 路由控制中心,NameServer之间没有数据同步,Broker上报信息到NameServer
Broker: 多主多从,只有主Broker节点才能写,当master宕机,master上的队列不可写入,但是读取依然是可以的
生产消息: SendSync/SendAsync/SendOneWay

Topic:
主题,创建topic时指定读写队列数量,可以指定broker创建也可以让集群自动分配
mqadmin updateTopic
mqadmin deleteTopic
mqadmin updateSubGroup
mqadmin deleteSubGroup
mqadmin updateTopicPerm
mqadmin consumerProgress
writeQueueNums/readQueueNum: 方便队列的缩容和扩容

Tag: 子主题
GroupName: 生产者组合或消费者组合
ProducerGroup: 
ConsumerGroup: 一个Queue最多只能分配给一个Consumer

主从:
slave向master报告自己的最大偏移量
master向slave返回偏移量后的CommitLog数据
brokerId=0表明这个broker是master,brokerId>0表明这个broker是slave
slave只负责读,rocketmq目前还不支持主从切换,需要手动切换
正常情况下consumer并不能配置从master读还是slave读,本次拉取的数据量大于物理内存的40%和当master不可用或者繁忙的时候consumer会从slave读
master可配置同步复制SYNC_MASTER/异步复制ASYNC_MASTER

Rebalance: 
订阅Topic的队列数量变化(broker宕机、队列扩容/缩容)/消费者组信息变化(消费者宕机、消费者扩容/缩容、Topic订阅信息发生变化)
一个队列最多分配给一个消费者,offset是异步提交造成重复消费,Broker端负责Rebalance元数据维护
周期性触发rebalance
同一个消费者组订阅多个Topic时可能会出现分配不均
对Topic队列/消费者各自进行排序,每个消费者需要使用相同的分配策略

广播消费:
广播模式消费位移使用本地文件存储,Rebalance过程中同一个ConsumeGroup下的consumer不会进行MessageQueue的分配,每个consumer负责订阅的topic下的所有MessageQueue

log:
commitLog存消息数据
consumeQueue存索引
config存Group/Topic/Consumer消费的offset
超时时间/磁盘占比/人工删除触发删除commitLog/consumeQueue

offset: 当消费模式为广播模式时offset使用本地模式存储;集群模式下存在config
消息堆积: 增加consumer;放到临时的topic再增加新的consumer去消费

延时队列:
生产消息时设置,只能选择1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h(可以改配置文件增加level),level从1开始;消息按照延迟时间段发送到指定的延时队列(SCHEDULE_TOPIC_XXXX)中,定时器进行轮训这些队列查看消息是否到期,如果到期就把这个消息发送到指定topic的队列中,这样的好处是同一队列中的消息延时时间是一致的,还有一个好处是这个队列中的消息是按照消息到期时间进行递增排序的,然后把延迟队列中的消息删除

死信队列:
%DLQ%+consumerGroup
消费失败自动进行消息重试,达到最大重试次数后将其发送到该消费者对应的特殊队列中,有效期与正常消息相同到期自动删除
一个死信队列对应一个GroupID

重试:
广播消息是不会重试的
生产端重试: 生产端自动重试,可设置超时时间和重试次数,异步发送重试次数只有1/0次
消费端重试: 主动返回RECONSUME_LATER消息会进入重试队列,超过最大重试次数就进入死信队列;超时重试是直接重试不需要延时,会一直重试下去;message携带重试次数消费端可以用来判断
重试队列: 先保存到SCHEDULE_TOPIC_XXXX中,再设置偏移量,后台定时任务按照对应的时间进行Delay后重新保存至%RETRY%+consumerGroup重试队列中,消费者消费重试队列

事务:
prepare阶段
commit/rollback阶段

ActiveMQ
JMS
kahadb leveldb mysql
topic
P2P: 生产者向队列投递一条消息,只有一个消费者能够监听得到这条消息
Pub/Sub: 生产者向队列投递一条消息,所有监听该队列的消费者都能够监听得到这条消息
与zookeeper进行构建主备集群模型
Network集群模型

Pulsar

优先队列
延时队列
消息丢失
重复消费 幂等
顺序消费
消息堆积
事务


6.网络/TCP/IP/UDP
物理层
数据链路层 ARP RARP
网络层 IP ICMP IGMP
传输层 TCP UDP
应用层 HTTP FTP TFTP SMTP DNS

三次握手 避免重复连接
四次挥手
粘包
DDOS
半连接队列
全连接队列

最大传输单元(MTU) 1500字节
MSS （最大报文段长度）536

SYN Flood
Syn Cache: 不直接分配TCB,使用更少的数据记录状态
Syn Cookie: 无状态的三次握手
cookie源认证: 记录sequence number,将真实客户端IP加入白名单
reset认证: reset报文,将真实客户端IP加入白名单

慢启动 慢启动门限(ssthresh) 65536 指数增长
拥塞避免 线性增长 重传了一个报文段 ssthresh=cwnd/2 cwnd=1 进入慢启动
快速重传 收到3个相同的ACK ssthresh=cwnd/2 cwnd=ssthresh 进入拥塞避免
快速恢复
窗口值的大小就代表能够发送出去的但还没有收到ACK的最大数据报文段
拥塞窗口(cwnd)
接收窗口(rwnd)


7.HTTP HTTP2 TLS/SSL
状态码:
200 请求成功
301 资源（网页等）被永久转移到其它URL

1xx 信息响应
2xx 成功响应
3xx 重定向
4xx 客户端错误
5xx 服务器错误

301 MovedPermanently 永久移动
302 Found 临时移动,与301类似,但资源只是临时被移动,客户端应继续使用原有URI

400 Bad Request
401 Unauthorized
403 Forbidden
404 请求的资源（网页等）不存在

500 InternalServerError
501 NotImplemented
502 BadGateway
503 ServiceUnavailable
504 GatewayTimeout
505 HTTPVersionNotSupported

包含请求方法、URI、HTTP版本信息
header
body

包含HTTP版本、状态码、状态码的原因短语
header
body

HTTP 2.0 和 HTTP1.1 区别
多路复用 二进制分帧层
首部压缩
HTTP2支持服务器推送

跨域CORS 同源策略 JSONP
CSRF/XSRF XSS
JWT Session Token
SSRF:
由攻击者构造形成由服务端发起请求的一个安全漏洞,一般情况下,SSRF攻击的目标是从外网无法访问的内部系统,正是因为它是由服务端发起的所以它能够请求到与它相连而与外网隔离的内部系统
形成的原因大都是由于服务端提供了从其他服务器应用获取数据的功能且没有对目标地址做过滤与限制,比如从指定URL地址获取网页文本内容,加载指定地址的图片,下载


8.Kubernetes
Pod Deployment Service DaemonSet StatefulSet ReplicaSet Job Label Namespace ConfigMap Secret Ingress
Volume PersistentVolume PersistentVolumeClaim StorageClass
kube-apiserver etcd kube-scheduler kube-controller-manager kubelet kube-proxy


9.微服务/服务网格
服务注册发现
链路追踪
Istio/Serverless


10.分布式
CAP
高并发
高可用
事务

唯一ID:
Snowflake,64位,第1位默认为0,接下来前41位是毫秒数时间戳,接下来的10位代表计算机ID,其余12位代表每台机器上生成ID的序列号
Uidgenerator
Leaf

限流 漏桶算法 令牌桶算法
熔断
降级
灾备
异地多活
Sentinel
秒杀
2PC/3PC/TCC
Raft/Paxos
CDN
SLB

11.操作系统
Reactor线程模型
汇编

linux:
sysconf/fpathconf/pathconf/confstr
gettimeofday/settimeofday
date/time/ctime/ftime
adjtime/adjtimex/clock_adjtime/ntp_adjtime
clock_gettime/clock_settime/clock_getres:根据clockid获取时间/设置时间/获取精确度
clock_getcpuclockid/pthread_getcpuclockid
getrlimit/setrlimit/prlimit

进程:
栈、堆
fork/vfork/clone
进程地址空间
进程池
execl/execlp/execle/execv/execvp/execvpe/execve
wait/waitpid/waitid/wait3/wait4
exit/_exit/_Exit/exit_group/on_exit/atexit
gdb/strace/ptrace
prctl/seccomp
getrusage
system
getpid/getppid
getcontext/setcontext/makecontext/swapcontext

进程调度:

线程:
轻量级进程,PCB/TCB,task_struct/thread_info/内核栈,slab分配器,线程有自己独立的内核栈
创建进程和线程底层都是调用clone系统调用,fork创建进程时clone不传参数则创建一个完整的进程,pthread_create创建线程时clone会传一些参数,共享地址空间
线程池
线程私有变量,pthread_key_create/pthread_setspecific/pthread_getspecific/pthread_key_delete
gettid
pthread_self

内存管理:
malloc/realloc/calloc/free/mmap
内存碎片
内存池
虚拟内存
页缓存和块缓存,页面回收和页交换,缺页中断
物理内存管理
MMU
slab分配器
多级cache L1 L2 L3

进程间通信IPC:
管道 命名管道FIFO 共享内存 消息队列 信号 UNIX域 socket DBUS
eventfd:把内存当文件,实际内部是一个8字节的计数器,read之后计数会清零,write则会递增计数器,如果计数器是0则不会通知可读

同步机制:
信号量 互斥量 条件变量 读写锁 自旋锁

futex: Fast userspace mutexes, 是一种用户态和内核态混合的同步机制,同步的进程间通过mmap共享一段内存,futex变量就位于这段共享的内存中且操作是原子的,当进程尝试进入互斥区或者退出互斥区的时候,先去查看共享内存中的futex变量,如果没有竞争发生则只修改futex而不用再执行系统调用了,当通过访问futex变量告诉进程有竞争发生,则还是得执行系统调用去完成相应的处理

文件系统:
vfs
ext3/ext4
fuse
statfs/fstatfs/stat/fstat/lstat/fstatat/statvfs/fstatvfs
readlink/readlinkat/symlink/symlinkat
access
chmod/fchmod/fchmodat/chown/fchown/lchown/fchownat
utime/utimes
realpath/getcwd/getwd/get_current_dir_name
chroot/chdir
open/read/write

IO多路复用:
poll select epoll

网络协议栈:
netfilter

设备驱动:
字符设备
块设备
网卡设备

系统调用

信号:
软中断 kill -l
kill 1234,默认SIGTERM,可以捕捉
kill -9 1234,SIGKILL,终止程序,不可捕捉
ctrl+c产生SIGINT默认反应是进程终止,可以捕捉
对于需要处理的信号,进程可以指定处理函数,由该函数来处理;也可以忽略某个信号;也可以对该信号的处理保留系统的默认值,大部分的信号缺省操作是使得进程终止
通过系统调用signal来指定进程对某个信号的处理行为
SIGSTOP只是要求进程暂时停下手头的工作,休息一下,直到听到SIGCONT的召唤
SIGKILL/SIGSTOP不能捕捉和忽略
SIGCHLD默认忽略
两个信号同时到达,同一种信号只能等前面的先执行完再执行后到的且相同的信号只保留一个,不同信号可以同时执行
fork子进程可以继承父进程的信号,execve时会把信号恢复到默认行为,已忽略的信号则可以完全地继承

当内核接收到信号后,会将其放到对应进程的信号队列中,同时向进程发送一个中断,使其陷入内核态
进程从内核态返回到用户态前进行信号检测,或者进程在内核态中,从睡眠状态被唤醒的时候进行信号检测
内核将当前内核栈的内容拷贝到用户栈上,并且修改指令寄存器eip将其指向信号处理函数
接下来进程返回到用户态中,执行相应的信号处理函数
信号处理函数执行完成后,还需要返回内核态,检查是否还有其它信号未处理
如果所有信号都处理完成,就会将内核栈恢复,从用户栈拷贝回来,同时恢复指令寄存器eip将其指向中断前的运行位置,最后回到用户态继续执行进程

设置信号处理函数,signal/sigaction,发送信号kill,向自己发信号raise,向线程发送信号,tkill,tgkill
signal:第一个参数是信号值1-64,第二个参数可以设置三种行为SIG_IGN/SIG_DFL/handler
signalfd:文件描述符接收信号,不接收SIGKILL/SIGSTOP
alarm/ualarm:定时多少秒后发送信号SIGALRM,默认终止进程,返回值是上一个alarm剩余的秒数,后一个alarm覆盖前一个alarm,alarm(0)会清除之前所有的alarm
sleep/usleep/nanosleep/clock_nanosleep:调用线程进入睡眠直到指定秒之后,如果有未忽略的信号到来则提前退出并返回剩余睡眠的秒数,如果是忽略的信号到来则不影响sleep,如果是信号的默认行为则取决于默认行为是什么
pause:调用进程/线程进入睡眠直到捕捉到信号并且信号处理函数返回
abort:即使捕捉信号进程也会终止
pthread_kill:类似kill,给线程发信号
sigaction:signal的升级版
sigprocmask/pthread_sigmask:阻塞信号;如果当前是阻塞状态,并且同一个信号发送了多次,当阻塞解除时只响应一个信号;函数本身不阻塞
sigpending:查询当前哪些信号处于pending状态
sigemptyset/sigfillset/sigaddset/sigdelset/sigismember:对sigset_t进行操作
sigsuspend:阻塞指定信号,即使接收到该信号也不返回,接收到其它信号才会返回,当sigsuspend返回后自动恢复mask成原来的值,指定信号在阻塞解除后会响应一次,保护不希望由信号中断的代码临界区
sigqueue/pthread_sigqueue:发送信号给指定pid,可以携带数据,sigqueue函数对不可靠信号不做排队,会丢失信号,kill只是单纯的递送对谁都不排队
sigwait/sigwaitinfo/sigtimedwait:阻塞指定信号,直到发现该信号是pending则返回,收到其它信号不返回
setitimer/getitimer:设置定时器,可重复执行定时任务,三种类型ITIMER_REAL/ITIMER_VIRTUAL统计进程的用户时间/ITIMER_PROF统计进程的用户时间和内核时间,对应信号SIGALRM/SIGVTALRM/SIGPROF
timer_create/timer_settime/timer_gettime/timer_getoverrun/timer_delete:创建定时器,通过信号来通知定时器到来
timerfd_create/timerfd_settime/timerfd_gettime:定时器,不会被信号影响
sigsetjmp/siglongjmp/longjmp/setjmp:调用setjmp的函数返回了上下文将变成无效,longjmp第二个参数成为setjmp的返回值
sigaltstack:设置额外的信号栈,用于执行信号处理函数
siginterrupt:系统调用被信号中断,可以重新开始(默认)/返回EINTR/如果有数据传输就返回传输成功的字节数
sigreturn:从信号处理函数返回,并清除栈帧

中断

常用命令:
cd mkdir rm grep find ln
netstat tcpdump lsof ifconfig
iostat fdisk du df iotop
free vmstat sar
top htop strace perf 


12.算法
栈/队列
排序
二叉树/平衡二叉树/红黑树
链表
动态规划
图
缓存LRU/LFU
字符串
radix tree

13.其它
utf-8:
Unicode只是一个符号集,它只规定了符号的二进制代码,却没有规定这个二进制代码应该如何存储,“严”的unicode是十六进制数U+4E25
utf-8是变长的编码方式,使用1~4个字节表示一个符号,utf-8编码方式:
0xxxxxxx
110xxxxx 10xxxxxx
1110xxxx 10xxxxxx 10xxxxxx
11110xxx 10xxxxxx 10xxxxxx 10xxxxxx

设计模式
音视频/流媒体
推荐系统
人工智能
大数据
云计算
web安全
