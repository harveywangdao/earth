1.Golang
slice:
只能判断slice==nil,不能slice1==slice2
扩容规则: 容量小于1024时每次扩容2倍,大于1024时每次扩大1.25倍,且遵循内存对齐规则;切片扩容机制与切片的数据类型、原本切片的容量、所需要的容量都有关系
s[:] s[i:] s[:j] s[i:j]
s[i:j:k]k代表容量,k>=j,如果没有k则默认原切片的cap长度,新切片的len=j-i,cap=k-i
从一个长的切片里截取部分数据,未使用的空间不会gc
nil切片也会分配结构体,ptr是0;空切片ptr指向固定地址
切片操作时j可以大于当前len

array:
数组以arr[:]方式转成切片,切片的底层直接指向了这个数组
数组可以使用len和cap
不能append,copy
arr2:=arr1是值复制,拷贝所有数据
可以range,会完全复制整个数组,编译器优化实际只有一份内存,有待研究?
可以直接==判断
append第一个参数必须是切片,第二个参数可以是单个类型/string/slice,string/slice要加三个点,返回值也是一个切片

string:
有len无cap
不可修改
对字符串进行切片操作(str[:])生成的还是字符串,不能修改值
[]byte转成string一定会拷贝内存吗,使用m[string(b)]来查找;字符串拼接;string(b) == "foo"
不能等于nil
str[0]是byte/uint8;range str返回的是rune/int32,range str时index可能是不连续的,value是unicode
[]rune(str)转成unicode,[]byte(str)转成utf-8的每个字节
常量字符串在编译阶段存在数据区,如果两个变量对应的字符串一样,那么两个变量对应的指针指向同一个地址

map:
冲突解决,开放寻址法:写入新的数据时如果发生了冲突就会将键值对写入到下一个索引为空的位置;拉链法:数组加上链表,引入红黑树以优化性能
切片/map不能作为key,但可以作为value
并发读写会panic,通过flags标志位判断
hash高8位用作tophash,底位用于计算在哪个桶
每个桶都是一个bmap,每个bucket可以存8个kv,摆放方式key1...key8/value1...value8,溢出桶通过链表链接
tophash,emptyRest表示后面没有数据了,emptyOne表示当前没有key
初始化,makemap,bucket数量一般是2的倍数,初始化时容量超过8才会分配空间,最少分配2个bucket
插入更新,mapassign,先找这个key是否已经存在,如果存在则更新value,如果不存在则找到第一个emptyOne/emptyRest插入新KV
删除,mapdelete,找到这个key,把tophash设置成emptyOne,把最后一个有key的后面所有的tophash都设置成emptyRest
查询,mapaccess1一个返回值,mapaccess2带ok的返回值,如果key不存在则返回&zeroVal[0]
遍历,mapiterinit初始化hiter结构体,起始桶和桶内的offset是随机数,mapiternext先遍历一个桶内的8个key再遍历下一个桶
扩容,map中数据总个数/桶个数>6.5时(overLoadFactor),引发翻倍扩容,或者是使用了太多的溢出桶时(tooManyOverflowBuckets)这种是同容量扩容将松散的数据聚合,因为删除操作造成太多的空洞,hashGrow开始扩容,插入/更新/删除时触发实际扩容(growWork),扩容当前的桶和一个每次递增的桶
mapextra,nextOverflow存放未使用的溢出桶,overflow/oldoverflow为了优化GC扫描而设计,当key和value均不包含指针并且都可以inline时使用,避免扫描hmap
hash函数

chan:
以通信方式共享内存,不要以共享内存方式通信
len+cap;读写nil管道都会阻塞;close nil管道会panic;close两次管道会panic
nil管道,发送/接收数据会阻塞,close会panic
往已close的管道发送数据会panic,可以接收数据第二个返回值是false
初始化,makechan,recvq/sendq存储G的接收发送队列,循环数组实现的数据队列,sendx/recvx记录队列中发送接收的位置
发送,chansend,如果recvq有等待的G会直接发送给这个G,调用goready唤醒这个G,如果队列没满就把数据放入队列,sendx加1然后返回,如果队列已经满了就把G放入sendq队列然后阻塞调用gopark,数据存在sudog上
接收,chanrecv1,chanrecv2返回值带ok,如果发送队列sendq不为空并且数据队列长度是0则直接获取阻塞G的数据并唤醒阻塞G,如果发送队列sendq不为空并且数据队列长度大于0则返回sendx位置的数据并且将阻塞G的数据放入队列,同样要唤醒阻塞G,此时队列是满的,recvx加1后,将recvx赋值给sendx,如果发送队列sendq为空并且数据队列不为空则返回sendx位置的数据,如果发送队列sendq为空并且数据队列也为空,那就将当前G放入recvq队列
close,closechan,close两次会panic,唤醒所有recv等待者,唤醒所有send等待者并且panic

select:
可用于收发多个管道,可非阻塞收发管道,可增加超时时间收发管道
select中所有case都阻塞就走default,没有default就阻塞
只能用于管道
case是随机执行的,避免饥饿问题
两个case可以接收同一个管道
超过1个case,有default,selectgo.block=false
超过1个case,无default,selectgo.block=true
0/1个case时编译器特殊处理:
只有一个读chan的case,chanrecv1
只有一个写chan的case,chansend1
只有一个读chan的case+default,selectnbrecv
只有一个写chan的case+default,selectnbsend
没有case也没有default,block
只有default,直接JMP
select recv多个管道,且这些管道都无数据,select所在G阻塞,sudog加入每个管道的recvq,其它G同时send数据给这些管道,通过g.selectDone防止所有管道同时给G发送数据

struct:
空结构体都指向zerobase;当空结构体放到另一个结构体中的最后一个字段时会进行特殊填充
结构体可以直接==判断
继承,一个结构体嵌到另一个结构体
如果一个struct嵌套了另一个匿名结构体,那么这个结构可以直接访问匿名结构体的方法从而实现继承
如果一个struct嵌套了另一个有名结构体,那么这个模式叫做组合
结构体方法调用时会先拷贝一份,所以无法改变原本结构体内部的成员值,因为接收者是结构体
结构体指针方法,把结构体赋值给接口,这时调用方法会造成编译不过,因为结构体会复制一份,当调用方法时需要取指针,这时结构体有两份拷贝编译器没有办法根据结构体找到一个唯一的指针

接口interface:
接口是一种抽象的类型,描述了一系列方法的集合,接口只定义方法名和参数而不包含具体的实现,对一系列具有联系的方法做出抽象和概括
只要实现了接口的所有方法,这个类型就实现了该接口,duck typing,不需要显式地去继承接口,编译阶段就可以发现是否实现了接口
eface表示空的interface{},有两个字段_type和data,data是指向数据的指针,_type是类型信息
iface表示至少带有一个函数的interface,有两个字段tab和data,itab表示interface和实际类型的转换信息,运行时为这一对具体的<Interface,Type>生成itab信息

协程:
pc: program counter,pc寄存器的作用是存储程序接下来运行的位置
sp: stack pointer,当前线程使用的栈的栈顶地址
systemstack: 可以由g0/gsignal/普通g调用,当由普通g调用的时候会切换到g0,调用完再切回普通g栈
mcall: 从普通g栈切换到g0栈,该函数由普通g调用,fn不能返回
stopTheWorld/startTheWorld: stopTheWorldWithSema通知所有P上的G被抢占,只设置抢占状态不保证立即被抢占,系统调用tgkill,发送信号给其它M让其停止,preemptall:循环allp调用preemptone,G正在newstack的时候要忽略停止的请求,设置G/P的preempt为true,preemptM-->signalM-->tgkill-->doSigPreempt-->asyncPreempt-->preemptPark->dropg->schedule->gcstopm->stopm->mPark;startTheWorldWithSema重新调整P大小procresize,循环所有P,绑定所有P和M,再唤醒所有M,wakep->startm如果有闲置的P那么就将P和一个闲置的M绑定,其它被唤醒的M执行schedule重新调度

lock/unlock:futexsleep/futexwakeup linux futex系统调用实现
notesleep:不带超时,g0调用
notetsleep:带超时,一般情况下被g0调用
notetsleepg:带超时,普通g调用
notewakeup:唤醒指定线程

gcstopm:stopm->mPark->notesleep
acquirep:wirep绑定M和P
releasep:解绑P和M
execute:绑定M和G
dropg:解绑M和G,G的状态改为_Grunning,调用gogo执行协程函数

throw->fatalthrow->startpanic_m+dopanic_m
gopanic->fatalpanic->startpanic_m+dopanic_m
raise->tgkill
crash->raise(SIGABRT)
exit->exit_group
LockOSThread/UnlockOSThread/FreeOSMemory/SetGCPercent/SetMaxStack/ReadGCStats/SetPanicOnFault/WriteHeapDump/SetTraceback

main:
_rt0_amd64_linux
_rt0_amd64
rt0_go
runtime.settls: 调用系统调用arch_prctl
runtime.check: 检查基础类型是否正确,如int8是不是一个字节
runtime.args: 处理参数
runtime.osinit: 获取cpu数量
runtime.schedinit: 初始化堆栈/环境变量/进程入参/gc
runtime.newproc: 创建新G运行fn=runtime.main->main_main,将G放入当前P的队列,执行wakep
runtime.mstart: 保存pc/sp,执行schedule
runtime.abort: INT $3

G:
Goroutine协程,初始2KB栈
G状态:_Grunning/_Gwaiting/_Grunnable/_Gsyscall/_Gidle/_Gdead/_Gcopystack/_Gpreempted
G存储在,LRQ本地运行队列/GRQ全局运行队列/Netpoller网络轮询器/系统调用/锁/chan receive/chan send/select,本地P运行队列没有剩余空间时会使用全局队列
GC sweep/GC scavenge/force gc/GC worker
tls: thread local storage 为线程本地存储
gsignal:signal-handling g,32KB栈
g0:8KB栈,是持有调度栈的Goroutine,参与运行时的调度过程,包括G的创建/大内存分配/CGO函数的执行
getg: 返回当前g的指针,在编译的时候才会生成该函数
newproc:创建一个新G,在g0栈里调用该函数,newproc1:从gFree里获取,如果获取不到就new一个g并分配2K栈状态设为_Gdead加到allgs上,参数放入栈,状态设为_Grunnable,goid设置成当前P上的自增值,新G放到当前P的本地队列/全局队列/当前P的下一个要执行的g,wakep->startm获取空闲P,如果没有空闲P直接返回,如果有空闲P就去获取空闲的M(mget),绑定P和M,唤醒M,如果没有空闲M就去newm
gopark/goready
gosave/gogo
gobuf
goexit:该函数地址放在栈顶,当协程函数执行完就会执行goexit,goexit1->goexit0,g状态设置成_Gdead,dropg拆解m和g的绑定,把g放到gFree上,重新schedule

M:
操作系统线程
SetMaxThreads,默认sched.maxmcount=10000
最大活跃线程数是GOMAXPROCS,非活跃线程可能阻塞在系统调用
目前并没有对闲置线程做清除处理
osyield: 线程让出cpu,调用系统调用sched_yield
procyield: 执行PAUSE指令空转
m0
startm: 获取一个闲置的M,如果没有就newm一个
newm: 创建新线程并让线程工作,newm(fn, _p_, id),allocm获取M,new一个m对象,mstartfn=mspinning,M初始化,分配g0,(解绑当前的P和M,当前P的状态设置为_Pidle),绑定空闲P和新M,newm1->newosproc->clone->mstart
allocm: 获取m结构体
newosproc: 创建系统线程
mcommoninit: M的一些初始化,创建gsignal
mexit: mstart的结尾调用,退出当前线程,释放gsignal栈,从allm移除m,(非系统栈时m对象放在sched.freem上,后期由allocm释放栈),解绑M和P,让P去找另一个M去执行,线程自然退出由OS释放资源,(非系统栈调用系统调用exit退出)
mstart: 线程开始工作,clone时传进去的函数/systemstack中有调用,mstart1,当前是g0在执行,保存pc/sp,初始化信号,acquirep->wirep正式绑定空闲P和新M,设置P的状态为_Prunning,schedule获取一个可执行的G,execute绑定M和G,G的状态设置为_Grunning,gogo执行协程的函数

P:
处理器,提供线程需要的上下文环境,调度等待队列,P本地运行队列最大256
P状态:_Pidle/_Prunning/_Psyscall/_Pgcstop/_Pdead
wakep: 获取一个闲置的P绑定M去执行

schedule:
全局运行队列sched.runq中有待执行的G时,通过schedtick保证有一定几率会从全局运行队列中查找G(globrunqget),从P本地运行队列中查找待执行的G(runqget),如果前两种方法都没有找到G,会通过findrunnable进行阻塞地查找G,网络轮询器中查找,通过runqsteal尝试从其它随机的P中窃取待运行的G,该函数还可能窃取处理器的计时器,gcstopm

netpoll:
当网络请求阻塞时,调度器会让当前阻塞的G放入网络轮询器中,由网络轮询器处理异步网络系统调用,从而让出P执行其它G
当异步网络调用由网络轮询器完成后,再由sysmon监控线程将其切换回来继续执行
netpoll: 调用时机,startTheWorldWithSema/findrunnable/pollWork(gc过程中执行)/sysmon(10ms一次)
epollcreate1(EPOLL_CLOEXEC)
epollctl EPOLL_CTL_ADD/EPOLL_CTL_MOD/EPOLL_CTL_DEL EPOLLIN/EPOLLOUT 
EPOLLET边沿触发(go使用ET),对于读事件EPOLLIN,只有socket上的数据从无到有EPOLLIN才会触发,对于写事件EPOLLOUT,只有在socket写缓冲区从不可写变为可写EPOLLOUT才会触发
EPOLLLT水平触发,对于读事件EPOLLIN只要socket上有未读完的数据EPOLLIN就会一直触发,对于写事件EPOLLOUT只要socket可写,EPOLLOUT就会一直触发
EPOLLRDHUP检查对方是否关闭socket
epoll_wait
Listen->listenTCP->internetSocket->socket->sysSocket->syscall.Socket->netFD.listenStream->syscall.Bind->syscall.Listen->netFD.init->FD.Init->pollDesc.init->runtime_pollOpen->netpollopen
TCPListener.Accept->TCPListener.accept->netFD.accept->FD.Accept->pollDesc.waitRead->runtime_pollWait->poll_runtime_pollWait->netpollblock->gopark->syscall.Accept4(s, syscall.SOCK_NONBLOCK|syscall.SOCK_CLOEXEC)
TCPConn.Read->conn.Read->netFD.Read->FD.Read->pollDesc.waitRead->syscall.Read
Dial->Dialer.Dial->Dialer.DialContext->sysDialer.dialSerial->sysDialer.dialSingle->sysDialer.dialTCP->sysDialer.doDialTCP->internetSocket->socket->sysSocket->syscall.Socket->netFD.dial->netFD.connect->syscall.Connect

sysmon:
每隔20us~10ms轮询一次,独立于GMP之外,独立的M
监控那些长时间运行的G,设置被强占的标识符,别的G就可以抢先进来执行
检查当前网络轮询器中所有G距离runtime.netpoll被调用是否超过了10ms,将其放入全局运行队列,等待下一次的继续执行
系统调用导致阻塞的话,P的状态为_Psyscall,则会让GM一起切换出去,让P重新找一个GM运行
如果垃圾回收器超过两分钟没有执行的话,sysmon监控线程也会强制进行GC
获取下一个需要被触发的计时器

内存管理:
mheap mspan mcentral mcache mstats TCMalloc
小于32KB,从P上的mcache分配mspan,不需要加锁,为每种类别的mspan维护着一个mcentral
mcentral的作用是为所有mcache提供切分好的mspan资源,每个central会持有一种特定大小的全局mspan列表,mcentral被所有的工作线程共同享有,需要加锁
当mcentral没有空闲的mspan时,会向mheap申请
而mheap没有资源时,会向操作系统申请新内存,mheap主要用于大对象的内存分配,以及管理未切割的mspan
大于32KB,会直接从堆上(mheap)上分配对应的数量的内存页(每页大小是8KB)给程序

newobject:mallocgc
mallocgc:
大于32KB直接在堆上分配,会判断是否要gc,mcache.allocLarge->mheap.alloc->mheap.allocSpan(systemstack)->pageAlloc.allocToCache,pageCache.alloc,mheap.grow,mheap.sysAlloc,linearAlloc.alloc,sysMap+sysUsed,返回mspan

小于32KB在每个P的cache free list分配,0字节直接返回zerobase地址
从P上的mcache分配,mcahce.alloc存放每个级别的mspan,如果mcache上的mspan没有可用空间则调用mcache.refill->mcentral.cacheSpan去获取新的mspan,这个mspan至少有一个未使用的对象,获取到新的mspan后放入mcache.alloc对应级别上,旧的mspan调用mcentral.uncacheSpan放入fullSwept,mheap上的mcentral也是按照级别用数组存放,如果mcentral上也没有则mcentral.grow->mheap.alloc

arena: 64MB
pageSize: 8KB
chunk: 4MB
arenaIndex spanOf *mspan
chunkIndex chunkOf *pallocData

pp.mcache *mcache
mcache.alloc []*mspan
allocmcache/freemcache
pp.pcache pageCache
mheap.pages pageAlloc
pp.mspancache buf [128]*mspan
mheap.spanalloc fixalloc: 用于分配mspan结构体
mheap.cachealloc fixalloc: 用于分配mcache结构体
mheap.arenas []*[]*heapArena: heapArena存放arena元数据
page allocator
page cache
sweep credit
memstats

mspan.nextFreeIndex: 放回空闲对象的位置
mcache.nextFree: mcache.refill,mspan.nextFreeIndex
mcache.refill: 获得一个新mspan,至少有一个空闲空间,在当前mcache满的情况下才会调用,满的mspan调用mcentral.uncacheSpan,通过mcentral.cacheSpan获取新的mspan,新mspan放入mcache.alloc
mcache.allocLarge
mcache.releaseAll

mcentral.cacheSpan: 返回一个mspan,从partialSwept/partialUnswept/fullUnswept获取mspan,如果依然没有mspan则调用mcentral.grow
mcentral.uncacheSpan: 回收一个mspan
mcentral.grow: mheap.alloc从mheap上分配一个mspan

mheap.alloc: mheap.reclaim分配前先sweep即将要分配的页数,mheap.allocSpan
mheap.allocSpan: 返回全新的mspan,小内存从P上的pageCache分配,如果P上的pageCache未初始化则调用mheap.pages.allocToCache分配一个pageCache,调用pageCache.alloc分配内存,再从P上的mspancache分配mspan结构体,如果P上没有,调用mheap.pages.alloc分配内存,如果依然没有则调用mheap.grow向OS申请内存再mheap.pages.alloc,mheap.spanalloc.alloc分配mspan结构体,mspan结构体初始化
mheap.grow: 增加npage给heap,mheap.sysAlloc,mheap.pages.grow
mheap.sysAlloc: 返回准备状态的内存区域,分配nbytes的arena空间,更新mheap.arenas元信息,sysReserve,sysMap,向OS申请内存,更新allArenas
mheap.freeSpan: mheap.pages.free释放内存,mspan结构体放回P上的mspancache,如果已满则mheap.spanalloc.free
mheap.scavengeAll

pageAlloc.grow: pageAlloc.sysGrow
pageAlloc.sysGrow: 更新summary,sysMap
pageAlloc.alloc: 分配npages内存,pageAlloc.find寻找npages内存
pageAlloc.find: 从radix tree查找npages
pageAlloc.allocToCache: 如果P上的pageCache是空的调用此方法分配pageCache,返回pageCache
pageCache.alloc: 从P上的pcache(pageCache)分配npages,不加锁

mmap/munmap/msync/mprotect/mremap/mlock/mlock2/munlock/mlockall/munlockall
madvise/posix_madvise/posix_fadvise
brk/sbrk/getpagesize
malloc/calloc/realloc/free/posix_memalign/memfd_create

协程栈:
每个goroutine都维护着自己的栈区,栈结构是连续栈,是一块连续的内存,栈区的初始大小是2KB,按照需要增长和收缩,最大1GB
分段栈,栈空间会以双向链表的形式串联起来,如果协程的栈几乎充满,那么任意的函数调用都会触发栈的扩容,当函数返回后又会触发栈的收缩,如果在一个循环中调用函数,栈分配释放造成巨大开销,热分裂问题
连续栈,栈空间不足时,初始化一片比旧栈大两倍的新栈并将原栈中的所有值都迁移到新的栈中,将指向旧栈对应变量的指针重新指向新栈
分配类似堆内存的分配

morestack: g0/gsignal不调用morestack,newstack
newstack: 扩大栈,copystack
stackalloc: 生成新G的时候调用stackalloc,小栈从mcache.stackcache内分配,如果mcache.stackcache是空的则调用stackcacherefill,大栈从stackLarge分配,如果stackLarge是空的则调用mheap.allocManual分配新的mspan
stackfree: 大栈_GCoff期间直接调用mheap.freeManual,否则放入stackLarge,小栈放回mcache.stackcache,如果mcache.stackcache超过32KB则调用stackcacherelease
copystack: stackalloc分配新栈空间,adjustsudogs/syncadjustsudogs,memmove拷贝数据,adjustctxt,adjustdefers,adjustpanics,gentraceback调整指针的值,stackfree释放老空间
shrinkstack: 当前使用的栈空间小于总空间的1/4的时候才会缩栈,调用copystack缩小成原来的1/2
freeStackSpans: gcMarkTermination内调用,stackpool/stackLarge未使用的mspan会调用mheap.freeManual释放,
stackpoolalloc: 从stackpool获取第一个mspan,如果stackpool是空的则调用mheap.allocManual返回一个新的mspan并放入stackpool,s.allocCount++,如果这个mspan用完了则从stackpool移除
stackpoolfree: 如果mspan有可用空间则放入stackpool,mspan.allocCount--,如果mspan.allocCount=0并且是_GCoff那么mheap.freeManual并且从stackpool移除
stackcacherefill: 循环调用stackpoolalloc生成16KB可用内存放入mcache.stackcache
stackcacherelease: mcache.stackcache保留16KB内存,其它内存循环调用stackpoolfree放回stackpool

go1.17函数入参/返回值,使用了9个通用寄存器,依次是AX/BX/CX/DI/SI/R8/R9/R10/R11,超出部分按顺序放在栈上

内存回收gc:
三色标记
开始所有对象都是白色的
遍历根节点(全局变量和栈内变量)集合里的所有根对象,把根对象引用的对象标记为灰色,从白色集合放入灰色集合
遍历灰色集合,将灰色对象引用的对象从白色集合放入灰色集合,之后将此灰色对象放入黑色集合
重复第三步,直到灰色集合中无任何对象
回收白色集合里的所有对象,本次垃圾回收结束
写屏障,在对象新增的同时给它着色为灰色,而所有新创建的对象都会被直接标记成黑色
开启写屏障前和移除写屏障前暂停应用程序
标记准备阶段,暂停程序
标记阶段,根对象入队,开启写屏障,恢复执行程序,开始扫描根对象,扫描协程栈期间会暂停当前处理器,
标记终止阶段,暂停程序
清理阶段,初始化清理状态并关闭写屏障,恢复用户程序,后台并发清理所有的内存管理单元,当goroutine申请新的内存管理单元时就会触发清理
触发时机,内存使用超过某值,超过两分钟,手动GC

setGCPhase,_GCoff/_GCmark/_GCmarktermination
gcStart: 调用时机:mallocgc/runtime.GC/sysmon两分钟唤醒一次forcegchelper,将剩余未清扫的span清扫完成,启动gomaxprocs个gcBgMarkWorker,如果以前启动过就不用重复启动,stopTheWorldWithSema,finishsweep_m,gcphase设置成_GCmark,gcMarkRootPrepare栈和全局变量入队列,gcMarkTinyAllocs标记小对象为灰色,startTheWorldWithSema
gcBgMarkWorker: 执行gcDrain的协程
gcDrain: 在work buffers里扫描roots和objects,将灰色对象变黑,直到所有工作都做完,GC结束前返回,循环调用markroot,循环调用scanobject,gcFlushBgCredit
markroot: flushmcache,markrootBlock,scanblock,markrootFreeGStacks,markrootSpans,scanstack
scanobject: 调用greyobject
scanblock: 类似scanobject,scan non-heap roots,调用greyobject
scanstack: 调用前需要suspendG,调用后需要resumeG,扫描G的栈,栈上的指针都变成灰色,调用scanblock,scanframeworker扫描栈帧局部变量/入参/返回值
greyobject: 通过位操作设置为灰色,设置mspan.gcmarkBits对应位上为1即为标记过
gcMarkDone: 最后一个终止标记的协程调用,标记终止阶段,stopTheWorldWithSema,唤醒所有辅助G,gcMarkTermination
gcMarkTermination: gcphase设置成_GCmarktermination,gcMark,gcphase设置成_GCoff,gcSweep,startTheWorldWithSema,freeStackSpans,每个P执行一次mcache.prepareForSweep
gcMark: 检查gc完成,设置memstats
gcSweep: 在gcMarkTermination里调用,结尾处唤醒bgsweep
gcWaitOnMark: 等待mark阶段结束,如果当前处于mark阶段当前G就gopark,等待在gcMarkTermination里唤醒该G
gcAssistAlloc: 普通G分配内存mallocgc并且处于标记阶段时,如果gcAssistBytes小于0就会调用此函数,辅助gc标记至少64KB,gcDrainN

write barriers: p.wbBuf每个P都有一个write barrier buf,防止一个白色对象被黑色对象引用,只要满足强/弱三色不变式的其中一种,即可保证对象不被丢失
hybrid barrier: Yuasa-style deletion barrier,Dijkstra insertion barrier,混合写屏障=删除写屏障+插入写屏障
强三色不变式: 永远不会出现黑色对象指向白色对象,强制性的不允许黑色对象引用白色对象
弱三色不变式: 黑色对象可以引用白色对象,白色对象存在其它灰色对象对它的引用,或者可达它的链路上游存在灰色对象
插入屏障: 是对象被引用时触发的机制,插入屏障拦截将白色指针插入黑色对象的操作,标记其对应对象为灰色状态,这样就不存在黑色对象引用白色对象的情况,满足了强三色不变式,插入屏障是一个很耗费性能的行为,而栈需要更高的性能要求,因此插入屏障技术只运用在堆内存空间里不会运用到栈里
删除屏障: 是对象被删除时触发的机制,删除屏障也是拦截写操作,因为它是写入一个空对象,具体的操作是被删除的对象如果自身为灰色或者白色,那么被标记为灰色,满足了弱三色不变式原则,保护灰色对象到白色对象的可达路径不会断
gcWriteBarrier: 编译器插入到代码里,将指针放入wbBuf,满了则调用wbBufFlush
wbBufFlush: flush当前P的write barrier buf到gc workbuf,调用wbBufFlush1,标记指针指向的mspan,gcw.putBatch将所有指针放入gcw,此时对象是灰色
bulkBarrierPreWrite: typedmemmove/typedslicecopy/typedmemclr/memclrHasPointers调用该函数,memmove前执行,src=0时memclr,wbBuf.putFast,wbBufFlush
bulkBarrierPreWriteSrcOnly: makeslicecopy/growslice调用该函数,同bulkBarrierPreWrite
bulkBarrierBitmap: bulkBarrierPreWrite内调用,同bulkBarrierPreWrite
typeBitsBulkBarrier: 管道传数据专用,同bulkBarrierPreWrite
标记起始阶段STW: finishsweep_m需要STW是为了当前不会有并发的sweep发生,这样才能保证所有的mspan都被sweep;gcMarkRootPrepare需要STW是为了计算root(全局变量)对象数量,设置nDataRoots/nBSSRoots/nSpanRoots;gcMarkTinyAllocs遍历所有P将mcache.tiny标记成灰色
标记终止阶段STW: 每个P执行wbBufFlush1,把P上的写屏障放入gcw,如果gcw不为空那么startTheWorldWithSema,gcMarkDone再从头开始执行,如果每个P上的gcw都是空的,设置gcBlackenEnabled,设置gcphase为_GCmarktermination,gcMark,设置gcphase为_GCoff,gcSweep,设置一些全局变量memstats/work/sweep

bgsweep: 循环调用sweepone,循环调用freeSomeWbufs,做完后gopark
sweepone: 清扫mspan,返回清扫的页数,没可清扫的返回^0,nextSpanForSweep找到需要sweep的mspan,调用mspan.sweep,如果清扫完会激活新一轮的scavenge
mheap.nextSpanForSweep: 从mcentral fullUnswept/partialUnswept找未sweep的mspan
mspan.sweep: 清扫单个mspan,设置mspan.allocCount/mspan.freeindex=0/mspan.allocCache/mspan.allocBits=mspan.gcmarkBits,如果这个mspan没有一个对象被使用则调用mheap.freeSpan
freeSomeWbufs: mheap.freeManual释放workbuf使用的mspan
mheap.freeSpan: mheap.freeSpanLocked释放spanAllocHeap类型
mheap.freeManual: mheap.freeSpanLocked释放spanAllocWorkBuf/spanAllocStack类型
mheap.freeSpanLocked: mheap.pages.free释放pages,mheap.freeMSpanLocked释放mspan对象
mheap.freeMSpanLocked: 释放一个mspan对象,先放入pp.mspancache,如果pp.mspancache已满,则调用mheap.spanalloc.free
pageAlloc.free: 释放npages内存
getempty/putempty: 返回空的workbuf/存储空的workbuf
mheap.allocManual/mheap.freeManual: 分配释放栈内存和workbuf

bgscavenge: sweep结束会唤醒此G,循环调用mheap.pages.(pageAlloc).scavenge
pageAlloc.scavenge: scavengeReserve,scavengeOne,scavengeUnreserve
pageAlloc.scavengeReserve: 预留连续内存用于scavenge
pageAlloc.scavengeOne: scavengeRangeLocked
pageAlloc.scavengeRangeLocked: sysUnused,scavenged.setRange
pageAlloc.scavengeUnreserve: 未scavenge的内存再存起来

sync.Map:
通过互斥锁和原子操作来实现近似无锁,空间换时间,延迟删除,删除一个键值只是打标记,只有在迁移dirty数据的时候才清理删除的数据,readOnly向dirty拷贝是遍历,不适合大数据场景
不加锁: 读/删一个存在readOnly中的key,写一个存在readOnly中的key并且没有标记删除
加锁: 增加新key会加锁,新key先放dirty,不适合频繁增加数据

sync.Mutex:
CAS+原子操作
正常模式: 等待者们以先进先出的顺序排队,排在最前面的等待者不一定能获得下一次的锁,比如在某个时刻,醒着的等待者与一个新到达的G竞争所有权,由于新到达的G一直在CPU上运行,此时这个醒着的等待者有很大的概率失去锁,在这种情况下,它就在等待队列的前面排队着,如果一个等待者没有获得锁超过1ms,就会切换到饥饿模式;正常模式会有好的性能在一个协程能多次获得一把锁,即使有阻塞的等待者
饥饿模式: 锁的所有权直接从未锁的协程推给队列前面的等待者,新到达的协程不会尝试获得锁,并且不会尝试自旋,它们会排在队列的尾端,如果一个等待者拿到了所有权,并且它看到了它是队列的最后一个或者它等待的时间小于1ms,切换到正常模式;饥饿模式是为了防止严重的尾端延迟情况
进入自旋的条件,非饥饿模式,自旋次数小于4,cpu大于1,空闲的P+自旋的M+1小于总P,当前P的runq是空的,执行PAUSE命令,自旋30次
如果不进入自旋接下来就会阻塞在信号量,放入队列,执行gopark,_Grunning->_Gwaiting,unlock时调用goready唤醒阻塞的协程,_Gwaiting->_Grunnable

sync.RWMutex:
使用Mutex和信号量实现
获得读锁,如果之前有读锁那么直接获得锁,如果之前有写锁那么阻塞在读信号量队列上,当释放写锁时唤醒读信号量队列上所有的读锁
获得写锁,如果之前有写锁那么直接阻塞在互斥量上,如果之前有读锁,那么阻塞在写信号量上,当释放最后一个读锁时唤醒写信号量

sync.Once:
CAS+mutex
首先原子判断done是不是0,如果不是0就直接返回,如果是0就代表未执行过,这时先加锁,再次判断done是不是0,不是0就代表被其它同时运行的G执行了直接退出,是0的话就执行fn再原子设置done为1

sync.WaitGroup:
Add: 支持加负数,检测到v等于0并且等待者不等于0就去释放所有等待者的信号量
Done: Add(-1)
Wait: 原子增加等待者的数量+1,协程进入信号量阻塞

sync.Cond:
用法: 先上锁,Wait,解锁
Wait: 先解锁,协程睡眠,等待被唤醒,再上锁
Signal: 唤醒单个等待者
Broadcast: 唤醒所有等待者

sync.Pool:
Get,P先去private找,如果private是空则去本地池查找,如果自己没有就去其它P偷过来一些,如果还是没有就去本地池victim取,如果都没有就New一个
Put,P操作本地池,数据放入一个双向链表,每个链表节点存储容量以2倍递增
gc前的STW执行注册的回调函数用于清理一代的缓存,原本的victim赋值nil去除对内存的引用,local赋值给victim
禁止G被抢占,false sharing问题的避免

atomic:
锁住变量的地址不允许其它cpu操作
通过指令实现原子操作,LOCK
ANDL/ORL/ANDB/ORB
StoreInt64 XCHGQ
LoadInt64 *ptr
AddInt64 XADDQ
CompareAndSwapInt64 CMPXCHGQ
SwapInt64 XCHGQ
MESI缓存一致性协议

return:
不带命名的返回参数会默认加r0...rn的名称,函数返回时需要给这些变量赋值
带命名的返回参数:
return后面什么都不加,等同于,return后面加返回值里的变量;
return后面加非返回值里的变量,先给这个函数返回值变量赋值再返回;

defer:
先进后出;defer无法改变已经return的变量,除非该变量在函数的返回值里申明
deferprocStack&deferreturn
先执行return再执行defer
defer函数的入参取决于执行到defer那一行时是什么值,入参放在deferprocStack函数入参_defer结构体的下面位置
gp._defer,defer以链表的形式存储

panic&recover:
只能recover本协程内的panic
gopanic&gorecover
数组切片越界;nil指针野指针;往已经close的chan里发送数据;并发读写相同map;interface{}断言未接收第二个返回值
gp._panic,panic以链表的形式存储
多个panic,recover的时候只返回最新的一个(链表头部)

闭包函数:
定义在一个函数内部的函数,闭包是将函数内部和函数外部连接起来的桥梁,局部变量变成全局变量

unsafe&uintptr:
unsafe.Pointer和uintptr可以相互转化
unsafe.Pointer不能加减
uintptr可以加减
uintptr对对象已经无引用,对象可能随时被回收;除非是系统调用传进去的uintptr,编译器做了处理对象不会被回收
普通变量取址也不能进行加减

copy:
第一个参数只能是slice,第二个参数可以是slice和string
nil:
nil不是关键字;nil可作为变量名;nil是没有默认类型的在使用它时必须要提供足够的信息能够让编译器推断nil期望的类型
iota:
只能和const一起使用;每当const出现时都会使iota初始化为0;const中每新增一行常量声明将使iota计数一次;默认int型

内存对齐:
不是所有的硬件平台都能访问任意地址上的任意数据,为了访问未对齐的内存,处理器需要作两次内存访问,而对齐的内存访问仅需要一次访问
计算机只能从4/8的倍数开始读数据,不能随便从一个地址读数据
结构体嵌套空结构体的情况,空结构体在最前面/中间不占字节,在最后会被填充对齐到前一个字段的大小

内存逃逸:
编译阶段确定;大内存优先分配在堆上/分配的大小不确定;变量在函数返回后还可能被使用,闭包,返回指针;造成gc压力变大
go build -gcflags "-m -m" main.go
go tool compile -m main.go

位运算:
&: 与AND
|: 或OR
^: 异或XOR,作为一元运算符时表示位反或位补,等价m^n,m所有位都是1
&^: 位清空AND NOT,运算符左边数据与右边数据相异的位保留,相同位清零,0&^0=0  0&^1=0  1&^0=1  1&^1=0;如果右侧是0,则左侧数保持不变;如果右侧是1,则左侧数一定清零
>>: 左移
<<: 右移
原码: 符号位加真值的绝对值
反码: 无符号数和正数的反码是其本身,负数的反码是将原码除符号位外的其他位按位取反,即0变1,1变0
补码: 无符号数和正数的补码是其本身,负数的补码是反码二进制加1
为了让符号位参与基本预算,产生了反码
为了解决反码运算后产生-0的问题产生了补码
计算机实际用补码参与运算,获得的结果需要转换成原码

pprof:
net/http/pprof runtime/pprof
go tool pprof http://localhost:6060/debug/pprof/heap
go tool pprof http://localhost:6060/debug/pprof/profile
go tool pprof http://localhost:6060/debug/pprof/goroutine
go tool pprof demo demo.prof
go tool pprof -http 0.0.0.0:8080 http://localhost:6060/debug/pprof/profile
能查到哪个函数分配的内存高
能查到哪个函数占用cpu高
火焰图
调用链,每个函数的耗时和占比

dlv:
查看函数参数、打印变量、单步执行、查看所有协程
dlv exec ./hello
设置断点
break /usr/local/go/src/runtime/os_linux.go:71
break main.go:35
打印所有断点 breakpoints
继续执行到下一个断点 continue
执行下一行 next
执行下个指令(更细) step
局部变量 locals var1
打印变量 print var1
strace -ff ./test1

Benchmark:
go test -bench .
go test -bench=. -cpuprofile=cpu.prof
go test -bench=. -memprofile=mem.prof
go tool pprof -http 0.0.0.0:8080 cpu.prof

trace:
curl -o app.trace http://localhost:6060/debug/pprof/trace
go tool trace -http 0.0.0.0:8080 performance app.trace
可以查看每个协程在哪耗时大

test:
go test -coverprofile=test.out
go tool cover -html=test.out -o cover.html
go test -run=FuzzReverse
go test -fuzz=Fuzz
go test -run=FuzzReverse/8fe4afa715c62ebbf52961c12d500dda471293a8d663e527b1f89032f1956f5f
go test -fuzz=Fuzz -fuzztime 30s

汇编plan9:
go tool compile -N -l -S main.go //打印汇编 生成.o
go run -gcflags "-N -l" main.go
go build -gcflags "-N -l" main.go
go build -gcflags=all="-N -l" main.go
go tool objdump -s do1 main.o
静态单赋值SSA GOSSAFUNC=do1 go build main.go
中间代码

tool:
go env -w GO111MODULE=on
go tool fix main.go //golang.org/x/net/context --> context
go fmt main.go
go vet main.go //检查基本错误如语法错误 fmt.Printf("%s", 12)
go tool asm main.s //.s --> .o
go tool link main.o //链接
readelf -w a.out
addr2line -e a.out
go tool nm main.o
go tool pack c file.a main.go
//go:noinline //go:nosplit //go:noescape //go:linkname //go:notinheap //go:norace
//go:generate stringer -type=Life
插件: go build -buildmode=plugin add.go

定时器:
time.Sleep: timeSleep,resettimer
resettimer: modtimer
modtimer: doaddtimer,wakeNetPoller
doaddtimer: 在当前P的heap上增加定时器
dodeltimer: 删除当前P的heap上的定时器,指定第几个timer
runtimer: runOneTimer真正运行一个timer
cleantimers: dodeltimer0移除pp.timers第一个timer
adjusttimers: 调整pp.timers,该删的删
addtimer: cleantimers,doaddtimer
deltimer: 不会真正删除timer,只会标记status
checkTimers: 调度器调用,adjusttimers,runtimer
time.NewTimer: startTimer->addtimer
Timer.Reset: resetTimer->resettimer
time.NewTicker: startTimer->addtimer
Ticker.Stop: stopTimer->deltimer
Ticker.Reset: modTimer->modtimer

性能优化:
select中的case太多会降低性能
map中的value如果没有使用到可以用struct{},减小内存占用
map中key和value尽量不使用指针减少gc压力
map只能扩容不能缩容,可以适当地重置map
不要在循环中使用defer
尽量不使用reflect,反射耗性能
不要从大的slice和string截取部分数据,因为其它部分的数据不会被gc
频繁拼接string考虑预先分配一个大空间,把待拼接的string拷贝进去,如strings.Builder,而不是使用+
slice/array的单个元素如果很大的话可以考虑for/range只返回索引,避免不必要的内存拷贝
slice可以提前预分配空间,避免append时频繁扩容

fmt:
每次打印从sync.Pool获取结构体空间,使用完,如果空间大于64KB直接交给gc,如果小于64KB就放回sync.Pool
打印结构体会使用到reflect

泛型:
~粗略匹配
编译为代码中所有类型的具体函数,会导致代码膨胀
comparable

net/http:
https://httpwg.org/specs/rfc7230.html
h1客户端对于同一个host可以和服务端建立多个tcp链接(受MaxIdleConns/MaxConnsPerHost/MaxIdleConnsPerHost制约),每个请求独占一个链接直到收到响应
h2客户端对于同一个host只建立一条tcp,多个请求多路复用
Serve->Server.Serve->conn.serve->conn.readRequest->readRequest->readTransfer->ServeHTTP->finishRequest
NewRequest->NewRequestWithContext->Client.Do->Client.do->Client.send->send->Transport.RoundTrip->Transport.roundTrip->Transport.getConn->Transport.queueForDial->Transport.dialConnFor->Transport.dialConn->Transport.dial->Transport.DialContext->Dialer.DialContext->persistConn.readLoop->persistConn.writeLoop->persistConn.roundTrip->persistConn.readResponse->ReadResponse

tls:
ServeTLS->Server.ServeTLS->tls.NewListener->Server.Serve->Conn.Handshake->Conn.handshakeFn->Conn.serverHandshake->Conn.readClientHello->serverHandshakeState.handshake->serverHandshakeState.processClientHello->serverHandshakeState.pickCipherSuite->serverHandshakeState.doFullHandshake->serverHandshakeState.establishKeys->serverHandshakeState.readFinished->serverHandshakeState.sendSessionTicket->serverHandshakeState.sendFinished
Transport.dialConn->persistConn.addTLS->tls.Client->Conn.Handshake->Conn.clientHandshake->clientHandshakeState.handshake->clientHandshakeState.processServerHello->clientHandshakeState.pickCipherSuite->clientHandshakeState.doFullHandshake->clientHandshakeState.establishKeys->clientHandshakeState.sendFinished->clientHandshakeState.readSessionTicket->clientHandshakeState.readFinished

websocket: x/net/websocket
Dial->DialConfig->dialWithDialer->Dialer.Dial->NewClient->hybiClientHandshake->http.ReadResponse->newHybiClientConn->newHybiConn
Handler.ServeHTTP->Server.serveWebSocket->newServerConn->hybiServerHandshaker.ReadHandshake->hybiServerHandshaker.AcceptHandshake->hybiServerHandshaker.NewServerConn->newHybiServerConn->newHybiConn
Conn.Write->hybiFrameWriterFactory.NewFrameWriter->hybiFrameWriter.Write
Conn.Read->hybiFrameReaderFactory.NewFrameReader->hybiFrameHandler.HandleFrame->hybiFrameReader.Read

http2.0: 只能在TLS情况下使用 ALPN
request和对应的response使用同一个StreamID,同一个请求HEADERS和DATA使用同一个StreamID
HEADERS是由一个或多个frame组成的,第一个frame是Headers类型,后面的是Continuation(0x9)类型,每个frame都包含帧首部(帧长度+帧类型+flags)+流标识符+优先值+帧净荷
DATA类型数据会发送一个或多个frame,每个frame的类型都是DATA
TLS版本不低于1.2
h2怎么保证两端的头部信息一致:
客户端的编码器发送到服务端的解码器,因为只有一条TCP链接,先发的数据肯定先到,保证了顺序,服务端的编码器发送到客户端的编码器,也是同理,客户端的编码器和客户端的解码器用的是不同的动态表
客户端发来的Setting改变服务端编码器动态表的大小,然后服务端发送001的头部编码改变客户端的解码器动态表大小

Transport.roundTrip->Transport.onceSetNextProtoDefaults->http2configureTransports->http2registerHTTPSProtocol->Transport.RegisterProtocol->Transport.altProto->Transport.TLSNextProto->upgradeFn->Transport.alternateRoundTripper->http2noDialH2RoundTripper.RoundTrip->http2Transport.RoundTrip->http2Transport.RoundTripOpt->http2noDialClientConnPool.GetClientConn->http2clientConnPool.getClientConn->Transport.getConn->Transport.queueForIdleConn->Transport.queueForDial->Transport.dialConnFor->Transport.dialConn->persistConn.addTLS->upgradeFn->http2clientConnPool.addConnIfNeeded->http2addConnCall.run->http2Transport.NewClientConn->http2Transport.newClientConn->http2Transport.RoundTrip->http2Transport.RoundTripOpt->http2noDialClientConnPool.GetClientConn->http2clientConnPool.getClientConn->http2ClientConn.RoundTrip->http2clientStream.doRequest->http2clientStream.writeRequest->http2clientStream.encodeAndWriteHeaders->http2ClientConn.encodeHeaders->http2ClientConn.writeHeaders->http2Framer.WriteHeaders->http2Framer.WriteContinuation->http2clientStream.writeRequestBody->http2Framer.WriteData->http2Framer.WriteDataPadded->http2Framer.startWrite->http2Framer.endWrite

http2Transport.newClientConn->http2ClientConn.readLoop->http2clientConnReadLoop.run->http2Framer.ReadFrame->http2readFrameHeader->http2typeFrameParser->http2parseHeadersFrame/http2parseDataFrame->http2Framer.readMetaFrame->http2clientConnReadLoop.processHeaders/processData

conn.serve->http2Server.ServeConn->http2serverConn.serve->http2serverConn.writeFrame->http2serverConn.scheduleFrameWrite->http2serverConn.startFrameWrite->http2serverConn.readFrames->http2Framer.ReadFrame->http2serverConn.processFrameFromReader->http2serverConn.processFrame->http2serverConn.processHeaders->http2serverConn.newWriterAndRequest->http2serverConn.newWriterAndRequestNoBody->http2serverConn.runHandler->http2serverConn.processData

http2chunkWriter.Write->http2responseWriterState.writeChunk->http2serverConn.writeHeaders->http2serverConn.writeDataFromHandler->http2serverConn.writeFrameFromHandler->http2serverConn.writeFrame

http2ClientConn.encodeHeaders->http2ClientConn.writeHeader->Encoder.WriteField

HTTP2.0:
https://httpwg.org/specs/rfc9113.html https://httpwg.org/specs/rfc7541.html
HTTP2.0和HTTP1.1区别:
多路复用/二进制分帧层/首部压缩/HTTP2支持服务器推送,HTTP2.0是在SPDY基础上形成的下一代HTTP,目的是通过支持请求与响应的多路复用来较少延迟,通过压缩HTTPS首部字段将协议开销降低,同时增加请求优先级和服务器端推送的支持,二进制分帧层将所有的传输信息分割为更小的消息和帧,进行二进制格式编码
frame:
帧首部(帧长度24+帧类型8+flags8)+流标识符31+优先值31+帧净荷
帧类型:
DATA(0x0)用于传输HTTP消息体;HEADERS(0x1)用于传输首部字段,SETTINGS(0x4)用于约定客户端和服务端的配置数据比如设置初识的双向流量控制窗口大小;WINDOW_UPDATE(0x8)用于调整个别流或个别连接的流量;PRIORITY(0x2)用于指定或重新指定引用资源的优先级;RST_STREAM(0x3)用于通知流的非正常终止;PUSH_PROMISE(0x5)服务端推送许可;PING(0x6)用于计算往返时间执行活性检活;GOAWAY(0x7)用于通知对端停止在当前连接中创建流
flags:
用于不同的帧类型定义特定的消息标志,比如DATA帧就可以使用End Stream:true表示该条消息通信完毕,Data:EndStream(0x1)/Padded(0x8);Headers:EndStream(0x1)/EndHeaders(0x4)/Padded(0x8)/Priority(0x20);Settings:Ack(0x1);Ping:Ack(0x1)
流标识位:
表示帧所属的流ID
优先值:
用于HEADERS帧表示请求优先级,流可以带有一个31bit的优先级,0表示最高优先级
消息:
一系列DATA帧和HEADERS帧组成了请求消息
stream:
是连接中的一个虚拟信道,可以承载双向消息传输,每个流有唯一整数标识符,为了防止两端流ID冲突,客户端发起的流具有奇数ID,服务器端发起的流具有偶数ID,所有HTTP2.0通信都在一个TCP连接上完成, 这个连接可以承载任意数量的双向数据流Stream,每个数据流以消息的形式发送而消息由一或多个帧组成,这些帧可以乱序发送,然后根据每个帧首部的流标识符重新组装
多路复用:
HTTP2.0成功解决了HTTP1.x的队首阻塞问题(TCP层的阻塞仍无法解决)
服务端推送:
服务端可以根据客户端的请求,提前返回多个响应,推送额外的资源给客户端,PUSH_PROMISE帧是服务端向客户端有意推送资源的信号,如果客户端不需要服务端Push,可在SETTINGS帧中设定服务端流的值为0禁用此功能;PUSH_PROMISE帧中只包含预推送资源的首部,如果客户端对PUSH_PROMISE帧没有意见,服务端在PUSH_PROMISE帧后发送响应的DATA帧开始推送资源,如果客户端已经缓存该资源,不需要再推送,可以选择拒绝PUSH_PROMISE帧;PUSH_PROMISE必须遵循请求-响应原则,只能借着对请求的响应推送资源
首部压缩:
首部压缩技术,压缩算法HPACK,在客户端和服务端之间使用首部表来跟踪和存储之前发送的kv,首部表在连接过程中始终存在,新增的kv会更新到表尾,不需要每次通信都需要再携带首部,静态表(从1开始计数,一共61个)/动态表(从62开始计数),SETTINGS可以设置动态表size,kv采用哈夫曼编码,编码:操作码/在表中的索引(这个索引可能是hearder中key值的索引也可能是整个键值对的索引)/是否使用哈夫曼编码/key的长度/key的编码/value的长度/value的编码
HPACK编码:
只有index:1xxx xxxx(x代表index的值),如果index>=127,1111 1111 0/1xxx xxxx(0代表后面没值了,1代表后面还有值)每个字节存7位
index+value:01xx xxxx(x代表index的值),如果index>=63,0111 1111 同上
key+value:0100 0000 0xxx xxxx(x代表字符串长度),后面直接跟字符串
sensitive:0001
不修改index:0000
更新动态表size:0010
SPDY:
DEFLATE压缩头部字段,有CRIME漏洞(Compression Ratio Info-leak Made Easy)
基于ALPN的协商过程:
支持HTTP2.0的浏览器可以在TLS会话层自发完成和服务端的协议协商以确定是否使用HTTP2.0通信,TLS1.2中引入了扩展字段以允许协议的扩展,ALPN协议(Application Layer Protocol Negotiation,应用层协议协商,前身是NPN)
基于HTTP的协商过程: HTTP Upgrade机制
HTTP Upgrade request
GET / HTTP/1.1
host: xxx
connection: Upgrade, HTTP2-Setting
upgrade: h2c
http2-settings: xxx

HTTP Upgrade request
HTTP/1.1 101 Switching Protocols
Connection: Upgrade
Upgrade: h2c

grpc:
gin: 路由匹配用的是前缀树算法
fasthttp: nethttp更稳定,fasthttp中Request/Response结构体通过sync.Pool获取,内部大量使用了sync.Pool去提高性能,减少[]byte转换string,不支持http2.0,复用goroutine/协程池通过chan唤醒或退出;两者都支持在服务端接收大的body(multipart/form-data数据)的时候把数据先放到磁盘,都支持流式读取body数据;fasthttp与nethttp对responsebody处理的不同之处,fasthttp会等用户handler返回才会开始写body,nethttp内部用了个2kb的缓冲区,如果写满了handler仍然没有返回,会自动切换为chunked编码然后开始写响应头和body,这之后再更改响应头就无效

wasm
iface/eface _type/_func itab symtab traceback
编译器/汇编/链接器/ast
反射reflect
cgo
C++
Rust


2.MySQL
聚族索引和非聚族索引
覆盖索引
前缀索引
主键索引 普通索引 唯一索引 联合索引 全文索引
InnoDB和MyISAM
索引B树和B+树
B树的所有节点既存放键(key)也存放数据(data),而B+树只有叶子节点存放key和data,其他内节点只存放key
B+树的叶子节点有一条引用链指向与它相邻的叶子节点

执行流程
mvcc 快照读 当前读 ReadView
隔离级别 读取未提交 读取已提交 可重复读 可串行化

InnoDB 通过数据行的 DB_TRX_ID 和 Read View 来判断数据的可见性
DB_TRX_ID(6字节): 表示最后一次插入或更新该行的事务 id
DB_ROLL_PTR(7字节): 回滚指针，指向该行的 undo log
DB_ROW_ID(6字节): 如果没有设置主键且该表没有唯一非空索引时，InnoDB会使用该id来生成聚簇索引

redo log
undo log
binlog
relay log

Record lock 记录锁 单条索引记录上加锁
Gap lock 间隙锁 锁住一个索引区间(开区间,不包括双端端点) 防止幻读,保证索引间的不会被插入数据
Next-key lock 临键锁 = Gap Lock + Record Lock 为了解决幻读 左开右闭区间
自增锁
意向锁 意向共享锁IS 意向排它锁IX 表级别锁
插入意向锁: 间隙锁的一种,专门针对insert操作,多个事务在同一个索引同一个范围区间插入记录时候,如果插入位置不冲突,不会彼此阻塞
select ... lock in share mode  S锁 共享锁
select ... for update X锁 排他锁

ACID 原子性 一致性 隔离性 持久性

脏读
幻读
不可重复读

回表

连接器 查询缓存、分析器、优化器、执行器

Buffer Pool
redo log buffer

分库分表
主从复制
读写分离

数据库三范式: 每列保持原子性 每列都和主键相关 每一列数据都和主键直接相关而不能间接相关
MySQL死锁

TIMESTAMP: 把客户端插入的时间从当前时区转化为UTC,查询时将其又转化为客户端当前时区进行返回;'1970-01-01 00:00:01.000000'to'2038-01-19 03:14:07.999999';插入NULL会自动赋值当前时间;4个字节;相对快
DATETIME: 原样输入和输出;'1000-01-01 00:00:00.000000'to'9999-12-31 23:59:59.999999';插入NULL就是NULL;8个字节;相对慢

utf8是1字符3字节,gbk是1字符2字节
utf8mb4的编码,mb4就是most bytes 4的意思,专门用来兼容四字节的unicode,好在utf8mb4是utf8的超集,除了将编码改为utf8mb4外不需要做其他转换
CHAR: 字符数而不是字节数;最大值为255字符;长度固定;速度快;CHAR(M)每个值都占用M个字节,如果某个长度小于M就会在它的右边用空格字符补足;
VARCHAR: 字符数而不是字节数;最大值为65535字节;可变长;速度慢;VARCHAR(M)每个值只占用刚好够用的字节再加上一个用来记录其长度的字节;
TEXT: 申明时不设置最大长度;最大65535字节;最慢
BLOB: 二进制

LIMIT: LIMIT offset,n; LIMIT n; LIMIT n OFFSET offset;
GROUP BY
ORDER BY ASC/DESC
INNER JOIN/LEFT JOIN/RIGHT JOIN/CROSS JOIN/OUTER JOIN
LIKE
UNION
COUNT/SUM/AVG/MAX/MIN
DISTINCT
HAVING
USING
IS NULL/IS NOT NULL
IN/NOT IN
BETWEEN
AS
EXISTS
存储过程
定时任务


3.NoSQL
MongoDB
LevelDB
TiDB

ElasticSearch:
Shard/Replica 倒排索引 master/data/ingest/coodrinating only
Logstash/Kibana/filebeat/Flume

Etcd/ZooKeeper/Nacos/Consul
Ceph
Nginx
Keepalived/Haproxy/LVS
Promethous/Grafana
MinIO


4.Redis
string SDS 长度不能超过512M int编码 raw编码 embstr编码
hash hashtable ziplist(列表保存元素个数小于512个&每个元素长度小于64字节)
list linkedlist ziplist(列表保存元素个数小于512个&每个元素长度小于64字节)
set hashtable intset(集合对象中所有元素都是整数&集合对象所有元素数量不超过512)
zset skiplist&字典 ziplist(保存的元素数量小于128&每个元素长度小于64字节)

AOF
RDB 快照 save&bgsave dump.rdb
RDB在恢复大数据集时的速度比AOF的恢复速度要快

HyperLogLog
PUB/SUB
事务 MULTI EXEC DISCARD UNWATCH WATCH
Lua EVAL "return {KEYS[1],KEYS[2],ARGV[1],ARGV[2]}" 2 key1 key2 first second
Redis GEO
Redis Stream
Redis Pipeline
Redis Bitmap

redis缓存击穿(热点key不失效或加锁)、缓存穿透(不存在的key设置空value和过期时间)、缓存雪崩(key失效时间不同)

redis和mysql数据一致性保证:
强一致性 弱一致性 最终一致性
Pattern: Cache-Aside/旁路缓存模式 Read-Through/Write-Through/读写穿透 Write-Behind/异步缓存写入
延时双删: 先删除缓存 再更新数据库 休眠一会再次删除缓存
同步binlog

读操作:
读到缓存直接返回
读不到缓存,先去DB读数据,再更新到缓存,再返回
写操作:
先写DB,删除缓存
问题:
A读了数据库还未更新缓存
B修改数据库
A再去更新缓存
数据不一致
解决办法加短的过期时间

单节点
主从 replicaof 127.0.0.1 7000
redis cluster
redis cluster+主从
主从+哨兵

daemonize yes
bind 127.0.0.1
port 7000
dir /home/thomas/server/redis/data/redis-7000
pidfile /var/run/redis/redis-7000.pid
logfile /home/thomas/server/redis/log/redis-7000.log
cluster-enabled yes
cluster-config-file /home/thomas/server/redis/conf/cluster-7000.conf
cluster-node-timeout 10000

rm -rf cluster data log
mkdir cluster data log
mkdir data/redis-7000 data/redis-7001 data/redis-7002 data/redis-8000 data/redis-8001 data/redis-8002 data/sentinel-9000 data/sentinel-9001 data/sentinel-9002

./redis-server /home/thomas/server/redis/conf/redis-7000.conf
./redis-cli -p 7000
./redis-cli --cluster create 127.0.0.1:7000 127.0.0.1:7001 127.0.0.1:7002
./redis-cli -c -p 7000
./redis-cli --cluster check 127.0.0.1:7000
./redis-cli --cluster reshard 127.0.0.1:7000
./redis-cli -p 7000 cluster nodes
./redis-cli --cluster add-node 127.0.0.1:7003 127.0.0.1:7000
./redis-cli --cluster add-node 127.0.0.1:8000 127.0.0.1:7000 --cluster-slave
./redis-cli --cluster add-node 127.0.0.1:8001 127.0.0.1:7000 --cluster-slave --cluster-master-id 7f3541c3b2e8bd05226729e9889a338b341cd77e
./redis-cli --cluster del-node 127.0.0.1:7000 3adfaaeb6d60f39e70562d961fe7fae200913386

port 9000
daemonize yes
logfile /home/thomas/server/redis/log/sentinel-9000.log
pidfile /var/run/redis/sentinel-9000.pid
dir /home/thomas/server/redis/data/sentinel-9000

sentinel monitor mymaster 127.0.0.1 7000 2
sentinel down-after-milliseconds mymaster 1500
sentinel failover-timeout mymaster 30000

./redis-sentinel /home/thomas/server/redis/conf/sentinel-9000.conf
./redis-cli -p 9000
sentinel master mymaster


5.MQ 异步/解耦/削峰
Kafka
消息永久保存,定期删除
topic partition ISR/OSR/AR
pull方式消费消息

Consumer Group:
多个消费者组成一个group,组内的所有消费者协调在一起来消费订阅主题的所有分区,每个分区只能由同一个消费组内的一个consumer来消费,避免重复消费,
记录offset到__consumer_offsets kafka自带的topic(记录到具体哪个分区hash(groupID) % numPartitions)

自动提交/手动提交: enable.auto.commit = true

Rebalance:
组成员发生变更/订阅主题数发生变更/订阅主题的分区数发生变更
coordinator来执行对于consumer group的管理,从consumer group选出一个leader并且generation+1,leader生成具体消费方案,leader把生成的方案发给coordinator,coordinator再同步给所有consumer
Heartbeat请求: consumer需要定期给coordinator发送心跳来表明自己还活着
LeaveGroup请求: 主动告诉coordinator我要离开consumer group
SyncGroup请求: group leader把分配方案发给coordinator,coordinator再告诉组内所有成员
JoinGroup请求: 成员请求加入组
DescribeGroup请求: 显示组的所有信息，包括成员信息，协议名称，分配方案，订阅信息等。通常该请求是给管理员使用

生产者幂等性:
ProducerID(每个新的Producer在初始化的时候会被分配一个唯一的PID)
SequenceNumber(对于每个PID,该Producer发送数据的每个<Topic,Partition>都对应一个从0开始单调递增的SequenceNumber)
只能保证单个partition内的幂等性,只能保证Producer在单个会话内不丟不重

事务:
涉及到多个Topic-Partition的写入时,这个事务操作要么会全部成功,要么会全部失败
initTransactions beginTransaction commitTransaction/abortTransaction
transactionalID由用户提供,和ProducerID+epoch组成唯一值
TransactionCoordinator __transaction_state
isolation.level read_committed/read_uncommitted
LEO: 日志末端位移(log end offset),最后一条消息的下一条消息的位移值
HW: 水位值,HW值不会大于LEO值,小于等于HW值的所有消息都被认为是已备份的,consumer无法消费分区下leader副本中位移值大于分区HW的任何消息,Kafka使用HW值来决定副本备份的进度
LSO:

log:
每个partition都有一个目录,里面有很多segment file
partition的第一个segment从0开始,后续每个segment文件名为上一个segment文件最后一条消息的offset
.index 文件名是消息总偏移 内容: 消息偏移(每个index都从0开始,稀疏索引,不是连续的)+字节偏移offset
.log
.timeindex CreateTime表示producer创建这条消息的时间,LogAppendTime leader broker将这条消息写入到log的时间

RabbitMQ
消息消费完就删除
AMQP/高级消息队列协议
routing-key/路由
交换器/Exchange: direct/fanout/topic/headers
支持pull、push方式消费消息

消息丢失:
生产者 事务(同步阻塞慢) 发送确认(异步快)(确认成功就在数据库设置标记,否则重新发送消息,未确认的消息也可存在内存/本地磁盘/redis)
broker 持久化Exchange、Queue、Message
消费者 改为手动提交(自动提交在broker发送消息到消费端就会删除) autoAck=false

死信交换机/死信队列:
默认情况下queue中被抛弃的消息将被直接丢掉,但是可以通过设置queue的x-dead-letter-exchange参数将被抛弃的消息发送到指定的exchange中
消费方nack/reject时指定了requeue=false、消息的TTL已到、消息队列的max-length已到
设置队列中所有消息的过期时间x-message-ttl,队列最大消息数x-max-length,生产者设置单个消息的expiration
Alternate Exchange: 发送消息的时候根据routing-key没有对应的队列接受消息,这就会将此消息路由到Alternate Exchange属性指定的Exchange上了,如果mandatory=true则会将消息返回给生产者
如果发送到A消费者的消息一直不确认,只有等到A消费者与rabbitmq的连接中断,rabbitmq才会考虑将A消费者未确认的消息重新投递给另一个消费者

Ack: 确认后删除消息; Reject: 只能拒绝一个; Nack: 可以拒绝多个

Message:
expiration 消息的过期时刻
deliveryMode 1为非持久化,2为持久化
Queue:
durable 持久化
exclusive 该队列仅对首次声明他它的连接可见,并在连接断开时自动删除
autoDelete 所有与这个连接的消费者都断开时会自动删除
Exchange:
durability 持久化
autoDelete 与这个Exchange绑定的Queue或Exchange都与此解绑时,会删除本交换器

requeue重新放入队列,是立即可以再次消费还是等多长时间?
没有ack后多久可以再次消费此消息?

集群:
普通集群 队列只会存在一个节点,存在哪个节点,是固定的一个还是随机分散?
镜像队列 主从模式,针对的是队列不是节点,push操作会在主从的每个节点上执行一次,消费操作在master执行然后广播给每个slave;
        新增加一个节点需要配置才会同步master所有数据,并且同步时会阻塞

延时队列: 死信队列+ttl 插件rabbitmq-delayed-message-exchange
优先队列: 队列设置的x-max-priority,消息设置队列设置的priority,优先级越大越先消费

事务:
txSelect txComment txRollback

RocketMQ
消息永久保存,定期删除
支持pull、push方式消费消息
NameServer: 路由控制中心,NameServer之间没有数据同步,Broker上报信息到NameServer
Broker: 多主多从,只有主Broker节点才能写,当master宕机,master上的队列不可写入,但是读取依然是可以的
生产消息: SendSync/SendAsync/SendOneWay

Topic:
主题,创建topic时指定读写队列数量,可以指定broker创建也可以让集群自动分配
mqadmin updateTopic
mqadmin deleteTopic
mqadmin updateSubGroup
mqadmin deleteSubGroup
mqadmin updateTopicPerm
mqadmin consumerProgress
writeQueueNums/readQueueNum: 方便队列的缩容和扩容

Tag: 子主题
GroupName: 生产者组合或消费者组合
ProducerGroup: 
ConsumerGroup: 一个Queue最多只能分配给一个Consumer

主从:
slave向master报告自己的最大偏移量
master向slave返回偏移量后的CommitLog数据
brokerId=0表明这个broker是master,brokerId>0表明这个broker是slave
slave只负责读,rocketmq目前还不支持主从切换,需要手动切换
正常情况下consumer并不能配置从master读还是slave读,本次拉取的数据量大于物理内存的40%和当master不可用或者繁忙的时候consumer会从slave读
master可配置同步复制SYNC_MASTER/异步复制ASYNC_MASTER

Rebalance: 
订阅Topic的队列数量变化(broker宕机、队列扩容/缩容)/消费者组信息变化(消费者宕机、消费者扩容/缩容、Topic订阅信息发生变化)
一个队列最多分配给一个消费者,offset是异步提交造成重复消费,Broker端负责Rebalance元数据维护
周期性触发rebalance
同一个消费者组订阅多个Topic时可能会出现分配不均
对Topic队列/消费者各自进行排序,每个消费者需要使用相同的分配策略

广播消费:
广播模式消费位移使用本地文件存储,Rebalance过程中同一个ConsumeGroup下的consumer不会进行MessageQueue的分配,每个consumer负责订阅的topic下的所有MessageQueue

log:
commitLog存消息数据
consumeQueue存索引
config存Group/Topic/Consumer消费的offset
超时时间/磁盘占比/人工删除触发删除commitLog/consumeQueue

offset: 当消费模式为广播模式时offset使用本地模式存储;集群模式下存在config
消息堆积: 增加consumer;放到临时的topic再增加新的consumer去消费

延时队列:
生产消息时设置,只能选择1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h(可以改配置文件增加level),level从1开始;消息按照延迟时间段发送到指定的延时队列(SCHEDULE_TOPIC_XXXX)中,定时器进行轮训这些队列查看消息是否到期,如果到期就把这个消息发送到指定topic的队列中,这样的好处是同一队列中的消息延时时间是一致的,还有一个好处是这个队列中的消息是按照消息到期时间进行递增排序的,然后把延迟队列中的消息删除

死信队列:
%DLQ%+consumerGroup
消费失败自动进行消息重试,达到最大重试次数后将其发送到该消费者对应的特殊队列中,有效期与正常消息相同到期自动删除
一个死信队列对应一个GroupID

重试:
广播消息是不会重试的
生产端重试: 生产端自动重试,可设置超时时间和重试次数,异步发送重试次数只有1/0次
消费端重试: 主动返回RECONSUME_LATER消息会进入重试队列,超过最大重试次数就进入死信队列;超时重试是直接重试不需要延时,会一直重试下去;message携带重试次数消费端可以用来判断
重试队列: 先保存到SCHEDULE_TOPIC_XXXX中,再设置偏移量,后台定时任务按照对应的时间进行Delay后重新保存至%RETRY%+consumerGroup重试队列中,消费者消费重试队列

事务:
prepare阶段
commit/rollback阶段

ActiveMQ
JMS
kahadb leveldb mysql
topic
P2P: 生产者向队列投递一条消息,只有一个消费者能够监听得到这条消息
Pub/Sub: 生产者向队列投递一条消息,所有监听该队列的消费者都能够监听得到这条消息
与zookeeper进行构建主备集群模型
Network集群模型

Pulsar

优先队列
延时队列
消息丢失
重复消费 幂等
顺序消费
消息堆积
事务


6.网络/TCP/IP/UDP
物理层
数据链路层 ARP RARP
网络层 IP ICMP IGMP
传输层 TCP UDP
应用层 HTTP FTP TFTP SMTP DNS

三次握手 避免重复连接
四次挥手
粘包
DDOS
半连接队列
全连接队列

最大传输单元(MTU) 1500字节
MSS （最大报文段长度）536

SYN Flood
Syn Cache: 不直接分配TCB,使用更少的数据记录状态
Syn Cookie: 无状态的三次握手
cookie源认证: 记录sequence number,将真实客户端IP加入白名单
reset认证: reset报文,将真实客户端IP加入白名单

慢启动 慢启动门限(ssthresh) 65536 指数增长
拥塞避免 线性增长 重传了一个报文段 ssthresh=cwnd/2 cwnd=1 进入慢启动
快速重传 收到3个相同的ACK ssthresh=cwnd/2 cwnd=ssthresh 进入拥塞避免
快速恢复
窗口值的大小就代表能够发送出去的但还没有收到ACK的最大数据报文段
拥塞窗口(cwnd)
接收窗口(rwnd)


7.HTTP1.1 TLS/SSL websocket HTTP2
GET(获取资源)/POST(创建修改资源)/PUT(幂等)/HEAD(验证uri是否有效不返回body)/DELETE(删除资源)
CONNECT: HTTP1.1的方法,隧道代理使用CONNECT方法建立连接,开启一个客户端与所请求资源之间的双向沟通的通道,客户端要求代理服务器将TCP连接作为通往目的主机隧道,之后该服务器会代替客户端与目的主机建立连接,连接建立好之后代理服务器会面向客户端发送或接收TCP消息流
OPTIONS: 用来询问服务器对应路由支持哪些方法,也可以传递*获取整个服务器支持的方法;检测某个接口是否支持跨域,复杂跨域请求之前先发送一个OPTIONS请求,浏览器根据返回的Access-Control-Allow-Origin,Access-Control-Allow-Headers,Access-Control-*来判断当前网页能否请求跨域资源
TRACE: 原样返回任意客户端请求的任何内容,主要用于测试或诊断,追踪路劲

状态码:
1xx 信息响应
2xx 成功响应
3xx 重定向
4xx 客户端错误
5xx 服务器错误

100 Continue客户端应当继续发送请求
200 请求成功
204 No Content成功处理但在返回的响应报文中不含实体的主体部分
301 MovedPermanently 资源（网页等）被永久转移到其它URL
302 Found 临时移动,与301类似,但资源只是临时被移动,客户端应继续使用原有URI
304 Not Modified未修改,自从上次请求后请求的网页未修改过服务器返回此响应时不会返回网页内容
400 Bad Request
401 Unauthorized
403 Forbidden
404 请求的资源（网页等）不存在
500 InternalServerError
501 NotImplemented
502 BadGateway
503 ServiceUnavailable
504 GatewayTimeout
505 HTTPVersionNotSupported

请求体:
包含请求方法、URI、HTTP版本信息
header
body

响应体:
包含HTTP版本、状态码、状态码的原因短语
header
body

Request Headers:
Host: a.com
Trailer: key1标识在body的后面会有类似key1: value1的首部字段,Trailer可以使用在HTTP/1.1版本分块传输编码时
Connection: close通知对端自己发送完数据会断开链接(HTTP1.0默认方式)、keep-alive通知对端自己发送完数据不会断开链接(HTTP1.1默认方式)
Accept-Encoding: gzip, deflate, br
Accept-Language: zh-CN,zh;q=0.9
Accept: "/"
Accept-Control-Request-Headers: xx
Accept-Control-Request-Method: POST
Cookie: a=1; b=2
Authorization: xxx
Origin: https://a.com
Referer: https://a.com
User-Agent: Mozilla/5.0

Response Headers:
Date: Wed, 20 Jul 2022 13:00:45 GMT
Server: xxx
Content-Type: application/json;charset=utf-8  text/html  image/jpeg  application/javascript  application/xml
Content-Length: 200
Content-Encoding: gzip
Content-Language: zh-CN
Content-Md5: xxx
Transfer-Encoding: chunked 分块传输
Cache-Control: max-age=31536000 no-cache
Pragma: no-cache(禁用缓存) Pragma旧产物 优先级从高到低是Pragma->Cache-Control->Expires
Location: a.com/b  重定向
Set-Cookie: status=enable; expires=Tue, 05 Jul 2018 02:01:22 GMT; path=/; domain=.example.com;
Allow: HEAD,GET,POST
Access-Control-Allow-Origin: *
Access-Control-Allow-Methods: GET, POST, PUT
Access-Control-Allow-Credentials: true 表示是否允许发送Cookie
Access-Control-Allow-Headers: X-Custom-Header
Access-Control-Max-Age: 3600  设置在3600秒不需要再发送预校验请求
Access-Control-Expose-Headers: FooBar

Cookie: NAME=VALUE; expires=DATE; Max-Age=3600(存活多少秒,IE不支持); path=PATH; domain=域名(域名匹配才会带上cookie); Secure(仅在HTTPS时才会发送) HttpOnly(使Cookie不能被js脚本访问,其主要目的为防止跨站脚本攻击Cross-sitescripting/XSS对Cookie的信息窃取)

缓存控制:
Pragma: 有两个字段Pragma和Expires,Pragma的值为no-cache时表示禁用缓存,Expires表示该缓存的有效时间
Cache-Control: 请求,no-cache(不使用缓存要向原服务器发起请求)/no-store(内容不保存到缓存)/max-age(告知server,client可以接收一个存在时间不超过多少秒的资源);响应,no-cache(不使用缓存要向server发起请求)/no-store(内容不保存到缓存)/max-age(告知client资源在多少秒内是新鲜的无需向server发起请求),no-store优先级最高
缓存校验:
Last-Modified: 服务端在返回资源时会将该资源的最后更改时间通过Last-Modified字段返回给客户端,客户端下次请求时通过If-Modified-Since或者If-Unmodified-Since带上Last-Modified,服务端检查该时间是否与服务器的最后修改时间一致:如果一致则返回304状态码,不返回资源;如果不一致则返回200和修改后的资源并带上新的时间,If-Modified-Since(告诉服务器如果时间一致返回状态码304),If-Unmodified-Since(告诉服务器如果时间不一致返回状态码412)
etag: 服务器通过某个算法对资源进行计算取得一串值(类似于文件的md5值)之后将该值通过etag返回给客户端,客户端下次请求时通过If-None-Match或If-Match带上该值,服务器对该值进行对比校验,如果一致则不要返回资源,If-None-Match(告诉服务器如果一致,返回状态码304,不一致则返回资源),If-Match(告诉服务器如果不一致,返回状态码412)

跨域CORS: 跨域资源共享,同源(协议域名端口号都一样)策略,当前网页访问一个host和自己不一样的服务器,这时浏览器为了安全会根据一些条件判断是否能请求并且接收到响应,对于复杂请求先发送OPTIONS预检请求(preflight),通过OPTIONS的响应判断是否能进行跨域请求,一旦服务器通过了预检请求,以后每次浏览器正常的CORS请求,就都跟简单请求一样会有一个Origin头信息字段;对于简单请求(HEAD/GET/POST,头部不超过Accept、Accept-Language、Content-Language、Last-Event-ID、Content-Type:只限三个application/x-www-form-urlencoded、multipart/form-data、text/plain)则直接请求,浏览器在请求头部插入Origin,浏览器判断响应是否允许跨域决定是否将响应给到页面
JSONP只支持GET请求,CORS支持所有类型的HTTP请求,JSONP的优势在于支持老式浏览器,以及可以向不支持CORS的网站请求数据

CSRF/XSRF XSS
JWT Session Token

SSRF:由攻击者构造形成由服务端发起请求的一个安全漏洞,一般情况下,SSRF攻击的目标是从外网无法访问的内部系统,正是因为它是由服务端发起的所以它能够请求到与它相连而与外网隔离的内部系统;形成的原因大都是由于服务端提供了从其他服务器应用获取数据的功能且没有对目标地址做过滤与限制,比如从指定URL地址获取网页文本内容,加载指定地址的图片,下载

TLS:
OCSP: 在线证书状态协议验证SSL证书的有效性,以确保它未被吊销
NPN/ALPN protocol: 是TLS的扩展允许在安全连接的基础上进行应用层协议的协商,协商使用HTTP1.1还是HTTP2.0
https://www.thesslstore.com/blog/explaining-ssl-handshake
密码套件: TLS_RSA_WITH_AES_128_GCM_SHA256/TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA 密钥交换算法 + 签名算法 + 对称加密算法 + 摘要算法
非对称加密需要应用到复杂的数学运算,虽然保证了安全,但速度很慢
加密套件列表: openssl ciphers -v
数字证书的签发流程:
CA会把一些基本信息例如持有者、用途、有效信息等打包,然后运用Hash算法得到一个Hash值
CA会使用自己的私钥将这个Hash值加密,生成一个Certificate Signature证书签名,CA对证书进行了签名
最后将签名加到证书文件形成数字证书
客户端验证证书的流程:
客户端使用同样的Hash算法,得到该证书的Hash值H1
浏览器使用CA的公钥,解密Certificate Signature中的内容,得到Hash值H2
如果H1等于H2则证明可信
Session ID: 为第一次握手时候发送的Session ID字段的值,服务器端会维护对于该Session ID对应的通信密钥,当Client再次连接的时候,只需要在头部中加上Session ID,即可通知Server重新使用上次协商过的通信密钥进行通信,这样就不需要每一次都重新协商来浪费资源,同时由于不需要完整的握手过程,所以握手时间也减少了1 RTT
Session Ticket: Server会在握手结束后向Client发送被加密的恢复连接所需要的数据,同时Server无需保存任何信息,且由于此时握手已经完成,所以信道是安全的,在下次建立TLS连接时,Client只需要在第一次握手时发送上次收到的被加密的恢复连接所需的数据,Server则可以通过只有自己知道的密钥解密该握手数据,并重新使用上次的通信密钥
为什么会有pre_master: 兼容RSA和DH算法

TLS 1.0-TLS 1.2: 耗时2-RTT TLS 1.0 = SSL 3.1
RSA算法:
1.client->Client Hello->server
加密套件列表+client_random+压缩算法+Session ID+SSL/TLS版本
2.1.client<-Server Hello<-server
选择使用的加密套件+server_random+压缩方法+Session ID+SSL/TLS版本
2.2.client<-Certificate/Server Key Exchange/Server Hello Done<-server
服务端证书(包括公钥+签名+持有者信息+有效时间+证书认证机构CA的信息)
3.1.client->Client Key Exchange->server
客户端验证服务端证书,通过后客户端生成一个预主密钥然后从服务器发送的证书中提取公钥,利用证书的公钥对预主密钥进行RSA加密再发送给服务端,此时客户端开始根据client_random+server_random+预主密钥生成主密钥,此密钥用于给后续传输的数据进行加解密
3.2.client->ChangeCipherSpec/Finished->server
告诉服务端它后续将切换到使用协商好的加密密钥对数据进行加密再传输
4.client<-ChangeCipherSpec/Finished<-server
从消息中提取加密过的预主密钥然后拿证书的私钥解密获取预主密钥,服务端根据预主密钥+client_random+server_random生成主密钥,告诉客户端后续将切换到使用协商好的加密密钥对数据进行加密再传输

DH算法: Diffie-Hellman
客户端和服务器都各自产生一个随机数,生成一个私钥,然后根据公开的DH算法算出自己的公钥,再把这个公钥通过TLS互换,只要有了自己的私钥和对方的公钥,就可以解密报文,即使公钥被截取了,在不知道私钥的情况下也无法计算出密钥,但是DH算法存在计算效率的问题,所以出现了ECDHE密钥协商算法
客户端与服务端都需要各自生成一对公私钥,交换各自本次会话临时生成的密钥对的公钥
客户端私钥+服务端公钥,根据椭圆算法算出预主密钥
服务端私钥+客户端公钥,根据椭圆算法算出预主密钥
1.client->Client Hello->server
加密套件列表+client_random+压缩算法+Session ID+SSL/TLS版本
2.client<-Server Hello<-server
服务端返回使用的加密套件+server_random+压缩方法+Session ID+SSL/TLS版本,服务端证书(包括公钥+签名+持有者信息+有效时间+证书认证机构CA的信息),同时服务器利用私钥将client_random,server_random,server_params签名,然后将签名和server_params发送给客户端
3.client->server
客户端验证服务端证书和server_params签名,通过后将client_params传递给服务器,此时客户端通过client_params+server_params生成预主密钥(因ECDHE计算基于椭圆曲线离散对数通过这两个DH参数就能计算出pre_random),客户端根据预主密钥+client_random+server_random生成主密钥,
告诉服务端它后续将切换到使用协商好的加密密钥对数据进行加密再传输
4.client<-server
通过client_params+server_params生成预主密钥,预主密钥+client_random+server_random生成主密钥,告诉客户端后续将切换到使用协商好的加密密钥对数据进行加密再传输

TLS 1.3: 耗时1-RTT
前向安全性: 指的是过去的通信的安全性不会受到未来的密钥泄露事件的影响
DHE/ECDHE算法: ECC椭圆曲线离散对数,ECDHE用于密钥交换,ECDSA用于数字签名
双方事先确定好使用什么椭圆曲线,和曲线上的基点G,两个参数都是公开的
双方各自随机生成私钥d,将G乘以私钥d得到公钥Q(Q=Gd),客户端的公私钥为d1和Q1,服务器的公私钥为d2和Q2
双方交换公钥,客户端计算d1Q2,服务器计算d2Q1,由乘法交换律和结合律得d2Q1 = d2d1G = d1d2G = d1Q2,双方的坐标都是一样的,实现了共享密钥
1.client->server
加密套件列表+TLS版本+client_random+client_params
2.client<-server
确认的加密套件+TLS版本+证书+server_random+server_params
服务端/客户端通过client_params+server_params生成预主密钥,再通过预主密钥+client_random+server_random生成主密钥

PSK: Pre-share key 0-RTT

websocket:
GET http://a.com HTTP/1.1
Host: http://a.com
Upgrade: websocket
Connection: Upgrade
Sec-WebSocket-Key: xxx
Origin: http://a.com
Sec-WebSocket-Version: 13
Sec-WebSocket-Protocol: a,b

HTTP/1.1 101 Switching Protocols
Upgrade: websocket
Connection: Upgrade
Sec-WebSocket-Accept: xxx
Sec-WebSocket-Protocol: a


8.Kubernetes
Pod Deployment Service DaemonSet StatefulSet ReplicaSet Job Label Namespace ConfigMap Secret Ingress
Volume PersistentVolume PersistentVolumeClaim StorageClass
kube-apiserver etcd kube-scheduler kube-controller-manager kubelet kube-proxy


9.微服务/服务网格
服务注册发现
链路追踪
Istio/Serverless


10.分布式
CAP
高并发
高可用
事务

唯一ID:
Snowflake,64位,第1位默认为0,接下来前41位是毫秒数时间戳,接下来的10位代表计算机ID,其余12位代表每台机器上生成ID的序列号
Uidgenerator
Leaf

限流 漏桶算法 令牌桶算法
熔断
降级
灾备
异地多活
Sentinel
秒杀
2PC/3PC/TCC
Raft/Paxos
CDN
SLB

11.操作系统
Reactor线程模型
汇编

linux:
sysconf/fpathconf/pathconf/confstr
gettimeofday/settimeofday
date/time/ctime/ftime
adjtime/adjtimex/clock_adjtime/ntp_adjtime
clock_gettime/clock_settime/clock_getres:根据clockid获取时间/设置时间/获取精确度
clock_getcpuclockid/pthread_getcpuclockid
getrlimit/setrlimit/prlimit

进程:
栈、堆
fork/vfork/clone
进程地址空间
进程池
execl/execlp/execle/execv/execvp/execvpe/execve
wait/waitpid/waitid/wait3/wait4
exit/_exit/_Exit/exit_group/on_exit/atexit
gdb/strace/ptrace
prctl/seccomp
getrusage
system
getpid/getppid
getcontext/setcontext/makecontext/swapcontext

进程调度:

线程:
轻量级进程,PCB/TCB,task_struct/thread_info/内核栈,slab分配器,线程有自己独立的内核栈
创建进程和线程底层都是调用clone系统调用,fork创建进程时clone不传参数则创建一个完整的进程,pthread_create创建线程时clone会传一些参数,共享地址空间
线程池
线程私有变量,pthread_key_create/pthread_setspecific/pthread_getspecific/pthread_key_delete
gettid
pthread_self

内存管理:
malloc/realloc/calloc/free/mmap
内存碎片
内存池
虚拟内存
页缓存和块缓存,页面回收和页交换,缺页中断
物理内存管理
MMU
slab分配器
多级cache L1 L2 L3

进程间通信IPC:
管道 命名管道FIFO 共享内存 消息队列 信号 UNIX域 socket DBUS
eventfd:把内存当文件,实际内部是一个8字节的计数器,read之后计数会清零,write则会递增计数器,如果计数器是0则不会通知可读

同步机制:
信号量 互斥量 条件变量 读写锁 自旋锁

futex: Fast userspace mutexes, 是一种用户态和内核态混合的同步机制,同步的进程间通过mmap共享一段内存,futex变量就位于这段共享的内存中且操作是原子的,当进程尝试进入互斥区或者退出互斥区的时候,先去查看共享内存中的futex变量,如果没有竞争发生则只修改futex而不用再执行系统调用了,当通过访问futex变量告诉进程有竞争发生,则还是得执行系统调用去完成相应的处理

文件系统:
vfs
ext3/ext4
fuse
statfs/fstatfs/stat/fstat/lstat/fstatat/statvfs/fstatvfs
readlink/readlinkat/symlink/symlinkat
access
chmod/fchmod/fchmodat/chown/fchown/lchown/fchownat
utime/utimes
realpath/getcwd/getwd/get_current_dir_name
chroot/chdir
open/read/write

IO多路复用:
poll select epoll

网络协议栈:
netfilter

设备驱动:
字符设备
块设备
网卡设备

系统调用

信号:
软中断 kill -l
kill 1234,默认SIGTERM,可以捕捉
kill -9 1234,SIGKILL,终止程序,不可捕捉
ctrl+c产生SIGINT默认反应是进程终止,可以捕捉
对于需要处理的信号,进程可以指定处理函数,由该函数来处理;也可以忽略某个信号;也可以对该信号的处理保留系统的默认值,大部分的信号缺省操作是使得进程终止
通过系统调用signal来指定进程对某个信号的处理行为
SIGSTOP只是要求进程暂时停下手头的工作,休息一下,直到听到SIGCONT的召唤
SIGKILL/SIGSTOP不能捕捉和忽略
SIGCHLD默认忽略
两个信号同时到达,同一种信号只能等前面的先执行完再执行后到的且相同的信号只保留一个,不同信号可以同时执行
fork子进程可以继承父进程的信号,execve时会把信号恢复到默认行为,已忽略的信号则可以完全地继承

当内核接收到信号后,会将其放到对应进程的信号队列中,同时向进程发送一个中断,使其陷入内核态
进程从内核态返回到用户态前进行信号检测,或者进程在内核态中,从睡眠状态被唤醒的时候进行信号检测
内核将当前内核栈的内容拷贝到用户栈上,并且修改指令寄存器eip将其指向信号处理函数
接下来进程返回到用户态中,执行相应的信号处理函数
信号处理函数执行完成后,还需要返回内核态,检查是否还有其它信号未处理
如果所有信号都处理完成,就会将内核栈恢复,从用户栈拷贝回来,同时恢复指令寄存器eip将其指向中断前的运行位置,最后回到用户态继续执行进程

设置信号处理函数,signal/sigaction,发送信号kill,向自己发信号raise,向线程发送信号,tkill,tgkill
signal:第一个参数是信号值1-64,第二个参数可以设置三种行为SIG_IGN/SIG_DFL/handler
signalfd:文件描述符接收信号,不接收SIGKILL/SIGSTOP
alarm/ualarm:定时多少秒后发送信号SIGALRM,默认终止进程,返回值是上一个alarm剩余的秒数,后一个alarm覆盖前一个alarm,alarm(0)会清除之前所有的alarm
sleep/usleep/nanosleep/clock_nanosleep:调用线程进入睡眠直到指定秒之后,如果有未忽略的信号到来则提前退出并返回剩余睡眠的秒数,如果是忽略的信号到来则不影响sleep,如果是信号的默认行为则取决于默认行为是什么
pause:调用进程/线程进入睡眠直到捕捉到信号并且信号处理函数返回
abort:即使捕捉信号进程也会终止
pthread_kill:类似kill,给线程发信号
sigaction:signal的升级版
sigprocmask/pthread_sigmask:阻塞信号;如果当前是阻塞状态,并且同一个信号发送了多次,当阻塞解除时只响应一个信号;函数本身不阻塞
sigpending:查询当前哪些信号处于pending状态
sigemptyset/sigfillset/sigaddset/sigdelset/sigismember:对sigset_t进行操作
sigsuspend:阻塞指定信号,即使接收到该信号也不返回,接收到其它信号才会返回,当sigsuspend返回后自动恢复mask成原来的值,指定信号在阻塞解除后会响应一次,保护不希望由信号中断的代码临界区
sigqueue/pthread_sigqueue:发送信号给指定pid,可以携带数据,sigqueue函数对不可靠信号不做排队,会丢失信号,kill只是单纯的递送对谁都不排队
sigwait/sigwaitinfo/sigtimedwait:阻塞指定信号,直到发现该信号是pending则返回,收到其它信号不返回
setitimer/getitimer:设置定时器,可重复执行定时任务,三种类型ITIMER_REAL/ITIMER_VIRTUAL统计进程的用户时间/ITIMER_PROF统计进程的用户时间和内核时间,对应信号SIGALRM/SIGVTALRM/SIGPROF
timer_create/timer_settime/timer_gettime/timer_getoverrun/timer_delete:创建定时器,通过信号来通知定时器到来
timerfd_create/timerfd_settime/timerfd_gettime:定时器,不会被信号影响
sigsetjmp/siglongjmp/longjmp/setjmp:调用setjmp的函数返回了上下文将变成无效,longjmp第二个参数成为setjmp的返回值
sigaltstack:设置额外的信号栈,用于执行信号处理函数
siginterrupt:系统调用被信号中断,可以重新开始(默认)/返回EINTR/如果有数据传输就返回传输成功的字节数
sigreturn:从信号处理函数返回,并清除栈帧

中断

常用命令:
cd mkdir rm grep find ln
netstat tcpdump lsof ifconfig
iostat fdisk du df iotop
free vmstat sar
top htop strace perf 


12.算法
栈/队列
排序
二叉树/平衡二叉树/红黑树
链表
动态规划
图
缓存LRU/LFU
字符串
radix tree

13.其它
utf-8:
Unicode只是一个符号集,它只规定了符号的二进制代码,却没有规定这个二进制代码应该如何存储,“严”的unicode是十六进制数U+4E25
utf-8是变长的编码方式,使用1~4个字节表示一个符号,utf-8编码方式:
0xxxxxxx
110xxxxx 10xxxxxx
1110xxxx 10xxxxxx 10xxxxxx
11110xxx 10xxxxxx 10xxxxxx 10xxxxxx

设计模式
音视频/流媒体
推荐系统
人工智能
大数据
云计算
web安全
