1.Golang
slice:
只能判断slice==nil,不能slice1==slice2
扩容规则:
go1.18前:
如果新容量大于两倍的旧容量那么直接使用这个新容量当成扩容容量
如果新容量小于两倍的旧容量并且旧容量小于1024时,扩容容量等于旧容量的2倍
如果新容量小于两倍的旧容量并且旧容量大于1024时,扩容容量等于旧容量的1.25倍,循环newcap=1.25newcap(初始newcap=旧容量),直到扩容容量大于等于新容量
遵循内存对齐规则(计算使用的是扩容容量*数据类型size)
切片扩容机制与切片的数据类型,原本切片的容量,所需要的容量都有关系
go1.18后:
如果新容量大于两倍的旧容量那么直接使用这个新容量当成扩容容量
如果新容量小于两倍的旧容量并且旧容量小于256时,扩容容量等于旧容量的2倍
如果新容量小于两倍的旧容量并且旧容量大于256时,扩容容量等于旧容量的1.25倍+192,循环newcap=1.25newcap+(3*256)/4(初始newcap=旧容量),直到扩容容量大于等于新容量(192是为了使容量变化更平滑,不至于从两倍直接变成1.25倍)
遵循内存对齐规则(计算使用的是扩容容量*数据类型size)
切片扩容机制与切片的数据类型,原本切片的容量,所需要的容量都有关系
s[:] s[i:] s[:j] s[i:j]
s[i:j:k]k代表容量,k>=j,如果没有k则默认原切片的cap长度,新切片的len=j-i,cap=k-i
j可以大于当前len但要小于等于cap
从一个长的切片里截取部分数据,未使用的空间不会gc
nil切片也会分配结构体,ptr是0;空切片ptr指向固定地址

array:
数组以arr[:]方式转成切片,切片的底层直接指向了这个数组
数组可以使用len和cap
不能append,copy
arr2:=arr1是值复制,拷贝所有数据
可以range,会完全复制整个数组,编译器优化实际只有一份内存,有待研究?
可以直接==判断
append第一个参数必须是切片,第二个参数可以是单个类型/string/slice,string/slice要加三个点,返回值也是一个切片
零长数组和空结构体行为一致,指向zerobase

string:
有len无cap
不可修改
对字符串进行切片操作(str[:])生成的还是字符串,不能修改值
[]byte转成string一定会拷贝内存吗,使用m[string(b)]来查找;字符串拼接;string(b) == "foo"
不能等于nil
str[0]是byte/uint8;range str返回的是rune/int32,range str时index可能是不连续的,value是unicode
[]rune(str)转成unicode,[]byte(str)转成utf-8的每个字节
常量字符串在编译阶段存在数据区,如果两个变量对应的字符串一样,那么两个变量对应的指针指向同一个地址

map:
切片/map不能作为key,但可以作为value
并发读写会panic,通过flags标志位判断
hash高8位用作tophash,底位用于计算在哪个桶
每个桶都是一个bmap,每个bucket可以存8个kv,摆放方式key1...key8/value1...value8,溢出桶通过链表链接
tophash,emptyRest表示后面没有数据了,emptyOne表示当前没有key
初始化,makemap,bucket数量一般是2的倍数,初始化时容量超过8才会分配空间,最少分配2个bucket
插入更新,mapassign,先找这个key是否已经存在,如果存在则更新value,如果不存在则找到第一个emptyOne/emptyRest插入新KV
删除,mapdelete,找到这个key,把tophash设置成emptyOne,把最后一个有key的后面所有的tophash都设置成emptyRest
查询,mapaccess1一个返回值,mapaccess2带ok的返回值,如果key不存在则返回&zeroVal[0]
遍历,mapiterinit初始化hiter结构体,起始桶和桶内的offset是随机数,mapiternext先遍历一个桶内的8个key再遍历下一个桶
扩容,map中数据总个数/桶个数>6.5时(overLoadFactor),引发翻倍扩容,或者是使用了太多的溢出桶时(tooManyOverflowBuckets)这种是同容量扩容将松散的数据聚合,因为删除操作造成太多的空洞,hashGrow开始扩容,插入/更新/删除时触发实际扩容(growWork),扩容当前的桶和一个每次递增的桶
mapextra,nextOverflow存放未使用的溢出桶,overflow/oldoverflow为了优化GC扫描而设计,当key和value均不包含指针并且都可以inline时使用,避免扫描hmap
hash函数

chan:
以通信方式共享内存,不要以共享内存方式通信
len+cap;读写nil管道都会阻塞;close nil管道会panic;close两次管道会panic
nil管道,发送/接收数据会阻塞,close会panic
往已close的管道发送数据会panic,可以接收数据第二个返回值是false
初始化,makechan,recvq/sendq存储G的接收发送队列,循环数组实现的数据队列,sendx/recvx记录队列中发送接收的位置
发送,chansend,如果recvq有等待的G会直接发送给这个G,调用goready唤醒这个G,如果队列没满就把数据放入队列,sendx加1然后返回,如果队列已经满了就把G放入sendq队列然后阻塞调用gopark,数据存在sudog上
接收,chanrecv1,chanrecv2返回值带ok,如果发送队列sendq不为空并且数据队列长度是0则直接获取阻塞G的数据并唤醒阻塞G,如果发送队列sendq不为空并且数据队列长度大于0则返回sendx位置的数据并且将阻塞G的数据放入队列,同样要唤醒阻塞G,此时队列是满的,recvx加1后,将recvx赋值给sendx,如果发送队列sendq为空并且数据队列不为空则返回sendx位置的数据,如果发送队列sendq为空并且数据队列也为空,那就将当前G放入recvq队列
close,closechan,close两次会panic,唤醒所有recv等待者,唤醒所有send等待者并且panic

select:
可用于收发多个管道,可非阻塞收发管道,可增加超时时间收发管道
select中所有case都阻塞就走default,没有default就阻塞
只能用于管道
case是随机执行的,避免饥饿问题
两个case可以接收同一个管道
超过1个case,有default,selectgo.block=false
超过1个case,无default,selectgo.block=true
0/1个case时编译器特殊处理:
只有一个读chan的case,chanrecv1
只有一个写chan的case,chansend1
只有一个读chan的case+default,selectnbrecv
只有一个写chan的case+default,selectnbsend
没有case也没有default,block
只有default,直接JMP
select recv多个管道,且这些管道都无数据,select所在G阻塞,sudog加入每个管道的recvq,其它G同时send数据给这些管道,通过g.selectDone防止所有管道同时给G发送数据

struct:
空结构体都指向zerobase;当空结构体放到另一个结构体中的最后一个字段时会进行特殊填充
结构体可以直接==判断
继承,一个结构体嵌到另一个结构体
如果一个struct嵌套了另一个匿名结构体,那么这个结构可以直接访问匿名结构体的方法从而实现继承
如果一个struct嵌套了另一个有名结构体,那么这个模式叫做组合
结构体方法调用时会先拷贝一份,所以无法改变原本结构体内部的成员值,因为接收者是结构体
结构体指针方法,把结构体赋值给接口,这时调用方法会造成编译不过,因为结构体会复制一份,当调用方法时需要取指针,这时结构体有两份拷贝编译器没有办法根据结构体找到一个唯一的指针
空结构体数组不占用空间

接口interface:
接口是一种抽象的类型,描述了一系列方法的集合,接口只定义方法名和参数而不包含具体的实现,对一系列具有联系的方法做出抽象和概括
只要实现了接口的所有方法,这个类型就实现了该接口,duck typing,不需要显式地去继承接口,编译阶段就可以发现是否实现了接口
eface表示空的interface{},有两个字段_type和data,data是指向数据的指针,_type是类型信息
iface表示至少带有一个函数的interface,有两个字段tab和data,itab表示interface和实际类型的转换信息,运行时为这一对具体的<Interface,Type>生成itab信息

协程:
pc: program counter,pc寄存器的作用是存储程序接下来运行的位置
sp: stack pointer,当前线程使用的栈的栈顶地址
systemstack: 可以由g0/gsignal/普通g调用,当由普通g调用的时候会切换到g0,调用完再切回普通g栈
mcall: 从普通g栈切换到g0栈,该函数由普通g调用,fn不能返回
stopTheWorld/startTheWorld: stopTheWorldWithSema通知所有P上的G被抢占,只设置抢占状态不保证立即被抢占,系统调用tgkill,发送信号给其它M让其停止,preemptall:循环allp调用preemptone,G正在newstack的时候要忽略停止的请求,设置G/P的preempt为true,preemptM-->signalM-->tgkill-->doSigPreempt-->asyncPreempt-->preemptPark->dropg->schedule->gcstopm->stopm->mPark;startTheWorldWithSema重新调整P大小procresize,循环所有P,绑定所有P和M,再唤醒所有M,wakep->startm如果有闲置的P那么就将P和一个闲置的M绑定,其它被唤醒的M执行schedule重新调度

lock/unlock:futexsleep/futexwakeup linux futex系统调用实现
notesleep:不带超时,g0调用
notetsleep:带超时,一般情况下被g0调用
notetsleepg:带超时,普通g调用
notewakeup:唤醒指定线程

gcstopm:stopm->mPark->notesleep
acquirep:wirep绑定M和P
releasep:解绑P和M
execute:绑定M和G
dropg:解绑M和G,G的状态改为_Grunning,调用gogo执行协程函数

throw->fatalthrow->startpanic_m+dopanic_m
gopanic->fatalpanic->startpanic_m+dopanic_m
raise->tgkill
crash->raise(SIGABRT)
exit->exit_group
LockOSThread/UnlockOSThread/FreeOSMemory/SetGCPercent/SetMaxStack/ReadGCStats/SetPanicOnFault/WriteHeapDump/SetTraceback

main:
_rt0_amd64_linux
_rt0_amd64
rt0_go
runtime.settls: 调用系统调用arch_prctl
runtime.check: 检查基础类型是否正确,如int8是不是一个字节
runtime.args: 处理参数
runtime.osinit: 获取cpu数量
runtime.schedinit: 初始化堆栈/环境变量/进程入参/gc
runtime.newproc: 创建新G运行fn=runtime.main->main_main,将G放入当前P的队列,执行wakep
runtime.mstart: 保存pc/sp,执行schedule
runtime.abort: INT $3

G:
Goroutine协程,初始2KB栈
G状态:_Grunning/_Gwaiting/_Grunnable/_Gsyscall/_Gidle/_Gdead/_Gcopystack/_Gpreempted
G存储在,LRQ本地运行队列/GRQ全局运行队列/Netpoller网络轮询器/系统调用/锁/chan receive/chan send/select,本地P运行队列没有剩余空间时会使用全局队列
GC sweep/GC scavenge/force gc/GC worker
tls: thread local storage 为线程本地存储
gsignal:signal-handling g,32KB栈
g0:8KB栈,是持有调度栈的Goroutine,参与运行时的调度过程,包括G的创建/大内存分配/CGO函数的执行
getg: 返回当前g的指针,在编译的时候才会生成该函数
newproc:创建一个新G,在g0栈里调用该函数,newproc1:从gFree里获取,如果获取不到就new一个g并分配2K栈状态设为_Gdead加到allgs上,参数放入栈,状态设为_Grunnable,goid设置成当前P上的自增值,新G放到当前P的本地队列/全局队列/当前P的下一个要执行的g,wakep->startm获取空闲P,如果没有空闲P直接返回,如果有空闲P就去获取空闲的M(mget),绑定P和M,唤醒M,如果没有空闲M就去newm
gopark/goready
gosave/gogo
gobuf
goexit:该函数地址放在栈顶,当协程函数执行完就会执行goexit,goexit1->goexit0,g状态设置成_Gdead,dropg拆解m和g的绑定,把g放到gFree上,重新schedule

M:
操作系统线程
SetMaxThreads,默认sched.maxmcount=10000
最大活跃线程数是GOMAXPROCS,非活跃线程可能阻塞在系统调用
目前并没有对闲置线程做清除处理
osyield: 线程让出cpu,调用系统调用sched_yield
procyield: 执行PAUSE指令空转
m0
startm: 获取一个闲置的M,如果没有就newm一个
newm: 创建新线程并让线程工作,newm(fn, _p_, id),allocm获取M,new一个m对象,mstartfn=mspinning,M初始化,分配g0,(解绑当前的P和M,当前P的状态设置为_Pidle),绑定空闲P和新M,newm1->newosproc->clone->mstart
allocm: 获取m结构体
newosproc: 创建系统线程
mcommoninit: M的一些初始化,创建gsignal
mexit: mstart的结尾调用,退出当前线程,释放gsignal栈,从allm移除m,(非系统栈时m对象放在sched.freem上,后期由allocm释放栈),解绑M和P,让P去找另一个M去执行,线程自然退出由OS释放资源,(非系统栈调用系统调用exit退出)
mstart: 线程开始工作,clone时传进去的函数/systemstack中有调用,mstart1,当前是g0在执行,保存pc/sp,初始化信号,acquirep->wirep正式绑定空闲P和新M,设置P的状态为_Prunning,schedule获取一个可执行的G,execute绑定M和G,G的状态设置为_Grunning,gogo执行协程的函数

P:
处理器,提供线程需要的上下文环境,调度等待队列,P本地运行队列最大256
P状态:_Pidle/_Prunning/_Psyscall/_Pgcstop/_Pdead
wakep: 获取一个闲置的P绑定M去执行
runqsteal: 如果当前P上没有可执行的G就去其它P上偷一半过来,runqgrab

schedule:
全局运行队列sched.runq中有待执行的G时,通过schedtick保证有一定几率会从全局运行队列中查找G(globrunqget),从P本地运行队列中查找待执行的G(runqget),如果前两种方法都没有找到G,会通过findrunnable进行阻塞地查找G,网络轮询器中查找,通过runqsteal尝试从其它随机的P中窃取待运行的G,该函数还可能窃取处理器的计时器,gcstopm

netpoll:
当网络请求阻塞时,调度器会让当前阻塞的G放入网络轮询器中,由网络轮询器处理异步网络系统调用,从而让出P执行其它G
当异步网络调用由网络轮询器完成后,再由sysmon监控线程将其切换回来继续执行
netpoll: 调用时机,startTheWorldWithSema/findrunnable/pollWork(gc过程中执行)/sysmon(10ms一次)
epollcreate1(EPOLL_CLOEXEC)
epollctl EPOLL_CTL_ADD/EPOLL_CTL_MOD/EPOLL_CTL_DEL EPOLLIN/EPOLLOUT 
EPOLLET边沿触发(go使用ET),对于读事件EPOLLIN,只有socket上的数据从无到有EPOLLIN才会触发,对于写事件EPOLLOUT,只有在socket写缓冲区从不可写变为可写EPOLLOUT才会触发
EPOLLLT水平触发,对于读事件EPOLLIN只要socket上有未读完的数据EPOLLIN就会一直触发,对于写事件EPOLLOUT只要socket可写,EPOLLOUT就会一直触发
EPOLLRDHUP检查对方是否关闭socket
epoll_wait
Listen->listenTCP->internetSocket->socket->sysSocket->syscall.Socket->netFD.listenStream->syscall.Bind->syscall.Listen->netFD.init->FD.Init->pollDesc.init->runtime_pollOpen->netpollopen
TCPListener.Accept->TCPListener.accept->netFD.accept->FD.Accept->pollDesc.waitRead->runtime_pollWait->poll_runtime_pollWait->netpollblock->gopark->syscall.Accept4(s, syscall.SOCK_NONBLOCK|syscall.SOCK_CLOEXEC)
TCPConn.Read->conn.Read->netFD.Read->FD.Read->pollDesc.waitRead->syscall.Read
Dial->Dialer.Dial->Dialer.DialContext->sysDialer.dialSerial->sysDialer.dialSingle->sysDialer.dialTCP->sysDialer.doDialTCP->internetSocket->socket->sysSocket->syscall.Socket->netFD.dial->netFD.connect->syscall.Connect

sysmon:
每隔20us~10ms轮询一次,独立于GMP之外,独立的M
监控那些长时间运行的G,设置被强占的标识符,别的G就可以抢先进来执行
检查当前网络轮询器中所有G距离runtime.netpoll被调用是否超过了10ms,将其放入全局运行队列,等待下一次的继续执行
系统调用导致阻塞的话,P的状态为_Psyscall,则会让GM一起切换出去,让P重新找一个GM运行
如果垃圾回收器超过两分钟没有执行的话,sysmon监控线程也会强制进行GC
获取下一个需要被触发的计时器

内存管理:
mheap mspan mcentral mcache mstats TCMalloc
小于32KB,从P上的mcache分配mspan,不需要加锁,为每种类别的mspan维护着一个mcentral
mcentral的作用是为所有mcache提供切分好的mspan资源,每个central会持有一种特定大小的全局mspan列表,mcentral被所有的工作线程共同享有,需要加锁
当mcentral没有空闲的mspan时,会向mheap申请
而mheap没有资源时,会向操作系统申请新内存,mheap主要用于大对象的内存分配,以及管理未切割的mspan
大于32KB,会直接从堆上(mheap)上分配对应的数量的内存页(每页大小是8KB)给程序

newobject:mallocgc
mallocgc:
大于32KB直接在堆上分配,会判断是否要gc,mcache.allocLarge->mheap.alloc->mheap.allocSpan(systemstack)->pageAlloc.allocToCache,pageCache.alloc,mheap.grow,mheap.sysAlloc,linearAlloc.alloc,sysMap+sysUsed,返回mspan

小于32KB在每个P的cache free list分配,0字节直接返回zerobase地址
从P上的mcache分配,mcahce.alloc存放每个级别的mspan,如果mcache上的mspan没有可用空间则调用mcache.refill->mcentral.cacheSpan去获取新的mspan,这个mspan至少有一个未使用的对象,获取到新的mspan后放入mcache.alloc对应级别上,旧的mspan调用mcentral.uncacheSpan放入fullSwept,mheap上的mcentral也是按照级别用数组存放,如果mcentral上也没有则mcentral.grow->mheap.alloc

arena: 64MB
pageSize: 8KB
chunk: 4MB
arenaIndex spanOf *mspan
chunkIndex chunkOf *pallocData

pp.mcache *mcache
mcache.alloc []*mspan
allocmcache/freemcache
pp.pcache pageCache
mheap.pages pageAlloc
pp.mspancache buf [128]*mspan
mheap.spanalloc fixalloc: 用于分配mspan结构体
mheap.cachealloc fixalloc: 用于分配mcache结构体
mheap.arenas []*[]*heapArena: heapArena存放arena元数据
page allocator
page cache
sweep credit
memstats

mspan.nextFreeIndex: 放回空闲对象的位置
mcache.nextFree: mcache.refill,mspan.nextFreeIndex
mcache.refill: 获得一个新mspan,至少有一个空闲空间,在当前mcache满的情况下才会调用,满的mspan调用mcentral.uncacheSpan,通过mcentral.cacheSpan获取新的mspan,新mspan放入mcache.alloc
mcache.allocLarge
mcache.releaseAll

mcentral.cacheSpan: 返回一个mspan,从partialSwept/partialUnswept/fullUnswept获取mspan,如果依然没有mspan则调用mcentral.grow
mcentral.uncacheSpan: 回收一个mspan
mcentral.grow: mheap.alloc从mheap上分配一个mspan

mheap.alloc: mheap.reclaim分配前先sweep即将要分配的页数,mheap.allocSpan
mheap.allocSpan: 返回全新的mspan,小内存从P上的pageCache分配,如果P上的pageCache未初始化则调用mheap.pages.allocToCache分配一个pageCache,调用pageCache.alloc分配内存,再从P上的mspancache分配mspan结构体,如果P上没有,调用mheap.pages.alloc分配内存,如果依然没有则调用mheap.grow向OS申请内存再mheap.pages.alloc,mheap.spanalloc.alloc分配mspan结构体,mspan结构体初始化
mheap.grow: 增加npage给heap,mheap.sysAlloc,mheap.pages.grow
mheap.sysAlloc: 返回准备状态的内存区域,分配nbytes的arena空间,更新mheap.arenas元信息,sysReserve,sysMap,向OS申请内存,更新allArenas
mheap.freeSpan: mheap.pages.free释放内存,mspan结构体放回P上的mspancache,如果已满则mheap.spanalloc.free
mheap.scavengeAll

pageAlloc.grow: pageAlloc.sysGrow
pageAlloc.sysGrow: 更新summary,sysMap
pageAlloc.alloc: 分配npages内存,pageAlloc.find寻找npages内存
pageAlloc.find: 从radix tree查找npages
pageAlloc.allocToCache: 如果P上的pageCache是空的调用此方法分配pageCache,返回pageCache
pageCache.alloc: 从P上的pcache(pageCache)分配npages,不加锁

mmap/munmap/msync/mprotect/mremap/mlock/mlock2/munlock/mlockall/munlockall
madvise/posix_madvise/posix_fadvise
brk/sbrk/getpagesize
malloc/calloc/realloc/free/posix_memalign/memfd_create

协程栈:
每个goroutine都维护着自己的栈区,栈结构是连续栈,是一块连续的内存,栈区的初始大小是2KB,按照需要增长和收缩,最大1GB
分段栈,栈空间会以双向链表的形式串联起来,如果协程的栈几乎充满,那么任意的函数调用都会触发栈的扩容,当函数返回后又会触发栈的收缩,如果在一个循环中调用函数,栈分配释放造成巨大开销,热分裂问题
连续栈,栈空间不足时,初始化一片比旧栈大两倍的新栈并将原栈中的所有值都迁移到新的栈中,将指向旧栈对应变量的指针重新指向新栈
分配类似堆内存的分配

morestack: g0/gsignal不调用morestack,newstack
newstack: 扩大栈,copystack
stackalloc: 生成新G的时候调用stackalloc,小栈从mcache.stackcache内分配,如果mcache.stackcache是空的则调用stackcacherefill,大栈从stackLarge分配,如果stackLarge是空的则调用mheap.allocManual分配新的mspan
stackfree: 大栈_GCoff期间直接调用mheap.freeManual,否则放入stackLarge,小栈放回mcache.stackcache,如果mcache.stackcache超过32KB则调用stackcacherelease
copystack: stackalloc分配新栈空间,adjustsudogs/syncadjustsudogs,memmove拷贝数据,adjustctxt,adjustdefers,adjustpanics,gentraceback调整指针的值,stackfree释放老空间
shrinkstack: 当前使用的栈空间小于总空间的1/4的时候才会缩栈,调用copystack缩小成原来的1/2
freeStackSpans: gcMarkTermination内调用,stackpool/stackLarge未使用的mspan会调用mheap.freeManual释放,
stackpoolalloc: 从stackpool获取第一个mspan,如果stackpool是空的则调用mheap.allocManual返回一个新的mspan并放入stackpool,s.allocCount++,如果这个mspan用完了则从stackpool移除
stackpoolfree: 如果mspan有可用空间则放入stackpool,mspan.allocCount--,如果mspan.allocCount=0并且是_GCoff那么mheap.freeManual并且从stackpool移除
stackcacherefill: 循环调用stackpoolalloc生成16KB可用内存放入mcache.stackcache
stackcacherelease: mcache.stackcache保留16KB内存,其它内存循环调用stackpoolfree放回stackpool

go1.17函数入参/返回值,使用了9个通用寄存器,依次是AX/BX/CX/DI/SI/R8/R9/R10/R11,超出部分按顺序放在栈上

内存回收gc:
三色标记
开始所有对象都是白色的
遍历根节点(全局变量和栈内变量)集合里的所有根对象,把根对象引用的对象标记为灰色,从白色集合放入灰色集合
遍历灰色集合,将灰色对象引用的对象从白色集合放入灰色集合,之后将此灰色对象放入黑色集合
重复第三步,直到灰色集合中无任何对象
回收白色集合里的所有对象,本次垃圾回收结束
写屏障,在对象新增的同时给它着色为灰色,而所有新创建的对象都会被直接标记成黑色
开启写屏障前和移除写屏障前暂停应用程序
标记准备阶段,暂停程序
标记阶段,根对象入队,开启写屏障,恢复执行程序,开始扫描根对象,扫描协程栈期间会暂停当前处理器,
标记终止阶段,暂停程序
清理阶段,初始化清理状态并关闭写屏障,恢复用户程序,后台并发清理所有的内存管理单元,当goroutine申请新的内存管理单元时就会触发清理
触发时机,内存使用超过某值,超过两分钟,手动GC

setGCPhase,_GCoff/_GCmark/_GCmarktermination
gcStart: 调用时机:mallocgc/runtime.GC/sysmon两分钟唤醒一次forcegchelper,将剩余未清扫的span清扫完成,启动gomaxprocs个gcBgMarkWorker,如果以前启动过就不用重复启动,stopTheWorldWithSema,finishsweep_m,gcphase设置成_GCmark,gcMarkRootPrepare栈和全局变量入队列,gcMarkTinyAllocs标记小对象为灰色,startTheWorldWithSema
gcBgMarkWorker: 执行gcDrain的协程
gcDrain: 在work buffers里扫描roots和objects,将灰色对象变黑,直到所有工作都做完,GC结束前返回,循环调用markroot,循环调用scanobject,gcFlushBgCredit
markroot: flushmcache,markrootBlock,scanblock,markrootFreeGStacks,markrootSpans,scanstack
scanobject: 调用greyobject
scanblock: 类似scanobject,scan non-heap roots,调用greyobject
scanstack: 调用前需要suspendG,调用后需要resumeG,扫描G的栈,栈上的指针都变成灰色,调用scanblock,scanframeworker扫描栈帧局部变量/入参/返回值
greyobject: 通过位操作设置为灰色,设置mspan.gcmarkBits对应位上为1即为标记过
gcMarkDone: 最后一个终止标记的协程调用,标记终止阶段,stopTheWorldWithSema,唤醒所有辅助G,gcMarkTermination
gcMarkTermination: gcphase设置成_GCmarktermination,gcMark,gcphase设置成_GCoff,gcSweep,startTheWorldWithSema,freeStackSpans,每个P执行一次mcache.prepareForSweep
gcMark: 检查gc完成,设置memstats
gcSweep: 在gcMarkTermination里调用,结尾处唤醒bgsweep
gcWaitOnMark: 等待mark阶段结束,如果当前处于mark阶段当前G就gopark,等待在gcMarkTermination里唤醒该G
gcAssistAlloc: 普通G分配内存mallocgc并且处于标记阶段时,如果gcAssistBytes小于0就会调用此函数,辅助gc标记至少64KB,gcDrainN

write barriers: p.wbBuf每个P都有一个write barrier buf,防止一个白色对象被黑色对象引用,只要满足强/弱三色不变式的其中一种,即可保证对象不被丢失
hybrid barrier: Yuasa-style deletion barrier,Dijkstra insertion barrier,混合写屏障=删除写屏障+插入写屏障
强三色不变式: 永远不会出现黑色对象指向白色对象,强制性的不允许黑色对象引用白色对象
弱三色不变式: 黑色对象可以引用白色对象,白色对象存在其它灰色对象对它的引用,或者可达它的链路上游存在灰色对象
插入屏障: 是对象被引用时触发的机制,插入屏障拦截将白色指针插入黑色对象的操作,标记其对应对象为灰色状态,这样就不存在黑色对象引用白色对象的情况,满足了强三色不变式,插入屏障是一个很耗费性能的行为,而栈需要更高的性能要求,因此插入屏障技术只运用在堆内存空间里不会运用到栈里
删除屏障: 是对象被删除时触发的机制,删除屏障也是拦截写操作,因为它是写入一个空对象,具体的操作是被删除的对象如果自身为灰色或者白色,那么被标记为灰色,满足了弱三色不变式原则,保护灰色对象到白色对象的可达路径不会断
gcWriteBarrier: 编译器插入到代码里,将指针放入wbBuf,满了则调用wbBufFlush
wbBufFlush: flush当前P的write barrier buf到gc workbuf,调用wbBufFlush1,标记指针指向的mspan,gcw.putBatch将所有指针放入gcw,此时对象是灰色
bulkBarrierPreWrite: typedmemmove/typedslicecopy/typedmemclr/memclrHasPointers调用该函数,memmove前执行,src=0时memclr,wbBuf.putFast,wbBufFlush
bulkBarrierPreWriteSrcOnly: makeslicecopy/growslice调用该函数,同bulkBarrierPreWrite
bulkBarrierBitmap: bulkBarrierPreWrite内调用,同bulkBarrierPreWrite
typeBitsBulkBarrier: 管道传数据专用,同bulkBarrierPreWrite
标记起始阶段STW: finishsweep_m需要STW是为了当前不会有并发的sweep发生,这样才能保证所有的mspan都被sweep;gcMarkRootPrepare需要STW是为了计算root(全局变量)对象数量,设置nDataRoots/nBSSRoots/nSpanRoots;gcMarkTinyAllocs遍历所有P将mcache.tiny标记成灰色
标记终止阶段STW: 每个P执行wbBufFlush1,把P上的写屏障放入gcw,如果gcw不为空那么startTheWorldWithSema,gcMarkDone再从头开始执行,如果每个P上的gcw都是空的,设置gcBlackenEnabled,设置gcphase为_GCmarktermination,gcMark,设置gcphase为_GCoff,gcSweep,设置一些全局变量memstats/work/sweep

bgsweep: 循环调用sweepone,循环调用freeSomeWbufs,做完后gopark
sweepone: 清扫mspan,返回清扫的页数,没可清扫的返回^0,nextSpanForSweep找到需要sweep的mspan,调用mspan.sweep,如果清扫完会激活新一轮的scavenge
mheap.nextSpanForSweep: 从mcentral fullUnswept/partialUnswept找未sweep的mspan
mspan.sweep: 清扫单个mspan,设置mspan.allocCount/mspan.freeindex=0/mspan.allocCache/mspan.allocBits=mspan.gcmarkBits,如果这个mspan没有一个对象被使用则调用mheap.freeSpan
freeSomeWbufs: mheap.freeManual释放workbuf使用的mspan
mheap.freeSpan: mheap.freeSpanLocked释放spanAllocHeap类型
mheap.freeManual: mheap.freeSpanLocked释放spanAllocWorkBuf/spanAllocStack类型
mheap.freeSpanLocked: mheap.pages.free释放pages,mheap.freeMSpanLocked释放mspan对象
mheap.freeMSpanLocked: 释放一个mspan对象,先放入pp.mspancache,如果pp.mspancache已满,则调用mheap.spanalloc.free
pageAlloc.free: 释放npages内存
getempty/putempty: 返回空的workbuf/存储空的workbuf
mheap.allocManual/mheap.freeManual: 分配释放栈内存和workbuf

bgscavenge: sweep结束会唤醒此G,循环调用mheap.pages.(pageAlloc).scavenge
pageAlloc.scavenge: scavengeReserve,scavengeOne,scavengeUnreserve
pageAlloc.scavengeReserve: 预留连续内存用于scavenge
pageAlloc.scavengeOne: scavengeRangeLocked
pageAlloc.scavengeRangeLocked: sysUnused,scavenged.setRange
pageAlloc.scavengeUnreserve: 未scavenge的内存再存起来

sync.Map:
通过互斥锁和原子操作来实现近似无锁,空间换时间,延迟删除,删除一个键值只是打标记,只有在迁移dirty数据的时候才清理删除的数据,readOnly向dirty拷贝是遍历,不适合大数据场景
不加锁: 读/删一个存在readOnly中的key,写一个存在readOnly中的key并且没有标记删除
加锁: 增加新key会加锁,新key先放dirty,不适合频繁增加数据

sync.Mutex:
CAS+原子操作
正常模式: 等待者们以先进先出的顺序排队,排在最前面的等待者不一定能获得下一次的锁,比如在某个时刻,醒着的等待者与一个新到达的G竞争所有权,由于新到达的G一直在CPU上运行,此时这个醒着的等待者有很大的概率失去锁,在这种情况下,它就在等待队列的前面排队着,如果一个等待者没有获得锁超过1ms,就会切换到饥饿模式;正常模式会有好的性能在一个协程能多次获得一把锁,即使有阻塞的等待者
饥饿模式: 锁的所有权直接从未锁的协程推给队列前面的等待者,新到达的协程不会尝试获得锁,并且不会尝试自旋,它们会排在队列的尾端,如果一个等待者拿到了所有权,并且它看到了它是队列的最后一个或者它等待的时间小于1ms,切换到正常模式;饥饿模式是为了防止严重的尾端延迟情况
进入自旋的条件,非饥饿模式,自旋次数小于4,cpu大于1,空闲的P+自旋的M+1小于总P,当前P的runq是空的,执行PAUSE命令,自旋30次
如果不进入自旋接下来就会阻塞在信号量,放入队列,执行gopark,_Grunning->_Gwaiting,unlock时调用goready唤醒阻塞的协程,_Gwaiting->_Grunnable

sync.RWMutex:
使用Mutex和信号量实现
获得读锁,如果之前有读锁那么直接获得锁,如果之前有写锁那么阻塞在读信号量队列上,当释放写锁时唤醒读信号量队列上所有的读锁
获得写锁,如果之前有写锁那么直接阻塞在互斥量上,如果之前有读锁,那么阻塞在写信号量上,当释放最后一个读锁时唤醒写信号量

sync.Once:
CAS+mutex
首先原子判断done是不是0,如果不是0就直接返回,如果是0就代表未执行过,这时先加锁,再次判断done是不是0,不是0就代表被其它同时运行的G执行了直接退出,是0的话就执行fn再原子设置done为1

sync.WaitGroup:
Add: 支持加负数,检测到v等于0并且等待者不等于0就去释放所有等待者的信号量
Done: Add(-1)
Wait: 原子增加等待者的数量+1,协程进入信号量阻塞

sync.Cond:
用法: 先上锁,Wait,解锁
Wait: 先解锁,协程睡眠,等待被唤醒,再上锁
Signal: 唤醒单个等待者
Broadcast: 唤醒所有等待者

sync.Pool:
Get,P先去private找,如果private是空则去本地池查找,如果自己没有就去其它P偷过来一些,如果还是没有就去本地池victim取,如果都没有就New一个
Put,P操作本地池,数据放入一个双向链表,每个链表节点存储容量以2倍递增
gc前的STW执行注册的回调函数用于清理一代的缓存,原本的victim赋值nil去除对内存的引用,local赋值给victim
禁止G被抢占,false sharing问题的避免

atomic:
锁住变量的地址不允许其它cpu操作
通过指令实现原子操作,LOCK
ANDL/ORL/ANDB/ORB
StoreInt64 XCHGQ
LoadInt64 *ptr
AddInt64 XADDQ
CompareAndSwapInt64 CMPXCHGQ
SwapInt64 XCHGQ
MESI缓存一致性协议

return:
不带命名的返回参数会默认加r0...rn的名称,函数返回时需要给这些变量赋值
带命名的返回参数:
return后面什么都不加,等同于,return后面加返回值里的变量;
return后面加非返回值里的变量,先给这个函数返回值变量赋值再返回;

defer:
先进后出;defer无法改变已经return的变量,除非该变量在函数的返回值里申明
deferprocStack&deferreturn
先执行return再执行defer
defer函数的入参取决于执行到defer那一行时是什么值,入参放在deferprocStack函数入参_defer结构体的下面位置
gp._defer,defer以链表的形式存储

panic&recover:
只能recover本协程内的panic
gopanic&gorecover
数组切片越界;nil指针野指针;往已经close的chan里发送数据;并发读写相同map;interface{}断言未接收第二个返回值
gp._panic,panic以链表的形式存储
多个panic,recover的时候只返回最新的一个(链表头部)

闭包函数:
定义在一个函数内部的函数,闭包是将函数内部和函数外部连接起来的桥梁,局部变量变成全局变量
生成一个内部的struct,如type.noalg.struct { F uintptr; "".add1 int; "".add2 *int },在调用闭包函数时通过DX寄存器传输这个结构体
函数变量是8字节

unsafe&uintptr:
unsafe.Pointer和uintptr可以相互转化
unsafe.Pointer不能加减
uintptr可以加减
uintptr对对象已经无引用,对象可能随时被回收;除非是系统调用传进去的uintptr,编译器做了处理对象不会被回收
普通变量取址也不能进行加减

copy:
第一个参数只能是slice,第二个参数可以是slice和string
nil:
nil不是关键字;nil可作为变量名;nil是没有默认类型的在使用它时必须要提供足够的信息能够让编译器推断nil期望的类型
iota:
只能和const一起使用;每当const出现时都会使iota初始化为0;const中每新增一行常量声明将使iota计数一次;默认int型

内存对齐:
不是所有的硬件平台都能访问任意地址上的任意数据,为了访问未对齐的内存,处理器需要作两次内存访问,而对齐的内存访问仅需要一次访问
计算机只能从4/8的倍数开始读数据,不能随便从一个地址读数据
结构体嵌套空结构体的情况,空结构体在最前面/中间不占字节,在最后会被填充对齐到前一个字段的大小

内存逃逸:
编译阶段确定;大内存优先分配在堆上/分配的大小不确定;变量在函数返回后还可能被使用,闭包,返回指针;造成gc压力变大
go build -gcflags "-m -m" main.go
go tool compile -m main.go

位运算:
&: 与AND
|: 或OR
^: 异或XOR,作为一元运算符时表示位反或位补,等价m^n,m所有位都是1
&^: 位清空AND NOT,运算符左边数据与右边数据相异的位保留,相同位清零,0&^0=0  0&^1=0  1&^0=1  1&^1=0;如果右侧是0,则左侧数保持不变;如果右侧是1,则左侧数一定清零
>>: 正数左移补0,负数左移补0(符号位1被冲掉)
<<: 正数右移补0,负数右移补1(-1右移还是-1)
原码: 符号位加真值的绝对值
反码: 无符号数和正数的反码是其本身,负数的反码是将原码除符号位外的其他位按位取反,即0变1,1变0
补码: 无符号数和正数的补码是其本身,负数的补码是反码二进制加1
为了让符号位参与基本预算,产生了反码
为了解决反码运算后产生-0的问题产生了补码
计算机实际用补码参与运算,获得的结果需要转换成原码
强制类型转换:
int8/uint8 -> int64/uint64 直接转成对应大小的数(从二进制角度看:如果int8是负数,缺少的高位全补1;如果int8是正数/uint8,缺少的高位全补0)
int64/uint64 -> int8/uint8 直接截取二进制数据的后8位

pprof:
net/http/pprof runtime/pprof
go tool pprof http://localhost:6060/debug/pprof/heap
go tool pprof http://localhost:6060/debug/pprof/profile
go tool pprof http://localhost:6060/debug/pprof/goroutine
go tool pprof demo demo.prof
go tool pprof -http 0.0.0.0:8080 http://localhost:6060/debug/pprof/profile
能查到哪个函数分配的内存高
能查到哪个函数占用cpu高
火焰图
调用链,每个函数的耗时和占比

dlv:
查看函数参数、打印变量、单步执行、查看所有协程
dlv exec ./hello
设置断点
break /usr/local/go/src/runtime/os_linux.go:71
break main.go:35
打印所有断点 breakpoints
继续执行到下一个断点 continue
执行下一行 next
执行下个指令(更细) step
局部变量 locals var1
打印变量 print var1
strace -ff ./test1

Benchmark:
go test -bench .
go test -bench=. -cpuprofile=cpu.prof
go test -bench=. -memprofile=mem.prof
go tool pprof -http 0.0.0.0:8080 cpu.prof

trace:
curl -o app.trace http://localhost:6060/debug/pprof/trace
go tool trace -http 0.0.0.0:8080 performance app.trace
可以查看每个协程在哪耗时大

test:
go test -coverprofile=test.out
go tool cover -html=test.out -o cover.html
go test -run=FuzzReverse
go test -fuzz=Fuzz
go test -run=FuzzReverse/8fe4afa715c62ebbf52961c12d500dda471293a8d663e527b1f89032f1956f5f
go test -fuzz=Fuzz -fuzztime 30s

汇编plan9:
go tool compile -N -l -S main.go //打印汇编 生成.o
go run -gcflags "-N -l" main.go
go build -gcflags "-N -l" main.go
go build -gcflags=all="-N -l" main.go
go tool objdump -s do1 main.o
静态单赋值SSA GOSSAFUNC=do1 go build main.go
中间代码

tool:
go env -w GO111MODULE=on
go tool fix main.go //golang.org/x/net/context --> context
go fmt main.go
go vet main.go //检查基本错误如语法错误 fmt.Printf("%s", 12)
go tool asm main.s //.s --> .o
go tool link main.o //链接
readelf -w a.out
addr2line -e a.out
go tool nm main.o
go tool pack c file.a main.go
//go:noinline //go:nosplit //go:noescape //go:linkname //go:notinheap //go:norace
//go:generate stringer -type=Life
插件: go build -buildmode=plugin add.go

定时器:
time.Sleep: timeSleep,resettimer
resettimer: modtimer
modtimer: doaddtimer,wakeNetPoller
doaddtimer: 在当前P的heap上增加定时器
dodeltimer: 删除当前P的heap上的定时器,指定第几个timer
runtimer: runOneTimer真正运行一个timer
cleantimers: dodeltimer0移除pp.timers第一个timer
adjusttimers: 调整pp.timers,该删的删
addtimer: cleantimers,doaddtimer
deltimer: 不会真正删除timer,只会标记status
checkTimers: 调度器调用,adjusttimers,runtimer
time.NewTimer: startTimer->addtimer
Timer.Reset: resetTimer->resettimer
time.NewTicker: startTimer->addtimer
Ticker.Stop: stopTimer->deltimer
Ticker.Reset: modTimer->modtimer

性能优化:
select中的case太多会降低性能
map中的value如果没有使用到可以用struct{},减小内存占用
map中key和value尽量不使用指针减少gc压力
map只能扩容不能缩容,可以适当地重置map
不要在循环中使用defer
尽量不使用reflect,反射耗性能
不要从大的slice和string截取部分数据,因为其它部分的数据不会被gc
频繁拼接string考虑预先分配一个大空间,把待拼接的string拷贝进去,如strings.Builder,而不是使用+
slice/array的单个元素如果很大的话可以考虑for/range只返回索引,避免不必要的内存拷贝
slice可以提前预分配空间,避免append时频繁扩容

fmt:
每次打印从sync.Pool获取结构体空间,使用完,如果空间大于64KB直接交给gc,如果小于64KB就放回sync.Pool
打印结构体会使用到reflect

泛型:
~粗略匹配
编译为代码中所有类型的具体函数,会导致代码膨胀
comparable

net/http:
https://httpwg.org/specs/rfc7230.html
h1客户端对于同一个host可以和服务端建立多个tcp链接(受MaxIdleConns/MaxConnsPerHost/MaxIdleConnsPerHost制约),每个请求独占一个链接直到收到响应
h2客户端对于同一个host只建立一条tcp,多个请求多路复用
Serve->Server.Serve->conn.serve->conn.readRequest->readRequest->readTransfer->ServeHTTP->finishRequest
NewRequest->NewRequestWithContext->Client.Do->Client.do->Client.send->send->Transport.RoundTrip->Transport.roundTrip->Transport.getConn->Transport.queueForDial->Transport.dialConnFor->Transport.dialConn->Transport.dial->Transport.DialContext->Dialer.DialContext->persistConn.readLoop->persistConn.writeLoop->persistConn.roundTrip->persistConn.readResponse->ReadResponse

tls:
ServeTLS->Server.ServeTLS->tls.NewListener->Server.Serve->Conn.Handshake->Conn.handshakeFn->Conn.serverHandshake->Conn.readClientHello->serverHandshakeState.handshake->serverHandshakeState.processClientHello->serverHandshakeState.pickCipherSuite->serverHandshakeState.doFullHandshake->serverHandshakeState.establishKeys->serverHandshakeState.readFinished->serverHandshakeState.sendSessionTicket->serverHandshakeState.sendFinished
Transport.dialConn->persistConn.addTLS->tls.Client->Conn.Handshake->Conn.clientHandshake->clientHandshakeState.handshake->clientHandshakeState.processServerHello->clientHandshakeState.pickCipherSuite->clientHandshakeState.doFullHandshake->clientHandshakeState.establishKeys->clientHandshakeState.sendFinished->clientHandshakeState.readSessionTicket->clientHandshakeState.readFinished

websocket: x/net/websocket
Dial->DialConfig->dialWithDialer->Dialer.Dial->NewClient->hybiClientHandshake->http.ReadResponse->newHybiClientConn->newHybiConn
Handler.ServeHTTP->Server.serveWebSocket->newServerConn->hybiServerHandshaker.ReadHandshake->hybiServerHandshaker.AcceptHandshake->hybiServerHandshaker.NewServerConn->newHybiServerConn->newHybiConn
Conn.Write->hybiFrameWriterFactory.NewFrameWriter->hybiFrameWriter.Write
Conn.Read->hybiFrameReaderFactory.NewFrameReader->hybiFrameHandler.HandleFrame->hybiFrameReader.Read

http2.0: 只能在TLS情况下使用 ALPN
request和对应的response使用同一个StreamID,同一个请求HEADERS和DATA使用同一个StreamID
HEADERS是由一个或多个frame组成的,第一个frame是Headers类型,后面的是Continuation(0x9)类型,每个frame都包含帧首部(帧长度+帧类型+flags)+流标识符+优先值+帧净荷
DATA类型数据会发送一个或多个frame,每个frame的类型都是DATA
TLS版本不低于1.2
h2怎么保证两端的头部信息一致:
客户端的编码器发送到服务端的解码器,因为只有一条TCP链接,先发的数据肯定先到,保证了顺序,服务端的编码器发送到客户端的编码器,也是同理,客户端的编码器和客户端的解码器用的是不同的动态表
客户端发来的Setting改变服务端编码器动态表的大小,然后服务端发送001的头部编码改变客户端的解码器动态表大小

Transport.roundTrip->Transport.onceSetNextProtoDefaults->http2configureTransports->http2registerHTTPSProtocol->Transport.RegisterProtocol->Transport.altProto->Transport.TLSNextProto->upgradeFn->Transport.alternateRoundTripper->http2noDialH2RoundTripper.RoundTrip->http2Transport.RoundTrip->http2Transport.RoundTripOpt->http2noDialClientConnPool.GetClientConn->http2clientConnPool.getClientConn->Transport.getConn->Transport.queueForIdleConn->Transport.queueForDial->Transport.dialConnFor->Transport.dialConn->persistConn.addTLS->upgradeFn->http2clientConnPool.addConnIfNeeded->http2addConnCall.run->http2Transport.NewClientConn->http2Transport.newClientConn->http2Transport.RoundTrip->http2Transport.RoundTripOpt->http2noDialClientConnPool.GetClientConn->http2clientConnPool.getClientConn->http2ClientConn.RoundTrip->http2clientStream.doRequest->http2clientStream.writeRequest->http2clientStream.encodeAndWriteHeaders->http2ClientConn.encodeHeaders->http2ClientConn.writeHeaders->http2Framer.WriteHeaders->http2Framer.WriteContinuation->http2clientStream.writeRequestBody->http2Framer.WriteData->http2Framer.WriteDataPadded->http2Framer.startWrite->http2Framer.endWrite
http2Transport.newClientConn->http2ClientConn.readLoop->http2clientConnReadLoop.run->http2Framer.ReadFrame->http2readFrameHeader->http2typeFrameParser->http2parseHeadersFrame/http2parseDataFrame->http2Framer.readMetaFrame->http2clientConnReadLoop.processHeaders/processData
conn.serve->http2Server.ServeConn->http2serverConn.serve->http2serverConn.writeFrame->http2serverConn.scheduleFrameWrite->http2serverConn.startFrameWrite->http2serverConn.readFrames->http2Framer.ReadFrame->http2serverConn.processFrameFromReader->http2serverConn.processFrame->http2serverConn.processHeaders->http2serverConn.newWriterAndRequest->http2serverConn.newWriterAndRequestNoBody->http2serverConn.runHandler->http2serverConn.processData
http2chunkWriter.Write->http2responseWriterState.writeChunk->http2serverConn.writeHeaders->http2serverConn.writeDataFromHandler->http2serverConn.writeFrameFromHandler->http2serverConn.writeFrame
http2ClientConn.encodeHeaders->http2ClientConn.writeHeader->Encoder.WriteField

grpc:
DialContext->newCCResolverWrapper->passthroughBuilder.Build->ccResolverWrapper.UpdateState->ClientConn.updateResolverState->ClientConn.maybeApplyDefaultServiceConfig->ClientConn.applyServiceConfigAndBalancer->ccBalancerWrapper.switchTo->ccBalancerWrapper.handleSwitchTo->Balancer.SwitchTo->pickfirstBuilder.Build->ccBalancerWrapper.updateClientConnState->ccBalancerWrapper.handleClientConnStateChange->Balancer.UpdateClientConnState->pickfirstBalancer.UpdateClientConnState->balancerWrapper.NewSubConn->ccBalancerWrapper.NewSubConn->ClientConn.newAddrConn->acBalancerWrapper.Connect/acBalancerWrapper.UpdateAddresses->addrConn.connect->addrConn.resetTransport->addrConn.tryAllAddrs->addrConn.createTransport->NewClientTransport->newHTTP2Client
ClientConn.Invoke->invoke->newClientStream->newClientStreamWithParams->clientStream.withRetry->csAttempt.getTransport->ClientConn.getTransport->pickerWrapper.pick->picker.Pick->addrConn.getReadyTransport->csAttempt.newStream->http2Client.NewStream->http2Client.createHeaderFields->http2Client.newStream->controlBuffer.executeAndPut->itemList.enqueue->controlBuffer.get->itemList.dequeue->loopyWriter.handle->loopyWriter.headerHandler/loopyWriter.preprocessData->loopyWriter.writeHeader->loopyWriter.processData
clientStream.SendMsg->prepareMsg->csAttempt.sendMsg->http2Client.Write
clientStream.RecvMsg->csAttempt.recvMsg->recv->recvAndDecompress->parser.recvMsg->recvBufferReader.Read->recvBufferReader.read->recvBuffer.get
http2Client.reader->http2Client.operateHeaders->http2Client.handleData->Stream.write->recvBuffer.put
Server.Serve->Server.handleRawConn->Server.newHTTP2Transport->NewServerTransport->Server.serveStreams->http2Server.HandleStreams->http2Server.operateHeaders/http2Server.handleData->Server.handleStream->Server.processUnaryRPC/Server.processStreamingRPC->recvAndDecompress->Server.sendResponse->http2Server.Write
resolver:passthrough/dns/unix/manual
balancer:pickfirst/roundrobin/weightedroundrobin/weightedtarget/grpclb/rls

gin: 路由匹配用的是前缀树算法,中间件
fasthttp: nethttp更稳定,fasthttp中Request/Response结构体通过sync.Pool获取,内部大量使用了sync.Pool去提高性能,减少[]byte转换string,不支持http2.0,复用goroutine/协程池通过chan唤醒或退出;两者都支持在服务端接收大的body(multipart/form-data数据)的时候把数据先放到磁盘,都支持流式读取body数据;fasthttp与nethttp对responsebody处理的不同之处,fasthttp会等用户handler返回才会开始写body,nethttp内部用了个2kb的缓冲区,如果写满了handler仍然没有返回,会自动切换为chunked编码然后开始写响应头和body,这之后再更改响应头就无效

tar/zip/gzip/bzip2/aes/ecdsa/hmac/md5/sha256/x509/crc32/math/regexp
sql/html/image/mime
wasm
iface/eface _type/_func itab symtab traceback
编译器/汇编/链接器/ast/dwarf/elf
反射reflect
cgo
Rust

C:
https://gcc.gnu.org/
https://github.com/gcc-mirror/gcc

C89/C90 C99 C11 C17/C18 C23
gcc -std=c11 -o app main.c

restrict:
C99引入,用于告诉编译器,对象已经被指针所引用,不能通过除该指针外所有其它直接或间接的方式修改该对象的内容,编译器可以做一些优化;如果restrict修饰的指针指向的内存依然被其它指针修改访问,那么结果是未知的,所以使用restrict的前提是程序员确保只有一个指针在访问数据

register:
变量会作为一个寄存器变量,让该变量的访问速度达到最快,例如一个程序逻辑中有一个很大的循环,循环中有几个变量要频繁进行操作,这些变量可以声明为register类型;不能对寄存器变量使用取地址符&,因为该变量没有内存地址

extern:
用在变量或者函数的声明前,用来说明此变量/函数是在别处定义的,要在此处引用
a.c申明全局变量int a=2;b.c引用extern int a(好像也可以不用extern/可以放在局部申明);全局变量尽量不要放在头文件中,会造成重复定义;可以在.c文件申明变量,在对应.h文件申明extern变量,这样其它.c文件想使用这个变量只需要include头文件即可
extern函数,如果a.c要调用b.c的函数,需要在a.c申明这个函数(可以不是全局申明),可以加extern也可以不加,不加extern编译器会默认加上;使用extern和包含头文件来引用函数的区别是可以加速程序的编译(预处理)
在C++中调用C代码需要带上extern "C",会指示编译器这部分代码按C语言进行编译而不是C++的
#ifdef __cplusplus
extern "C"{
#endif
void fun(int p);
#ifdef __cplusplus
}
#endif
在C语言中调用C++代码,一般会封装C++代码成C语言支持的语法,因为C语言不支持C++的大多数语法

全局变量:
未初始化的全局变量,默认初始化0
全局变量初始化要在编译期就确认,不能通过调用函数的方式获取初始值
全局变量,允许其它c文件通过extern访问到该变量
未初始化的全局变量可以重复定义;初始化的全局变量不能重复定义;可以定义一个初始化的全局变量再定义多个未初始化的同名全局变量,最终的值以初始化的全局变量为准,为了防止不小心申明了和别人一样的全局变量最好在申明全局变量的时候都进行初始化
全局变量和局部变量可以重名,函数内不同作用域也可以定义同名局部变量,访问的时候首先访问的是当前作用域的变量,如果当前作用域没有则访问同名全局变量

static:
static全局变量,不允许其它c文件访问到变量,即使其它c文件使用extern申明也不能访问;未初始化的static全局变量,默认初始化0
static局部变量,在函数内定义也只能在该函数内访问,它的值不会因为函数调用的结束而被清除,当函数再次被调用时它的值是上一次调用结束后的值;处于静态存储区,未经初始化的局部静态变量会被程序自动初始化为0
static函数,不能被其它c文件访问

进程地址空间:
内核空间
栈
共享内存/mmap/共享库
堆
未初始化数据区.bss(未初始化(或初始化为0)全局变量/未初始化(或初始化为0)全局静态变量/未初始化(或初始化为0)局部静态变量)
已初始化数据区.data(已初始化全局变量/已初始化全局静态变量,已初始化局部静态变量)
常量区.rodata(字符串常量/全局const)
代码区.text

gcc:
预处理*.i 编译*.s 汇编*.o 链接.exe
-O0: 默认
-O/-O1: 编译器会尝试减少代码段大小和优化程序的执行时间,但不执行需要消耗大量编译时间的优化
-O2: 相比于-O1,-O2打开了更多的编译优化开关
-O3: 在-O2的基础上,level 3的级别优化
-Os: 优化生成的目标文件的大小
-Ofast: 为了提高程序的执行速度,GCC可以无视严格的语言标准,-Ofast会开启所有-O3的编译开关
-Og: 优化调试信息,相对于-O0生成的调试信息-Og是为了能够生成更好的调试信息,和-O0一样-Og选项关闭了很多优化开关
gcc -Q -O2 --help=optimizers

-g0: 不生成调试信息,相当于没有使用-g
-g1: 生成最小的调试信息,足够在不打算调试的程序中进行堆栈查看,最小调试信息包括函数描述,外部变量,行数表,但不包括局部变量信息
-g2: 默认-g的调试级别
-g3: 相对-g,生成额外的信息,例如所有的宏定义

-ggdb: 生成GDB调试的调试信息
-gdwarf: 生成DWARF格式的调试信息
-gstabs: 生成stabs格式的调试信息,不包含GDB扩展信息

-E: 预编译
-S: 输出汇编代码
-c: 生成xxx.o,只编译不链接
-Wall: 生成所有警告信息
-Werror: 将所有警告都当作错误
-w: 关闭告警
-l: -lpthread
-L: -L/usr/lib
-I: -I/usr/include
-D: -DDEBUG 编译时加的宏
-static: 这主要决定编译-链接时使用的库是静态库还是动态库
动态库: gcc -fPIC -shared -o libxxx.so xxx.o,动态库在程序编译时并不会被连接到目标代码中,而是在程序运行时才被载入,因此在程序运行时还需要动态库存在
静态库: ar -crv libxxx.a xxx.o, gcc -o hello main.c -L. -lxxx,静态库在程序编译时会被连接到目标代码中,程序运行时将不再需要该静态库;如果静态库中使用到了动态库的函数,那么在构建静态库的时候不会打包动态库的代码,同时使用到该静态库的程序在运行时也需要加载动态库

常用函数:
memmove能处理空间重叠,memcpy不能

C++:
c++98 c++03 c++11 c++14 c++17 c++20 c++23
g++ -std=c++11 -o app main.cpp

struct/class:
默认成员权限,class是私有的,struct是公有的
默认继承权限,class是private,struct是public
class可以定义模板参数template<class T>,而没有template<struct T>

static:
静态类成员
静态类成员函数

template:
函数模板
template <typename T = int>默认int
T const& Max(T const& a, T const& b)
类模板
template <class T>
class Stack {
private:
  vector<T> elems;
}

元编程:

引用&:
相当于一个变量的别名,对引用赋值就是对这个变量赋值;一旦引用被初始化为一个对象就不能被指向到另一个对象;引用必须在创建时被初始化,引用在语法层面只能在申明的时候初始化,无法重新赋值,因为后面对引用的所有操作都相当于操作指向的那个变量
引用作为函数返回值要注意返回的值要在函数返回后依然存在,如不能返回函数体内的局部变量(非static)
对const常量取引用,引用也不许是const类型

指针:
对const常量取指针,指针应该是const int*类型的,也可以强制转换成int*类型,能够编译通过,但是对指针的操作是未定义的且不影响常量的值

virtual:
纯虚函数: 只申明不实现,留给子类实现
class A {
public:
  virtual void add(int a, int b) = 0;
}
虚基类:
继承间接共同基类时只保留一份成员,当基类通过多条派生路径被一个派生类继承时,该派生类只继承该基类一次
class Base
class A : virtual public Base
class B : virtual public Base
class C : public A, public B
抽象类:
抽象类就是含有至少一个纯虚函数;抽象类不能有实例对象;子类没有覆写所有的纯虚函数则子类还是抽象类;不能实例化

const:
const修饰类成员函数,其目的是防止类成员函数修改被调用对象的成员值,如下
class A {
private:
  int num;
public:
  int getNum() const 
  {
    //num = 12;
    return num;
  }
}

constexpr:
在编译阶段就能计算出结果;使用gcc时constexpr指针所指变量必须是全局变量或者static变量,constexpr保护指针变量,不保护指针指向的内存;放在if上如果else走不到就不会编译else的内容;即可用于函数声明也可用于变量声明;当一个变量的声明中包含了constexpr时,这个变量将自动成为以const声明的常量
c++11不允许constexpr修饰返回值为void的函数,c++14之后可以
consteval:
只能参与函数的声明,编译时运行的函数,编译时参数是确定的返回值也是常量;constexpr可能退化成运行时计算,但consteval不会,consteval比constexpr更严格
constinit:
只能参与变量的声明,显式地指定变量的初始化方式为静态初始化,主要作用是强调静态变量能在编译期就确定值,只能修饰static/全局变量,实际上并不是常量,可以改变值

final:
禁止重载,std::is_final
修饰类时,禁止继承这个类,struct A final {};
修饰类的成员函数时,这个函数在基类中必须是virtual的
override:
override明确地表示一个函数是对基类中一个虚函数的重载,它会检查基类虚函数和派生类中重载函数的签名不匹配问题,override表示函数应当重写基类中的虚函数(用于派生类的虚函数中)
函数必须是virtual的

using:
using namespace std;
类似typedef,using myint = int;
typedef不能用于模板,using可以定义模板别名

构造函数:
如果类没有定义构造函数则编译器会默认生成一个无参构造函数,如果类定义了一个构造函数(可以有参数也可以无参数),则编译器不会生成默认构造函数
B()    默认构造函数
~B()   默认析构函数
B(const B&) 默认拷贝构造函数
B& operator=(const B&) 默认赋值函数
B(const B&&)      移动构造函数
B& operator=(B&&) 移动拷贝函数

析构函数:
对象在销毁时会自动调用析构函数,完成类的一些资源清理工作
~MyClass() {} //无参数无返回值
如果不显式定义析构函数,编译器会生成一个析构函数,都会在对象的声明周期结束时自动调用,并且会调用成员变量(自定义类型)的析构函数来释放资源
基类指针操作派生类对象,基类析构函数不是虚函数的话,析构时不会调用派生类的析构函数

f() = delete:
指明这个函数不允许调用;可以对任何函数指定=delete,不局限于类的成员函数,但一般情况下对析构函数不指定;一般用来限制一些构造函数的使用,如拷贝构造函数加上=delete就可以禁止类的拷贝;=delete必须出现在函数第一次声明的时候,也就是在类的内部申明的时候
f() = default:
如果自己定义了构造函数,编译器就不会自动生成构造函数,但有时希望编译器依然可以生成一些默认的构造函数,就可以加上=default,编译器将为这些构造函数自动生成函数体,这样可以减轻编码时的工作量
只能对默认构造函数和五个拷贝控制成员使用=default,析构函数也可以定义=default
=default可以在类内部定义也可以在类外部定义
自己定义的默认构造函数没有编译器生成的默认构造函数执行效率高

lambda:
[] () mutable throw() -> return-type {}
捕获列表:捕获列表能够捕捉上下文中的变量以供Lambda函数使用;[var]表示值传递方式捕获变量var,[=]表示值传递方式捕获所有父作用域的变量;[&var]表示引用传递捕捉变量var,[&]表示引用传递方式捕捉所有父作用域的变量;[this]表示值传递方式捕捉当前的this指针
编译器会把一个Lambda表达式生成一个匿名类的匿名对象,并在类中重载函数调用运算符,实现了一个operator()方法
函数式编程

异常:
try {throw 42;} catch (const std::exception& e) {}
func() try {
  throw 23;
}
catch (const std::exception& e) {
  std::cout << e.what() << 'endl';
}
std::exception
std::overflow_error
std::runtime_error
std::system_error
std::bad_alloc

noexcept:
void f() noexcept; // does not throw
void f() noexcept(false); // may throw
void f() throw(int, double); // deprecated in C++11, removed in C++17
void f() throw(); // deprecated in C++17, removed in C++20, 换成noexcept(true)
std::nothrow

右值引用:
可以通过右值引用,充分使用临时变量,减少不必要的拷贝
移动构造函数
移动复制运算符
std::move,将一个左值转换成右值,使用前提:1.定义的类使用了资源并定义了移动构造函数和移动赋值运算符;2.该变量即将不再使用
std::forward,主要是用来解决在参数传递的过程当中右值被传递为左值失去了原来的无拷贝功能,完美转发
x++是右值,++x是左值
将对象的状态或者所有权从一个对象转移到另一个对象,只是转移,没有内存的搬迁或者内存拷贝
左值lvalue,非临时的,可以被取地址,可以出现在等号的左边或右边,可以被修改
右值rvalue,临时的,不能取地址,只能出现在等号的右边,不能被修改
左值引用,引用一个对象
右值引用,必须绑定到右值的引用,通过&&获得右值引用
将亡值,即将被销毁却能够被移动的值
纯右值
返回值优化RVO
命名返回值优化NRVO
&& && -> &&
& && -> &
& & -> &
&& & -> &

const_cast:
去除复合类型中const和volatile属性;有些常量在编译的时候已经硬编码到代码里(常量折叠),所以打印的是硬编码的值不是内存里的值,自定义的数据类型(class/struct)无法在编译阶段常量折叠;
static_cast:
数据类型转换,可使用于需要明确隐式转换的地方,存在安全性
dynamic_cast:
主要用于有继承关系的多态类(基类必须有虚函数)的指针或引用之间的转换,将派生类指针转换为基类指针(上行转换)这个操作与static_cast的效果是一样的,将基类指针转换为派生类指针(下行转换)dynamic_cast具有类型检查的功能,比static_cast更安全
reinterpret_cast:
任意类型的转换,不关心继承体系,存在安全性,后的尖括号中的类型必须是一个指针/引用/算术类型/函数指针或者成员指针,它可以把一个指针转换成一个整数,也可以把一个整数转换成一个指针

static_assert:
编译期间的断言,不生成目标代码,C++11引入,static_assert(bool,"msg")/static_assert(bool)C++17

auto/decltype:
引入decltype是因为auto并不适用于所有的自动类型推导场景,如auto不能作为函数参数;auto不能作用于类的非静态成员变量;auto关键字不能定义数组;auto不能作用于模板参数A<auto>;auto要求变量必须初始化decltype不要求
typeid:
std::type_info
std::type_index

alignas/alignof:
alignas只能是2的次方
如果结构体本身的对齐是n字节,那么alignas只能比n大,否则无效
sizeof(struct A)>=alignof(struct A),alignas设置的如果比sizeof(struct A)还要大,那么sizeof(struct A)就增大

volatile:
当读取volatile变量的时候,系统总是重新从它所在的内存读取数据,即使它前面的指令刚刚从该处读取过数据,而且读取的数据立刻被寄存
mutable:
被mutable修饰的变量将永远处于可变的状态
如果类中的某个成员申明成mutable类型,那么即使类是const的也可以修改这个成员

explicit:
只能用于修饰只有一个参数的类构造函数,表明该构造函数是显示的而非隐式的,类构造函数默认情况下即声明为隐式的,加了explicit之后的构造函数必须明确调用方式,如申明explicit A(int n)后就不能这么调用A a=10;
explicit关键字只对有一个参数的类构造函数有效,如果类构造函数参数大于或等于两个时是不会产生隐式转换的,所以explicit关键字也就无效了,也有一个例外就是当除了第一个参数以外的其它参数都有默认值的时候,explicit关键字依然有效

thread_local:
线程存储期
thread_local变量生命周期是跟着线程走,在线程开始的时候被生成,在线程结束的时候被销毁,每个线程都拥有一个独立的变量实例
thread_local全局变量,它能与static或extern结合,以分别指定内部或外部链接
thread_local局部变量,不像普通局部变量随函数退出即销毁,thread_local局部变量在函数退出后依然存在;thread_local和static同时修饰的局部变量,好像static没什么作用,thread_local局部变量会自动static
thread_local类成员变量,必须是static的
thread_local变量要在声明时初始化,这样只会在线程启动时初始化一次,否则每次都会赋值

namespace:
xy::a = 100;
using namespace xy
using xy::a

friend:
在类中申明友元函数,这个函数不是这个类的成员函数,但是可以在友元函数里访问这个类的私有化成员;友元函数可以是一个独立的函数,也可以是某个类的成员函数
友元类
class A
{
  int data;
  friend class X;
  friend Y;
};
可以在X类中访问A的私有化成员

asm:
C++内部嵌入汇编
asm ("movq $60, %rax\n\t"
     "movq $2,  %rdi\n\t"
     "syscall");

pragma:
#pragma once:
只要在头文件的最开始加入这条就能够保证头文件只被编译一次,类似_Pragma("once")和
#ifndef XXX
#define XXX
code
#endif
优点:可以避免宏名碰撞;缺点:某个头文件有多份拷贝本方法不能保证他们不被重复包含,pragma once针对的是物理文件;#pragma依赖于编译器一些老的编译器不提供
#pragma pack:
#pragma pack(show):显示当前字节对齐方式的字节数以warning显示
#pragma pack(push):将当前的字节对齐方式入栈(internal compiler stack)也就是保存当前的字节对齐方式
#pragma pack(pop):将(internal compiler stack)栈顶的记录出栈也就是恢复最新的一次字节对齐方式
#pragma pack(push,identfier):当同push一起使用时赋予当前被压入栈中的record一个名称
#pragma pack(pop,identfier):当同pop一起使用时从internal compiler stack中pop出所有的record直到identifier被pop出,如果identifier没有被找到则忽略pop操作
#pragma pack(n):指定n个字节对齐,合法数值为2的非负整数次幂1/2/4/8/16缺省时为8
#pragma pack():恢复默认字节对齐
#pragma pack(push,n):当同push一起使用时,将当前的字节对齐方式入栈,同时设置当前的字节对齐数值为n
#pragma pack(pop,n):当同pop一起使用时,将栈顶的字节对齐方式出栈,同时设置当前的字节对齐数值为n

C++20:
<=>
concept
requires

export
import
module

co_await
co_return
co_yield

C++23:
atomic_cancel
atomic_commit
atomic_noexcept
reflexpr
synchronized
transaction_safe
transaction_safe_dynamic

[[noreturn]]
[[maybe_unused]]
[[carries_dependency]]
[[deprecated]]
[[deprecated("reason")]]
[[fallthrough]]
[[nodiscard]]
[[nodiscard("reason")]]
[[likely]]
[[unlikely]]
[[no_unique_address]
[[assume]]

std::array:
std::array<int,4>
内置的数组有很多麻烦的地方,比如无法直接对象赋值,无法直接拷贝等等;支持迭代器访问/获取容量/不会退化成指针
申明时指定数组容量,容量固定不能修改,不能添加或删除元素
std::vector:
std::vector<int>
类似数组是一个连续内存的空间;申明时不用指定容量,可扩容,扩容时重新分配一个两倍的空间,然后将元素从旧空间拷贝过去,旧空间释放
push_back普通追加,要创建一次对象,还要拷贝一次
emplace_back高性能追加操作,只需要创建一次对象,不用拷贝
std::deque:
双端队列,可以高效的在头尾两端插入和删除元素,随机访问快,元素并非连续存储,存储空间会自动按需扩大和缩小,不涉及到现有元素复制到新的内存位置
内部是多个内存块组合成的空间,每个内存块首尾相连,首尾插入数据在不同的方向操作,如果在尾部插入数据发现空间不够,就在尾部再分配一个内存块
std::string:
动态字符串,可以修改的字符串
std::string_view:
对内存字符串进行展示操作,本身并不拥有内存本身,它只是一个View,观看内存的窗口;可以通过取指针的方式修改内存;字符串内存的生命周期或者说作用域一定要大于string_view,否则可能有未知的后果
capacity大于47以后capacity = oldcapacity + oldcapacity/2
list:
双向链表,只支持双向顺序访问,在list中任何位置进行插入/删除操作速度都很快,不支持随机访问
forward_list:
单向链表,只支持单向顺序访问,在链表任何位置进行插入/删除操作速度都很快
std::set
std::unordered_set 平衡二叉树
std::multiset 可以存放多个相同的元素
std::unordered_multiset
std::map
std::unordered_map
std::multimap
std::unordered_multimap
std::stack
std::queue
std::priority_queue

智能指针:
std::unique_ptr:
指针会在unique_ptr析构时释放,不用手动delete p,std::make_unique
std::shared_ptr:
最后一个拥有指针的对象析构的时候会释放内存,std::make_shared
std::weak_ptr:
指向一个shared_ptr指向的对象,且不会改变对象的引用计数,当所有的shared_ptr释放内存会释放,即使weak_ptr还存在

time:
std::time
std::chrono::time_point
std::chrono::duration
std::chrono::system_clock
std::chrono::steady_clock
std::chrono::high_resolution_clock

std::chrono::nanoseconds
std::chrono::microseconds
std::chrono::milliseconds
std::chrono::seconds
std::chrono::minutes
std::chrono::hours

线程:
std::thread
std::this_thread::sleep_for(std::chrono::seconds(1));
std::thread t(func, param1);
t.join()/t.detach()

std::async:
auto a = std::async(std::launch::async, func, param1, param2); a.get();
std::async(&X::foo, &x, param1, param2);
auto a = std::async(std::launch::deferred, &X::bar, x, param1); a.wait()/a.get();
std::async(std::launch::async, X(), 43);

std::future:
f1.wait();f1.get()
std::shared_future:
允许多个线程等待同一个共享状态
std::promise:
std::promise<int> p;
std::future<int> f = p.get_future();
void func(std::promise<int> p) { p.set_value(1); }
std::thread t(func, std::move(p));
int n = f.get()

std::packaged_task:
int func2(int x, int y) { return std::pow(x,y); }
std::packaged_task<int(int,int)> task1(func2);
std::future<int> result = task1.get_future();
std::thread t(std::move(task1), 2, 10); t.join();
result.get();
std::packaged_task<int(int,int)> task2([](int a, int b) { return std::pow(a, b); });
task2(2, 9);
std::packaged_task<int()> task3(std::bind(func2, 2, 11));
task3();

std::mutex
std::timed_mutex
std::recursive_mutex
std::recursive_timed_mutex
std::shared_mutex
std::shared_timed_mutex
std::condition_variable
std::call_once
std::once_flag

std::lock:
同时给多个锁上锁,不自动释放锁,为避免死锁而设计
std::lock_guard:
只能管理一个锁,构造函数即上锁,离开作用域自动析构解锁,可领养锁
std::scoped_lock:
支持绑定多个锁,避免死锁,构造函数即上锁,离开作用域自动析构解锁,可领养锁
std::unique_lock:
只能move不能cpoy,离开作用域自动析构解锁
支持延迟锁/非阻塞锁/领养锁/带时间
std::shared_lock:
包装读锁,只能move不能cpoy,只能管理一个锁,离开作用域自动析构解锁
支持延迟锁/非阻塞锁/领养锁/带时间

std::defer_lock: 延迟锁,不在构造函数加锁,后面手动加锁
std::try_to_lock: 非阻塞锁
std::adopt_lock: 领养锁,调用之前已加锁,确保锁会释放

std::atomic_store
std::atomic_load
std::atomic_exchange
std::atomic_bool

std::decay:
为我们移除类型中的一些特性,比如引用/常量/volatile,但是不包括指针特性
std::for_each:
std::for_each(nums.begin(), nums.end(), [](int &n){ n++; });

std::bitset
std::hash
std::function
std::bind
std::exchange
std::swap
std::sort
std::size_t
std::pair
std::tuple
std::memory_order
std::less
std::greater
std::equal_to
rapidjson/proxygen/beast/proxysql/folly/muduo


2.MySQL
ACID 原子性 一致性 隔离性 持久性
聚族索引和非聚族索引
覆盖索引
主键索引 普通索引 唯一索引 联合索引 全文索引 前缀索引
InnoDB和MyISAM
索引B树和B+树
B树的所有节点既存放键(key)也存放数据(data),而B+树只有叶子节点存放key和data,其他内节点只存放key
B+树的叶子节点有一条引用链指向与它相邻的叶子节点

执行流程: 连接器(管理链接权限验证,user表/db表/tables_priv表/columns_priv表),查询缓存如果存在直接返回(key是具体的SQL语句value是结果的集合,8.0版本以后缓存被官方删除掉),分析器(词法语法分析),优化器(生成执行计划),执行器(调用存储引擎的API),innodb引擎,写Undo Log(写存储指针和事务ID),记录是否在内存中,不在则去磁盘读取,写Redo Log,写binlog,提交事务,刷Redo Log,刷binlog

隔离级别: 读未提交 读已提交 可重复读 可串行化
MVCC: 多版本并发控制,很多情况下它避免了加锁降低了开销,维持一个数据的多个版本,使得读写操作没有冲突;每个事务都有一个对应版本的快照,快照版本按照单向增长的时间戳来决定先后顺序,对于读操作,我们只读该事务开始前的数据库快照,并不去读取正在修改的数据,解决脏读/不可重复读
InnoDB通过数据行的DB_TRX_ID和Read View来判断数据的可见性
DB_TRX_ID(6字节): 表示最后一次插入或更新该行的事务id
DB_ROLL_PTR(7字节): 回滚指针指向该行的undo log
DB_ROW_ID(6字节): 如果没有设置主键且该表没有唯一非空索引时,InnoDB会使用该id来生成聚簇索引
DELETED_BIT(1字节): 记录被更新或删除并不代表真的删除而是删除flag变了,相当于记录一次逻辑删除

快照读: 不加锁的SELECT,不加锁的非阻塞读,串行级别下的快照读会退化成当前读,快照读的实现是基于MVCC,不同的快照可以看作不同的数据版本
当前读: 悲观锁,UPDATE/INSERT/DELETE/SELECT FOR UPDATE/SELECT LOCK IN SHARE MODE,读取的是目前数据库中最新的版本,读取时还要保证其它并发事务不能修改当前记录所以会对读取数据加锁
Read View: 读视图,可见性判断,用来判断当前事务能够看到哪个版本的数据,存放着一个列表,记录当前数据库系统中活跃的读写事务,用来判断某一个版本是否对当前事务可见,changes_visible,读已提交级别下每次读都采用新的Read View,这样就可以读取到其它事务的提交
creator_trx_id(创建当前Read View所对应的事务ID)
m_ids(所有当前未提交事务的事务ID,也就是活跃事务的事务id列表)
min_trx_id(m_ids里最小的事务id值)
max_trx_id(InnoDB需要分配给下一个事务的事务ID值)

redo log: 当mysql服务器意外崩溃或者宕机后,保证已经提交的事务确定持久化到磁盘中的一种措施,修改的数据先放到Buffer Pool中,再写入redo log buffer并刷盘,innodb_flush_log_at_trx_commit:1表示commit的时候进行刷盘;2表示commit的时候只是刷新近os的内核缓冲区具体的刷盘时机不确定;0表示后台线程每s刷新一次到磁盘中;
两阶段提交: 判断这条记录在不在buffer pool中,在的话直接更新,否则从磁盘中加载到buffer pool中然后进行更新,将这个更新操作记录到redo log中,记录的是一个物理日志,此时redo log是一个prepare状态,记录该操作的binlog并且将binlog刷盘,提交事务对redo log进行提交
undo log:
insert undo log:至少把这条记录的主键记录下来,回滚的时候只需要把主键对应的记录删除即可
update undo log:至少要把修改这条记录前的旧值都记录下来,回滚的时候再把这条记录的值更新为旧值
delete undo log:删除一条记录时至少要把这条记录中的全部内容都记录下来,回滚的时候再重新将这些内容组成的记录插入到表中就好了,删除操作都只是设置一下老记录的DELETE_BIT,并不是真正将其删除,为了节省磁盘空间InnoDB有专门的purge线程来清理DELETED_BIT为true的记录,如果某个记录的DELETED_BIT为true并且DB_TRX_ID(最后一个操作的事务ID)相对于purge线程的readview可见,那么这条记录一定是可以被安全清除的

Record lock: 记录锁,单条索引记录上加锁
Gap lock: 间隙锁,锁住一个索引区间(开区间,不包括双端端点),防止幻读,保证索引间的不会被插入数据
Next-key lock: 临键锁 = Gap Lock + Record Lock,为了解决幻读,左开右闭区间
自增锁
意向锁: 意向共享锁IS/意向排它锁IX,表级别锁,比如一个事务想要对表加排他锁(alter table/drop table),如果没有意向锁的话,那么该事务在加锁前需要判断当前表的每一行是否已经加了锁,如果表很大遍历每行进行判断需要耗费大量的时间,如果使用意向锁的话,那么加表锁前,只需要判断当前表是否有意向锁即可,这样加快了对表锁的处理速度
插入意向锁: 间隙锁的一种,专门针对insert操作,多个事务在同一个索引同一个范围区间插入记录时候,如果插入位置不冲突,不会彼此阻塞
select ... lock in share mode  S锁 共享锁 当前读
select ... for update X锁 排他锁 当前读

唯一索引等值查询:
当查询的记录存在,next-key lock会退化成记录锁
当查询的记录不存在,next-key lock会退化成间隙锁

非唯一索引等值查询:
当查询的记录存在,除了会加next-key lock外,还额外加间隙锁,也就是会加两把锁
当查询的记录不存在,只会加next-key lock,然后会退化为间隙锁,也就是只会加一把锁

唯一索引范围查询&非唯一索引范围查询:
唯一索引在满足一些条件的时候,next-key lock退化为间隙锁和记录锁
非唯一索引范围查询,next-key lock不会退化为间隙锁和记录锁

脏读: 一个事务读取到了另一个事务没有提交的内容,事务1更新了一行数据未提交,这时事务2可以读到事务1更新的那一行数据,此时事务1rollback,那么事务2读到的数据就是脏数据
幻读: 一个事务内两次查询的结果集数量不一致;可重复读隔离级别下快照读是通过MVCC/Read View解决幻读的;可重复读隔离级别下当前读没有解决幻读,可以通过select for update解决,使用了next-key(记录锁和间隙锁的组合)
幻读仅专指新插入的行,中途通过update更新数据而出现同一个事务前后两次查询的结果集合不一样这种不算幻读
插入: 事务1执行查询操作,事务2插入一行数据并提交,事务1执行update并也更新到了事务2新插入的那一行,事务1再次查询就可以查询出事务2新插入的那一行
更新: 事务1执行查询操作,事务2更新一行数据的其中一个字段并提交,事务1执行update并也更新到了事务2更新的那一行,事务1再次查询就可以查询出事务2更新的数据
删除: 事务1执行查询操作,事务2删除一条数据,事务1执行update并也更新到了事务2删除的那一行,事务1再次查询依然可以查询出事务2删除的那一行

不可重复读: 一个事务内两次查询的结果不一样
回表: 先到普通索引上定位主键值,再到聚集索引上定位行记录,索引覆盖:联合索引减少回表,查询字段都在索引里就不用回表了

分库分表:
热点数据太多,数据库缓存不足产生大量磁盘IO效率较低,请求数据太多带宽不够网络IO瓶颈
CPU瓶颈,排序/分组/连接查询/聚合统计等SQL会消耗大量的CPU资源
缺点:分布式事务/跨库join查询/分布式全局唯一id/开发成本高
水平分表: 指同一个库中的两个表结构一样表名不一样,如按照月份去区分表
垂直分表: 表中字段太多可以拆分成多个表,用唯一字段去关联多个表
水平分库: 每个库内的表结构相同,根据userid的哈希值去找到对应的库
垂直分库: 根据业务拆分,电商系统,拆分成订单库,会员库,商品库

主从复制: 解决Mysql的单点故障
基于语句的复制STATEMENT/基于行的复制ROW/混合类型的复制MIXED(一旦发现基于语句的无法精确的复制时就会采用基于行的复制)
master将数据的改变都记录到binlog
salve服务器会在一定时间间隔内对主节点binlog进行探测其是否发生改变,如果发生改变则开启一个I/O Thread请求主节点binlog
同时主节点为每个I/O线程启动一个dump线程,用于向其发送binlog,并保存至从节点本地的中继日志(relay log)中
从节点将启动SQL线程从中继日志中读取binlog在本地重放使得其数据和主节点的保持一致
最后I/O Thread和SQL Thread将进入睡眠状态等待下一次被唤醒
异步复制,MySQL默认的复制即是异步的
全同步复制,当主库执行完一个事务,所有的从库都执行了该事务才返回给客户端
半同步复制,主库在执行完客户端提交的事务后不是立刻返回给客户端,而是等待至少一个从库接收到并写到relay log中才返回给客户端
Loss-Less半同步复制,rpl_semi_sync_master_wait_point,AFTER_SYNC:Waiting Slave dump在Storage Commit之前,主要是解决了AFTER_COMMIT导致的主库crash后主从之间数据不一致的问题;AFTER_COMMIT:提交之后再发给从库
读写分离: 缓解数据库压力,数据库的写入影响了查询的效率,更新少查询多的情况下会考虑使用

优化:
update语句的where条件没有用到索引列就会全表扫描,会锁住整个表
避免索引失效,如<>,LIKE '%ABC',NOT IN,字段重复率过高,or语句前后没有同时使用索引,组合索引不是使用第一列索引,如果列类型是字符串那一定要在条件中将数据使用引号引用起来否则不使用索引,IS NULL/IS NOT NULL,对索引字段进行计算操作字段上使用函数,当全表扫描速度比索引速度快时
长字段建立索引可以存储字段的hash值,这样可以快速判断这个字段是否存在

数据库三范式: 每列保持原子性 每列都和主键相关 每一列数据都和主键直接相关而不能间接相关
MySQL死锁

force index([index_name])

TIMESTAMP: 把客户端插入的时间从当前时区转化为UTC,查询时将其又转化为客户端当前时区进行返回;'1970-01-01 00:00:01.000000'to'2038-01-19 03:14:07.999999';插入NULL会自动赋值当前时间;4个字节;相对快
DATETIME: 原样输入和输出;'1000-01-01 00:00:00.000000'to'9999-12-31 23:59:59.999999';插入NULL就是NULL;8个字节;相对慢

utf8是1字符3字节,gbk是1字符2字节
utf8mb4的编码,mb4就是most bytes 4的意思,专门用来兼容四字节的unicode,好在utf8mb4是utf8的超集,除了将编码改为utf8mb4外不需要做其他转换
CHAR: 字符数而不是字节数;最大值为255字符;长度固定;速度快;CHAR(M)每个值都占用M个字节,如果某个长度小于M就会在它的右边用空格字符补足;
VARCHAR: 字符数而不是字节数;最大值为65535字节;可变长;速度慢;VARCHAR(M)每个值只占用刚好够用的字节再加上一个用来记录其长度的字节;
TEXT: 申明时不设置最大长度;最大65535字节;最慢
BLOB: 二进制

LIMIT: LIMIT offset,n; LIMIT n; LIMIT n OFFSET offset;
GROUP BY
ORDER BY ASC/DESC
INNER JOIN/LEFT JOIN/RIGHT JOIN/CROSS JOIN/OUTER JOIN
LIKE
UNION
COUNT/SUM/AVG/MAX/MIN
DISTINCT
HAVING:WHERE聚合前筛选记录,HAVING聚合后使用,WHERE>聚合函数(SUM,MIN,MAX,COUNT)>HAVING,HAVING和GROUP BY组合用,SELECT name,COUNT(score) nums FROM t GROUP BY name HAVING nums>2;
USING
IS NULL/IS NOT NULL
IN/NOT IN
BETWEEN
AS
EXISTS
存储过程
定时任务


3.Redis
string SDS 长度不能超过512M int编码 raw编码 embstr编码
hash hashtable ziplist(列表保存元素个数小于512个&每个元素长度小于64字节)
list linkedlist ziplist(列表保存元素个数小于512个&每个元素长度小于64字节)
set hashtable intset(集合对象中所有元素都是整数&集合对象所有元素数量不超过512)
zset skiplist&字典 ziplist(保存的元素数量小于128&每个元素长度小于64字节)

AOF
RDB 快照 save&bgsave dump.rdb
RDB在恢复大数据集时的速度比AOF的恢复速度要快

HyperLogLog
PUB/SUB
事务 MULTI EXEC DISCARD UNWATCH WATCH
Lua EVAL "return {KEYS[1],KEYS[2],ARGV[1],ARGV[2]}" 2 key1 key2 first second
Redis GEO
Redis Stream
Redis Pipeline
Redis Bitmap

redis缓存击穿(热点key不失效或加锁)、缓存穿透(不存在的key设置空value和过期时间)、缓存雪崩(key失效时间不同)

redis和mysql数据一致性保证:
强一致性 弱一致性 最终一致性
Pattern: Cache-Aside/旁路缓存模式 Read-Through/Write-Through/读写穿透 Write-Behind/异步缓存写入
延时双删: 先删除缓存 再更新数据库 休眠一会再次删除缓存
同步binlog

读操作:
读到缓存直接返回
读不到缓存,先去DB读数据,再更新到缓存,再返回
写操作:
先写DB,删除缓存
问题:
A读了数据库还未更新缓存
B修改数据库
A再去更新缓存
数据不一致
解决办法加短的过期时间

单节点
主从 replicaof 127.0.0.1 7000
redis cluster
redis cluster+主从
主从+哨兵

daemonize yes
bind 127.0.0.1
port 7000
dir /home/thomas/server/redis/data/redis-7000
pidfile /var/run/redis/redis-7000.pid
logfile /home/thomas/server/redis/log/redis-7000.log
cluster-enabled yes
cluster-config-file /home/thomas/server/redis/conf/cluster-7000.conf
cluster-node-timeout 10000

rm -rf cluster data log
mkdir cluster data log
mkdir data/redis-7000 data/redis-7001 data/redis-7002 data/redis-8000 data/redis-8001 data/redis-8002 data/sentinel-9000 data/sentinel-9001 data/sentinel-9002

./redis-server /home/thomas/server/redis/conf/redis-7000.conf
./redis-cli -p 7000
./redis-cli --cluster create 127.0.0.1:7000 127.0.0.1:7001 127.0.0.1:7002
./redis-cli -c -p 7000
./redis-cli --cluster check 127.0.0.1:7000
./redis-cli --cluster reshard 127.0.0.1:7000
./redis-cli -p 7000 cluster nodes
./redis-cli --cluster add-node 127.0.0.1:7003 127.0.0.1:7000
./redis-cli --cluster add-node 127.0.0.1:8000 127.0.0.1:7000 --cluster-slave
./redis-cli --cluster add-node 127.0.0.1:8001 127.0.0.1:7000 --cluster-slave --cluster-master-id 7f3541c3b2e8bd05226729e9889a338b341cd77e
./redis-cli --cluster del-node 127.0.0.1:7000 3adfaaeb6d60f39e70562d961fe7fae200913386

port 9000
daemonize yes
logfile /home/thomas/server/redis/log/sentinel-9000.log
pidfile /var/run/redis/sentinel-9000.pid
dir /home/thomas/server/redis/data/sentinel-9000

sentinel monitor mymaster 127.0.0.1 7000 2
sentinel down-after-milliseconds mymaster 1500
sentinel failover-timeout mymaster 30000

./redis-sentinel /home/thomas/server/redis/conf/sentinel-9000.conf
./redis-cli -p 9000
sentinel master mymaster


4.NoSQL
MongoDB
LevelDB rocksdb
TiDB

ElasticSearch:
Shard/Replica 倒排索引 master/data/ingest/coodrinating only
Logstash/Kibana/filebeat/Flume

Etcd/ZooKeeper/Nacos/Consul
Ceph
Promethous/Grafana
MinIO


5.MQ 异步/解耦/削峰
Kafka
消息永久保存,定期删除
topic partition ISR/OSR/AR
pull方式消费消息

Consumer Group:
多个消费者组成一个group,组内的所有消费者协调在一起来消费订阅主题的所有分区,每个分区只能由同一个消费组内的一个consumer来消费,避免重复消费,
记录offset到__consumer_offsets kafka自带的topic(记录到具体哪个分区hash(groupID) % numPartitions)

自动提交/手动提交: enable.auto.commit = true

Rebalance:
组成员发生变更/订阅主题数发生变更/订阅主题的分区数发生变更
coordinator来执行对于consumer group的管理,从consumer group选出一个leader并且generation+1,leader生成具体消费方案,leader把生成的方案发给coordinator,coordinator再同步给所有consumer
Heartbeat请求: consumer需要定期给coordinator发送心跳来表明自己还活着
LeaveGroup请求: 主动告诉coordinator我要离开consumer group
SyncGroup请求: group leader把分配方案发给coordinator,coordinator再告诉组内所有成员
JoinGroup请求: 成员请求加入组
DescribeGroup请求: 显示组的所有信息，包括成员信息，协议名称，分配方案，订阅信息等。通常该请求是给管理员使用

生产者幂等性:
ProducerID(每个新的Producer在初始化的时候会被分配一个唯一的PID)
SequenceNumber(对于每个PID,该Producer发送数据的每个<Topic,Partition>都对应一个从0开始单调递增的SequenceNumber)
只能保证单个partition内的幂等性,只能保证Producer在单个会话内不丟不重

事务:
涉及到多个Topic-Partition的写入时,这个事务操作要么会全部成功,要么会全部失败
initTransactions beginTransaction commitTransaction/abortTransaction
transactionalID由用户提供,和ProducerID+epoch组成唯一值
TransactionCoordinator __transaction_state
isolation.level read_committed/read_uncommitted
LEO: 日志末端位移(log end offset),最后一条消息的下一条消息的位移值
HW: 水位值,HW值不会大于LEO值,小于等于HW值的所有消息都被认为是已备份的,consumer无法消费分区下leader副本中位移值大于分区HW的任何消息,Kafka使用HW值来决定副本备份的进度
LSO:

log:
每个partition都有一个目录,里面有很多segment file
partition的第一个segment从0开始,后续每个segment文件名为上一个segment文件最后一条消息的offset
.index 文件名是消息总偏移 内容: 消息偏移(每个index都从0开始,稀疏索引,不是连续的)+字节偏移offset
.log
.timeindex CreateTime表示producer创建这条消息的时间,LogAppendTime leader broker将这条消息写入到log的时间

RabbitMQ
消息消费完就删除
AMQP/高级消息队列协议
routing-key/路由
交换器/Exchange: direct/fanout/topic/headers
支持pull、push方式消费消息

消息丢失:
生产者 事务(同步阻塞慢) 发送确认(异步快)(确认成功就在数据库设置标记,否则重新发送消息,未确认的消息也可存在内存/本地磁盘/redis)
broker 持久化Exchange、Queue、Message
消费者 改为手动提交(自动提交在broker发送消息到消费端就会删除) autoAck=false

死信交换机/死信队列:
默认情况下queue中被抛弃的消息将被直接丢掉,但是可以通过设置queue的x-dead-letter-exchange参数将被抛弃的消息发送到指定的exchange中
消费方nack/reject时指定了requeue=false、消息的TTL已到、消息队列的max-length已到
设置队列中所有消息的过期时间x-message-ttl,队列最大消息数x-max-length,生产者设置单个消息的expiration
Alternate Exchange: 发送消息的时候根据routing-key没有对应的队列接受消息,这就会将此消息路由到Alternate Exchange属性指定的Exchange上了,如果mandatory=true则会将消息返回给生产者
如果发送到A消费者的消息一直不确认,只有等到A消费者与rabbitmq的连接中断,rabbitmq才会考虑将A消费者未确认的消息重新投递给另一个消费者

Ack: 确认后删除消息; Reject: 只能拒绝一个; Nack: 可以拒绝多个

Message:
expiration 消息的过期时刻
deliveryMode 1为非持久化,2为持久化
Queue:
durable 持久化
exclusive 该队列仅对首次声明他它的连接可见,并在连接断开时自动删除
autoDelete 所有与这个连接的消费者都断开时会自动删除
Exchange:
durability 持久化
autoDelete 与这个Exchange绑定的Queue或Exchange都与此解绑时,会删除本交换器

requeue重新放入队列,是立即可以再次消费还是等多长时间?
没有ack后多久可以再次消费此消息?

集群:
普通集群 队列只会存在一个节点,存在哪个节点,是固定的一个还是随机分散?
镜像队列 主从模式,针对的是队列不是节点,push操作会在主从的每个节点上执行一次,消费操作在master执行然后广播给每个slave;
        新增加一个节点需要配置才会同步master所有数据,并且同步时会阻塞

延时队列: 死信队列+ttl 插件rabbitmq-delayed-message-exchange
优先队列: 队列设置的x-max-priority,消息设置队列设置的priority,优先级越大越先消费

事务:
txSelect txComment txRollback

RocketMQ
消息永久保存,定期删除
支持pull、push方式消费消息
NameServer: 路由控制中心,NameServer之间没有数据同步,Broker上报信息到NameServer
Broker: 多主多从,只有主Broker节点才能写,当master宕机,master上的队列不可写入,但是读取依然是可以的
生产消息: SendSync/SendAsync/SendOneWay

Topic:
主题,创建topic时指定读写队列数量,可以指定broker创建也可以让集群自动分配
mqadmin updateTopic
mqadmin deleteTopic
mqadmin updateSubGroup
mqadmin deleteSubGroup
mqadmin updateTopicPerm
mqadmin consumerProgress
writeQueueNums/readQueueNum: 方便队列的缩容和扩容

Tag: 子主题
GroupName: 生产者组合或消费者组合
ProducerGroup: 
ConsumerGroup: 一个Queue最多只能分配给一个Consumer

主从:
slave向master报告自己的最大偏移量
master向slave返回偏移量后的CommitLog数据
brokerId=0表明这个broker是master,brokerId>0表明这个broker是slave
slave只负责读,rocketmq目前还不支持主从切换,需要手动切换
正常情况下consumer并不能配置从master读还是slave读,本次拉取的数据量大于物理内存的40%和当master不可用或者繁忙的时候consumer会从slave读
master可配置同步复制SYNC_MASTER/异步复制ASYNC_MASTER

Rebalance: 
订阅Topic的队列数量变化(broker宕机、队列扩容/缩容)/消费者组信息变化(消费者宕机、消费者扩容/缩容、Topic订阅信息发生变化)
一个队列最多分配给一个消费者,offset是异步提交造成重复消费,Broker端负责Rebalance元数据维护
周期性触发rebalance
同一个消费者组订阅多个Topic时可能会出现分配不均
对Topic队列/消费者各自进行排序,每个消费者需要使用相同的分配策略

广播消费:
广播模式消费位移使用本地文件存储,Rebalance过程中同一个ConsumeGroup下的consumer不会进行MessageQueue的分配,每个consumer负责订阅的topic下的所有MessageQueue

log:
commitLog存消息数据
consumeQueue存索引
config存Group/Topic/Consumer消费的offset
超时时间/磁盘占比/人工删除触发删除commitLog/consumeQueue

offset: 当消费模式为广播模式时offset使用本地模式存储;集群模式下存在config
消息堆积: 增加consumer;放到临时的topic再增加新的consumer去消费

延时队列:
生产消息时设置,只能选择1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h(可以改配置文件增加level),level从1开始;消息按照延迟时间段发送到指定的延时队列(SCHEDULE_TOPIC_XXXX)中,定时器进行轮训这些队列查看消息是否到期,如果到期就把这个消息发送到指定topic的队列中,这样的好处是同一队列中的消息延时时间是一致的,还有一个好处是这个队列中的消息是按照消息到期时间进行递增排序的,然后把延迟队列中的消息删除

死信队列:
%DLQ%+consumerGroup
消费失败自动进行消息重试,达到最大重试次数后将其发送到该消费者对应的特殊队列中,有效期与正常消息相同到期自动删除
一个死信队列对应一个GroupID

重试:
广播消息是不会重试的
生产端重试: 生产端自动重试,可设置超时时间和重试次数,异步发送重试次数只有1/0次
消费端重试: 主动返回RECONSUME_LATER消息会进入重试队列,超过最大重试次数就进入死信队列;超时重试是直接重试不需要延时,会一直重试下去;message携带重试次数消费端可以用来判断
重试队列: 先保存到SCHEDULE_TOPIC_XXXX中,再设置偏移量,后台定时任务按照对应的时间进行Delay后重新保存至%RETRY%+consumerGroup重试队列中,消费者消费重试队列

事务:
prepare阶段
commit/rollback阶段

ActiveMQ
JMS
kahadb leveldb mysql
topic
P2P: 生产者向队列投递一条消息,只有一个消费者能够监听得到这条消息
Pub/Sub: 生产者向队列投递一条消息,所有监听该队列的消费者都能够监听得到这条消息
与zookeeper进行构建主备集群模型
Network集群模型

Pulsar

优先队列
延时队列
消息丢失
重复消费 幂等
顺序消费
消息堆积
事务


6.网络/IP/TCP/UDP
OSl七层参考模型:
物理层 负责0/1比特流与物理设备电压高低/光的闪灭之间的互换
数据链路层 ARP RARP 将0/1序列划分为数据帧从一个节点传输到临近的另一个节点,这些节点是通过MAC来唯一标识的
网络层 IP ICMP IGMP
传输层 TCP UDP
会话层 建立维护会话
表示层 数据格式转化数据加密压缩
应用层 HTTP FTP TFTP SMTP DNS NFS SNMP TELNET

MTU: Maximum Transmit Unit,最大传输单元,由数据链路层提供给网络层最大一次传输数据的大小,一般MTU=1500字节
MSS：Maximum Segment Size(最大报文段长度),TCP提交给IP层最大分段大小,不包含TCP Header和TCP Option,只包含TCP Payload,MSS是TCP用来限制应用层最大的发送字节数
MSS = 1500- 20(IP Header) -20 (TCP Header) = 1460 byte
为什么MTU一般是1500:如果MTU太小则传输效率低,因为头部字段是固定长度的,每次传输都要带上头部;如果MTU太大容易出现丢包
MSS 536?

数据链路层:
封装成帧:把网络层数据报加头和尾,封装成帧,帧头中包括源MAC地址和目的MAC地址
透明传输:零比特填充,转义字符
可靠传输:在出错率很低的链路上很少用,但是无线链路WLAN会保证可靠传输
差错检测(CRC):接收者检测错误,如果发现差错,丢弃该帧

ARP:
地址解析协议,根据IP地址获取MAC地址
先查询ARP缓存(IP-MAC对应表),如果不存在,那么主机就向网络发送ARP协议广播包,广播包携带IP地址,收到这个广播包的主机会查询自己的IP地址,如果符合就发送携带自己MAC地址的ARP包给源主机,源主机拿到ARP包后会更新自己的缓存
arp -a

IP:
所有的TCP/UDP/IMCP/IGMP的数据都以IP数据格式传输,IP不是可靠的协议,IP协议没有提供一种数据未传达以后的处理机制
32位IP地址分为网络位和地址位,这样做可以减少路由器中路由表记录的数目,限定拥有相同网络地址的终端都在同一个范围内,那么路由表只需要维护一条这个网络地址的方向,就可以找到相应的这些终端了
IP头部20字节,头部字段:4位版本(IPv4/IPv6/PIP),4位首部长度,8位TOS,16位总长度,16为标识,3位标识,13位片位移,8位生存时间(TTL,该数据包在穿过多少个路由之后才会被抛弃,IP数据包每穿过一个路由器,该数据包的TTL数值就会减少1,当该数据包的TTL成为零它就会被自动抛弃,这个字段的最大值是255),8位协议类型(ICMP1,IGMP2,TCP6,UDP17),16位首部校验和,32位源IP,32位目的IP
options字段+填充(默认无),IP头部可从20字节扩展到60字节

IP地址分类:
IP地址=IP地址类型+网络ID+主机ID
A类,0+7位网络ID+24位主机ID,一共128个,允许127个网络,允许1670万台主机,适合大规模的网络,000-127
B类,10+14位网络ID+16位主机ID,16000个网络,65535台主机,适合中等规模的网络,128-191
C类,110+21位网络ID+8位主机ID,共有209万个网络,每个网络有254台主机,适合小型网络,192-223
D类,1110+28位多播地址,组播,224-239
E类,1111,保留地址,240-255

主机ID全为0的地址不分配给任何主机,用于表示某个网络的网络地址,192.168.1.0网络表示192.168.1.1-192.168.1.254的主机ID
主机ID全为1的地址不分配给任何主机,用作广播地址,目的地址为这个地址数据发给该网络的所有主机,如192.168.1.255
255.255.255.255为有限广播地址,子网的广播地址路由器不转发
0.0.0.0表示主机本身,发往此IP地址的数据由本机接收
127.0.0.1回环地址代表本机IP

IPv6:
地址占16字节,分为8段,每段为16bit,网络前缀+接口标识
头部40字节,4位版本,8位流类别(traffic class类似TOS),20位流标签(flow label),16位载荷长度,8位下一个报头(next header),8位跳数限制(类似TTL),源地址,目的地址
扩展首部:next header+扩展首部长度+扩展首部数据
IPv6地址分为单播地址/任播地址(Anycast Address)/组播地址,取消了广播地址
IPv6单播地址分为未指定地址/环回地址(0:0:0:0:0:0:0:1/128)/全球单播地址/唯一本地地址/链路本地地址/特殊地址

ICMP:
Internet Control Message Protocol,互联网控制报文协议,确认IP包是否成功送达目标地址,报告发送过程中IP包被废弃的原因,改善网络设置
当传送IP数据包发生错误,比如主机不可达,路由不可达等等,ICMP协议将会把错误信息封包,然后传送回给主机,给主机一个处理错误的机会,这也就是为什么说建立在IP层以上的协议是可能做到安全的原因
ICMP头部,8位类型(取值为1~127的差错报文,取值128以上的信息报文),8位代码(类型字段一起共同标识了ICMP报文的详细类型),16位校验和(整个ICMP数据报的校验和),32位数据(取决于报文类型),数据部分,将整个ICMP报文放入IP包的载荷部分
ping:request:类型8,代码0;reply:类型0,代码0
网络/主机/协议/端口不可达,Type=3,网络不可到达Code=0,主机不可到达Code=1,协议不可到达Code=2,端口不可达Code=3

IGMP:
Internet Group Management Protocol,互联网组管理协议,负责IPv4组播成员管理的协议,在接收者主机和与其直接相邻的组播路由器之间建立和维护组播成员关系,IGMP报文封装在IP报文中
IGMP报文向路由器申请加入和退出组播组,默认情况下路由器是不会转发组播包到连接中的主机,除非主机通过IGMP加入到组播组,主机申请加入到组播组时,路由器就会记录IGMP路由器表,路由器后续就会转发组播包到对应的主机了
IGMP报文采用IP封装,IP头部的协议号为2,而且TTL字段值通常为1,因为IGMP是工作在主机与连接的路由器之间

加入组播组:
路由器会周期性发送目的地址为224.0.0.1(同一网段内所有主机和路由器)的IGMP常规查询报文
主机收到这个查询后会启动报告延迟计时器,计时器的时间是随机的,通常是0~10秒,计时器超时后主机就会发送IGMP成员关系报告报文,源IP地址为自己主机的IP地址,目的IP地址为组播地址,如果在定时器超时之前收到同一个组内的其它主机发送的成员关系报告报文,则自己不再发送,这样可以减少网络中多余的IGMP报文数量
路由器收到主机的成员关系报文后,就会在IGMP路由表中加入该组播组,后续网络中一旦该组播地址的数据到达路由器,它会把数据包转发出去

退出组播组:
情况一网段中仍有该组播组:
主机1要离开组224.1.1.1,发送IGMPv2离组报文,报文的目的地址是224.0.0.2(发向网段内的所有路由器),路由器收到该报文后,以1秒为间隔连续发送IGMP特定组查询报文,共计发送2个,以便确认该网络是否还有224.1.1.1组的其它成员,其它主机立即响应这个特定组查询,路由器知道该网络中仍然存在该组播组的成员,于是继续向该网络转发224.1.1.1的组播数据包
情况二网段中没有该组播组:
主机1要离开组播组224.1.1.1,发送IGMP离组报文,路由器收到该报文后,以1秒为间隔连续发送IGMP特定组查询报文,共计发送2个,此时在该网段内,组224.1.1.1已经没有其他成员了,因此没有主机响应这个查询,一定时间后,路由器认为该网段中已经没有224.1.1.1组播组成员了,将不会再向这个网段转发该组播地址的数据包

UDP:
User Datagram Protocol,用户数据报协议
发送端发了10次接收端也会接收10次,应用层交给UDP多长的报文,UDP就照样发送,即一次发送一个报文,若报文太长则IP层需要分片降低效率
UDP头部8字节,16位源端口号,16位目的端口号,16位长度(包括数据和首部),16位校验和
校验和计算,12字节伪首部(4字节源IP地址+4字节目的IP地址+1字节0+1字节0x11+2字节UDP长度)+UDP头部+UDP数据

TCP:
面向连接 可靠的 基于字节流
TCP Header,16位源端口,16位目的端口,32位序列号seq,32位确认号ACK,4位数据偏移(标识该TCP头部有多少个4字节),6位保留,URG,ACK,PSH(提示接收端应该立即从TCP接受缓冲区中读走数据为接受新数据腾出空间),RST,SYN,FIN,16位窗口(TCP接收端缓冲区还能容纳多少个字节),16位校验和(不仅校验头部还包括数据部分),16位紧急指针(发送端向接收端发送紧急数据的方法),选项+填充(可选,这部分最多包含40个字节)
TCP头部最长为60字节
发送端发了10次接收端不一定接收10次
TCP分段时使用MSS,IP分片时使用MTU
半连接队列
全连接队列

三次握手:
client                                                server
            -->            SYN=1,seq=x          -->
SYN-SENT
            <--     SYN=1,ACK=1,seq=y,ack=x+1   <--
                                                      SYN-RCVD
            -->        ACK=1,seq=x+1,ack=y+1    -->
ESTABLISHED
                                                      ESTABLISHED
为什么是三次握手而不是两次:
1.确认客户端和服务端的原始序列号
2.确认客户端和服务端都可以收发数据

四次挥手:
client                                                server
            -->            FIN=1,seq=u          -->
FIN-WAIT1
            <--        ACK=1,seq=v,ack=u+1      <--
                                                      CLOSE-WAIT
FIN-WAIT2
            <--     FIN=1,ACK=1,seq=w,ack=u+1   <--
                                                      LAST-ACK
            -->       ACK=1,seq=u+1,ack=w+1     -->
TIME-WAIT(2MSL)
                                                      CLOSED
CLOSED

TIME-WAIT:
怕最后一个ACK包对方没有收到,对方在超时后将重发第三次握手的FIN包,主动关闭端接到重发的FIN包后可以再发一个ACK应答包,实际使用中通过设置SO_REUSEADDR选项可以不必等待2MSL时间结束后再使用此端口;怕影响下一个链接
MSL(Maximum segment Lifetime)报文最大生存时间,它是任何报文在网络上存在的最长时间,超过这个时间报文将被丢弃,RFC793中规定MSL为2分钟,实际常用的是30秒,1分钟和2分钟

TCP Keep-Alive:
时间通常是设置为2小时,每隔75秒钟发送一次,若一连发送10个探测报文仍然没反应,服务器就认为客户端出了故障,接着就关闭连接

拥塞控制:
发送方维持一个拥塞窗口cwnd(congestion window),发送方让自己的发送窗口等于拥塞窗口,只要网络没有出现拥塞,拥塞窗口就再增大一些,以便把更多的分组发送出去,但只要网络出现拥塞,拥塞窗口就减小一些,以减少注入到网络中的分组数
无论在慢开始阶段还是在拥塞避免阶段,只要发送方判断网络出现拥塞(没有收到确认),就把慢开始门限ssthresh设置为出现拥塞时的发送方窗口的一半,但不能小于2,然后把拥塞窗口cwnd重新设置为1,执行慢开始算法,使得发生拥塞的路由器有足够时间把队列中积压的分组处理完毕
cwnd<ssthresh,使用慢开始算法
cwnd>ssthresh,停止使用慢开始算法而改用拥塞避免算法
cwnd=ssthresh,既可使用慢开始算法,也可使用拥塞避免算法

慢启动:
慢开始,指数增长,慢启动门限(ssthresh),当主机开始发送数据时,如果立即发送大量数据注入到网络,那么就有可能引起网络拥塞,因为现在并不清楚网络的负荷情况,因此较好的方法是先探测一下,即由小到大逐渐增大发送窗口,也就是说由小到大逐渐增大拥塞窗口数值
初始时设置拥塞窗口cwnd为一个最大报文段MSS的数值,每经过一个传输轮次(往返时间RTT)拥塞窗口cwnd*2,直到拥塞窗口cwnd大于ssthresh,就进入拥塞避免阶段

拥塞避免:
线性增长,让拥塞窗口cwnd缓慢地增大,即每经过一个往返时间RTT就把发送方的拥塞窗口cwnd加1而不是加倍

快速重传:
首先要求接收方每收到一个失序的报文段后就立即发出重复确认,收到3个相同的ACK,则直接重传丢失的报文,不需要等待重传计时器到期

快速恢复:
当发送方连续收到三个重复确认时,设置慢开始门限ssthresh=cwnd/2,cwnd=ssthresh,然后进入快速恢复算法,cwnd=ssthresh+3,重传丢失的数据包,如果再收到重复的ACK那么cwnd加1,如果收到新数据的ACK后设置cwnd=ssthresh,恢复过程已经结束,然后开始执行拥塞避免算法,使拥塞窗口缓慢地线性增大

滑动窗口:
窗口大小就是指无需等待确认应答,而可以继续发送数据的最大值,假设窗口大小为3个TCP段,那么发送方就可以连续发送3个TCP段,并且中途若有ACK丢失,可以通过下一个确认应答进行确认,只有收到最后一个ACK才能继续发送数据

Nagle算法:
等待多个数据包,避免发送小的数据包,长度达到MSS立刻发送否则等待下一个包到来,如果下一包到来后两个包的总长度超过MSS的话就会进行拆分发送;等待超时(一般为200ms)立即发送;导致粘包和性能问题,一般也会把它关掉

粘包:
加入特殊标志;加入消息长度信息;CRC;UDP无粘包问题,UDP每个包包头都有长度字段;IP层也没有粘包问题,如果数据量很大数据会被切片,每个切片数据通过IP包发送会携带偏移量

TCP队头阻塞:
由于前面的数据丢失导致后面的数据没办法及时给到应用层的现象,乱序包放入乱序队列,乱序队列用的是接收缓冲区的内存,乱序的情况越多,接收缓冲区的内存就被占用的越多,对应的接收窗口就会变小,网络吞吐就变差

SYN Flood
Syn Cache: 不直接分配TCB,使用更少的数据记录状态
Syn Cookie: 无状态的三次握手
cookie源认证: 记录sequence number,将真实客户端IP加入白名单
reset认证: reset报文,将真实客户端IP加入白名单
DDOS

单播:Unicast,主机之间一对一的通讯模式,如TCP
广播:Broadcast,主机之间一对所有的通讯模式,网络对其中每一台主机发出的信号都进行无条件复制并转发,所有主机都可以接收到所有信息,禁止广播数据穿过路由器,防止广播数据影响大面积的主机,单个客户端接收的数据是有限的
多播(组播):Multicast,主机之间一对一组的通讯模式,加入了同一个组的主机可以接受到此组内的所有数据,网络中的交换机和路由器只向有需求者复制并转发其所需数据,主机可以向路由器请求加入或退出某个组,此协议和单播协议一样允许在Internet宽带网上传输,发生丢包错包后难以弥补
任播:Anycast,IPv6中定义的一种新型通信服务

路由:
路由选择算法 路由表
静态路由算法:Dijkstra算法(最短路径算法)/扩散法
动态路由算法:距离向量路由算法
RIP/BGP/OSPF
链路状态最短路由优先算法SPF
路由收敛原理
匹配IP长度->管理距离(优先选手动配的静态路由,次优选OSPF动态学习过来的表项)->路径成本(度量值metrics)->等价路径(等价多路径ECMP)
等价多路径路由ECMP:选择多条路径传输,提高链路带宽,同时利用五元组做哈希键进行路径选择,保证了同一条连接的数据包走同一条路径,减少了乱序的情况(乱序会降低TCP传输性能)
traceroute baidu.com 收到目的主机的IP后,首先给目的主机发送一个TTL=1的UDP数据包,而经过的第一个路由器收到这个数据包以后就自动把TTL减1,而TTL变为0以后路由器就把这个包给抛弃了,并同时产生一个主机不可达的ICMP数据报给主机,主机收到这个数据报以后再发一个TTL=2的UDP数据报给目的主机,然后刺激第二个路由器给主机发ICMP数据报,如此往复直到到达目的主机traceroute就拿到了所有的路由器IP
route
nc -p 6666 baidu.com 80

DNS:
Domain Name System,协议支持TCP和UDP,常用端口是53,每一级域名的长度限制是63,域名总长度限制是253
UDP查询中能保证性能的最大长度是512字节,要让所有根域名服务器数据能包含在512字节的UDP包中,根服务器只能限制在13个,而且每个服务器要使用字母表中单字母名
当一个域名对应多个IP时,当你查询这个域名的IP,会返回离你最近的IP
访问本地的DNS缓存,/etc/hosts,本地DNS服务器(递归解析服务器),根域名服务器,顶级域名服务器,权威域名服务器
/etc/nsswitch.conf 决定resolving顺序
/etc/resolv.conf配置本地DNS服务器
递归解析服务器: 递归DNS服务器,自动递归查询方便用户一次性得到结果,递归解析服务器通过请求一级一级的权威域名服务器,获得下一目标的地址,直到找到目标域名的权威域名服务器,一般由ISP提供,公共递归解析服务器如谷歌的8.8.8.8,联通的114.114.114.114
根域名. 全球有13个根域名解析服务器,A.ROOT-SERVERS.NET一直到M.ROOT-SERVERS.NET
顶级域名 通用顶级域名gTLD比如.com和.net,国别顶级域名ccTLD比如.cn和.us 顶级域名由国际域名管理机构ICANN控制
一级域名 权威域名服务器 .example.com 次级域名
二级域名
三级域名
A 地址记录(Ipv4)
AAAA 地址记录(Ipv6)
CNAME 别名记录
MX 邮件服务器记录
NS 名字服务器记录
PTR 反向记录
RT 路由穿透记录
SRV TCP服务器信息记录
TXT 域名对应的文本信息
nslookup www.baidu.com 114.114.114.114
dig www.baidu.com
dig -x 192.30.252.153
dig @1.1.1.1 es6.ruanyifeng.com
dig @192.33.4.12 es6.ruanyifeng.com
dig @192.41.162.30 es6.ruanyifeng.com
dig @172.64.32.123 es6.ruanyifeng.com

DHCP:
Dynamic Host Configuration Protocol 动态主机配置协议,使主机开机后自动获取IP地址/子网掩码/DNS
DHCP使用UDP协议实现通信,网络层协议号字段为0x11,DHCP Client端口号68,DHCP Server端口67
发现阶段:
发送DHCP Discover广播报文,源IP地址为0.0.0.0,目的IP地址为255.255.255.255,源MAC地址为自己的MAC地址,目的MAC地址为ff:ff:ff:ff:ff:ff,该报文会在二层网络中洪泛,如果网络中存在DHCP服务器,则DHCP服务器会收到该报文
提供阶段:
DHCP Server会根据管理员的相关配置给DHCP Client提供一个可用的IP地址,同时给其提供DNS/子网掩码,DHCP Server会发送DHCP Offer信息给DHCP Client提供上述信息,广播报文,源IP地址为DHCP Server的IP地址,目的IP地址为DHCP Server给该DHCP Client分配的IP地址,源MAC地址为DHCP Server的MAC地址,目的MAC地址为DHCP Client的MAC地址
请求阶段:
DHCP Client会向DHCP Server发送DHCP Request报文,正式向DHCP Server申请使用该IP地址,源IP地址为0.0.0.0,目的地址为255.255.255.255,源MAC和目的MAC地址分别是DHCP Client的和DHCP Server的MAC地址
确认阶段:
DHCP Server会向DHCP Client发送DHCP Reply报文,表示同意DHCP Client使用该IP地址,源IP地址为DHCP Server的IP地址,目的IP地址为DHCP Client的IP地址,源目MAC为DHCP Server和Client的MAC地址
重启机器:
PC机对于DHCP有记忆功能,重启PC后直接进入第三个阶段,直接向DHCP Server发送DHCP Request报文,如果DHCP同意,则会回应DHCP Reply报文,如果该IP地址已经被占用,则DCHP Server会回应DHCP NACK报文,这时PC就必须重新进行DHCP四个阶段
续约机制:
默认情况下当PC申请到一个DHCP地址后使用时间为一天,也可以手动修改该时间,最短为1小时,当PC申请的DHCP IP地址到达租约时间后,该IP地址就不可以继续使用,因此PC会在租约到期之前进行续约,DHCP Client会进行两次续约,一次是在租约期的50%时候,DHCP Cient会向DHCP Server发送DHCP Reqruest报文,如果收到DHCP Server的回应则续约成功,第二次续约是在租约期的87.5%的时候,DHCP会再次向DHCP Server发送DHCP Request报文,申请租约,如果此时仍为收到DHCP响应的DCHP NACK报文,则必须要重新进行DHCP的四个阶段
DHCP中继代理:
DHCP客户端向DHCP中继代理发送DHCP请求包,而DHCP中继代理在收到这个广播包以后,再以单播的形式发给DHCP服务器,服务器端收到该包以后再向DHCP中继代理返回应答,并由DHCP中继代理将此包广播给DHCP客户端

NAT:
unix:


7.HTTP1.1 TLS/SSL websocket HTTP2 QUIC
GET(获取资源)/POST(创建修改资源)/PUT(幂等)/HEAD(验证uri是否有效不返回body)/DELETE(删除资源)
CONNECT: HTTP1.1的方法,隧道代理使用CONNECT方法建立连接,开启一个客户端与所请求资源之间的双向沟通的通道,客户端要求代理服务器将TCP连接作为通往目的主机隧道,之后该服务器会代替客户端与目的主机建立连接,连接建立好之后代理服务器会面向客户端发送或接收TCP消息流
OPTIONS: 用来询问服务器对应路由支持哪些方法,也可以传递*获取整个服务器支持的方法;检测某个接口是否支持跨域,复杂跨域请求之前先发送一个OPTIONS请求,浏览器根据返回的Access-Control-Allow-Origin,Access-Control-Allow-Headers,Access-Control-*来判断当前网页能否请求跨域资源
TRACE: 原样返回任意客户端请求的任何内容,主要用于测试或诊断,追踪路劲

状态码:
1xx 信息响应
2xx 成功响应
3xx 重定向
4xx 客户端错误
5xx 服务器错误

100 Continue客户端应当继续发送请求
200 请求成功
204 No Content成功处理但在返回的响应报文中不含实体的主体部分
301 MovedPermanently 资源(网页等)被永久转移到其它URL
302 Found 临时移动,与301类似,但资源只是临时被移动,客户端应继续使用原有URI
304 Not Modified未修改,自从上次请求后请求的网页未修改过服务器返回此响应时不会返回网页内容
400 Bad Request
401 Unauthorized
403 Forbidden
404 请求的资源(网页等)不存在
500 InternalServerError
501 NotImplemented
502 BadGateway
503 ServiceUnavailable
504 GatewayTimeout
505 HTTPVersionNotSupported

请求体:
包含请求方法、URI、HTTP版本信息
header
body

响应体:
包含HTTP版本、状态码、状态码的原因短语
header
body

Request Headers:
Host: a.com
Trailer: key1标识在body的后面会有类似key1: value1的首部字段,Trailer可以使用在HTTP/1.1版本分块传输编码时
Connection: close通知对端自己发送完数据会断开链接(HTTP1.0默认方式)、keep-alive通知对端自己发送完数据不会断开链接(HTTP1.1默认方式)
Accept-Encoding: gzip, deflate, br 和Content-Encoding: gzip对应;如果client没有显式的设置Accept-Encoding则自动加上gzip,并且如果服务端返回的数据是压缩的client可以自动解压缩;如果client显式的设置Accept-Encoding并且服务端返回的数据是gzip的则client不会自动解压缩需要应用层自己解压缩;go http server默认不进行gzip
Accept-Language: zh-CN,zh;q=0.9
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*; 客户端希望接收的响应body数据类型
Accept-Control-Request-Headers: xx
Accept-Control-Request-Method: POST
Cookie: a=1; b=2
Authorization: xxx
Origin: https://a.com
Referer: https://a.com
User-Agent: Mozilla/5.0

Response Headers:
Date: Wed, 20 Jul 2022 13:00:45 GMT
Server: xxx
Content-Type: application/json;charset=utf-8  text/html  image/jpeg  application/javascript  application/xml
Content-Length: 200
Content-Encoding: gzip
Content-Language: zh-CN
Content-Md5: xxx
Transfer-Encoding: chunked 分块传输
Cache-Control: max-age=31536000 no-cache
Pragma: no-cache(禁用缓存) Pragma旧产物 优先级从高到低是Pragma->Cache-Control->Expires
Location: a.com/b  重定向
Set-Cookie: status=enable; expires=Tue, 05 Jul 2018 02:01:22 GMT; path=/; domain=.example.com;
Allow: HEAD,GET,POST
Access-Control-Allow-Origin: *
Access-Control-Allow-Methods: GET, POST, PUT
Access-Control-Allow-Credentials: true 表示是否允许发送Cookie
Access-Control-Allow-Headers: X-Custom-Header
Access-Control-Max-Age: 3600  设置在3600秒不需要再发送预校验请求
Access-Control-Expose-Headers: FooBar

Cookie: NAME=VALUE; expires=DATE; Max-Age=3600(存活多少秒,IE不支持); path=PATH; domain=域名(域名匹配才会带上cookie); Secure(仅在HTTPS时才会发送) HttpOnly(使Cookie不能被js脚本访问,其主要目的为防止跨站脚本攻击Cross-sitescripting/XSS对Cookie的信息窃取)

缓存控制:
Pragma: 有两个字段Pragma和Expires,Pragma的值为no-cache时表示禁用缓存,Expires表示该缓存的有效时间
Cache-Control: 请求,no-cache(不使用缓存要向原服务器发起请求)/no-store(内容不保存到缓存)/max-age(告知server,client可以接收一个存在时间不超过多少秒的资源);响应,no-cache(不使用缓存要向server发起请求)/no-store(内容不保存到缓存)/max-age(告知client资源在多少秒内是新鲜的无需向server发起请求),no-store优先级最高
缓存校验:
Last-Modified: 服务端在返回资源时会将该资源的最后更改时间通过Last-Modified字段返回给客户端,客户端下次请求时通过If-Modified-Since或者If-Unmodified-Since带上Last-Modified,服务端检查该时间是否与服务器的最后修改时间一致:如果一致则返回304状态码,不返回资源;如果不一致则返回200和修改后的资源并带上新的时间,If-Modified-Since(告诉服务器如果时间一致返回状态码304),If-Unmodified-Since(告诉服务器如果时间不一致返回状态码412)
etag: 服务器通过某个算法对资源进行计算取得一串值(类似于文件的md5值)之后将该值通过etag返回给客户端,客户端下次请求时通过If-None-Match或If-Match带上该值,服务器对该值进行对比校验,如果一致则不要返回资源,If-None-Match(告诉服务器如果一致,返回状态码304,不一致则返回资源),If-Match(告诉服务器如果不一致,返回状态码412)

跨域CORS: 跨域资源共享,同源(协议域名端口号都一样)策略,当前网页访问一个host和自己不一样的服务器,这时浏览器为了安全会根据一些条件判断是否能请求并且接收到响应,对于复杂请求先发送OPTIONS预检请求(preflight),通过OPTIONS的响应判断是否能进行跨域请求,一旦服务器通过了预检请求,以后每次浏览器正常的CORS请求,就都跟简单请求一样会有一个Origin头信息字段;对于简单请求(HEAD/GET/POST,头部不超过Accept、Accept-Language、Content-Language、Last-Event-ID、Content-Type:只限三个application/x-www-form-urlencoded、multipart/form-data、text/plain)则直接请求,浏览器在请求头部插入Origin,浏览器判断响应是否允许跨域决定是否将响应给到页面
JSONP只支持GET请求,CORS支持所有类型的HTTP请求,JSONP的优势在于支持老式浏览器,以及可以向不支持CORS的网站请求数据

CSRF/XSRF XSS
JWT Session Token

SSRF:由攻击者构造形成由服务端发起请求的一个安全漏洞,一般情况下,SSRF攻击的目标是从外网无法访问的内部系统,正是因为它是由服务端发起的所以它能够请求到与它相连而与外网隔离的内部系统;形成的原因大都是由于服务端提供了从其他服务器应用获取数据的功能且没有对目标地址做过滤与限制,比如从指定URL地址获取网页文本内容,加载指定地址的图片,下载

TLS:
OCSP: 在线证书状态协议验证SSL证书的有效性,以确保它未被吊销
NPN/ALPN protocol: 是TLS的扩展允许在安全连接的基础上进行应用层协议的协商,协商使用HTTP1.1还是HTTP2.0
https://www.thesslstore.com/blog/explaining-ssl-handshake
密码套件: TLS_RSA_WITH_AES_128_GCM_SHA256/TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA 密钥交换算法 + 签名算法 + 对称加密算法 + 摘要算法
非对称加密需要应用到复杂的数学运算,虽然保证了安全,但速度很慢
加密套件列表: openssl ciphers -v
数字证书的签发流程:
CA会把一些基本信息例如持有者、用途、有效信息等打包,然后运用Hash算法得到一个Hash值
CA会使用自己的私钥将这个Hash值加密,生成一个Certificate Signature证书签名,CA对证书进行了签名
最后将签名加到证书文件形成数字证书
客户端验证证书的流程:
客户端使用同样的Hash算法,得到该证书的Hash值H1
浏览器使用CA的公钥,解密Certificate Signature中的内容,得到Hash值H2
如果H1等于H2则证明可信
Session ID: 为第一次握手时候发送的Session ID字段的值,服务器端会维护对于该Session ID对应的通信密钥,当Client再次连接的时候,只需要在头部中加上Session ID,即可通知Server重新使用上次协商过的通信密钥进行通信,这样就不需要每一次都重新协商来浪费资源,同时由于不需要完整的握手过程,所以握手时间也减少了1 RTT
Session Ticket: Server会在握手结束后向Client发送被加密的恢复连接所需要的数据,同时Server无需保存任何信息,且由于此时握手已经完成,所以信道是安全的,在下次建立TLS连接时,Client只需要在第一次握手时发送上次收到的被加密的恢复连接所需的数据,Server则可以通过只有自己知道的密钥解密该握手数据,并重新使用上次的通信密钥
为什么会有pre_master: 兼容RSA和DH算法

TLS 1.0-TLS 1.2: 耗时2-RTT TLS 1.0 = SSL 3.1
RSA算法:
1.client->Client Hello->server
加密套件列表+client_random+压缩算法+Session ID+SSL/TLS版本
2.1.client<-Server Hello<-server
选择使用的加密套件+server_random+压缩方法+Session ID+SSL/TLS版本
2.2.client<-Certificate/Server Key Exchange/Server Hello Done<-server
服务端证书(包括公钥+签名+持有者信息+有效时间+证书认证机构CA的信息)
3.1.client->Client Key Exchange->server
客户端验证服务端证书,通过后客户端生成一个预主密钥然后从服务器发送的证书中提取公钥,利用证书的公钥对预主密钥进行RSA加密再发送给服务端,此时客户端开始根据client_random+server_random+预主密钥生成主密钥,此密钥用于给后续传输的数据进行加解密
3.2.client->ChangeCipherSpec/Finished->server
告诉服务端它后续将切换到使用协商好的加密密钥对数据进行加密再传输
4.client<-ChangeCipherSpec/Finished<-server
从消息中提取加密过的预主密钥然后拿证书的私钥解密获取预主密钥,服务端根据预主密钥+client_random+server_random生成主密钥,告诉客户端后续将切换到使用协商好的加密密钥对数据进行加密再传输

DH算法: Diffie-Hellman
客户端和服务器都各自产生一个随机数,生成一个私钥,然后根据公开的DH算法算出自己的公钥,再把这个公钥通过TLS互换,只要有了自己的私钥和对方的公钥,就可以解密报文,即使公钥被截取了,在不知道私钥的情况下也无法计算出密钥,但是DH算法存在计算效率的问题,所以出现了ECDHE密钥协商算法
客户端与服务端都需要各自生成一对公私钥,交换各自本次会话临时生成的密钥对的公钥
客户端私钥+服务端公钥,根据椭圆算法算出预主密钥
服务端私钥+客户端公钥,根据椭圆算法算出预主密钥
1.client->Client Hello->server
加密套件列表+client_random+压缩算法+Session ID+SSL/TLS版本
2.client<-Server Hello<-server
服务端返回使用的加密套件+server_random+压缩方法+Session ID+SSL/TLS版本,服务端证书(包括公钥+签名+持有者信息+有效时间+证书认证机构CA的信息),同时服务器利用私钥将client_random,server_random,server_params签名,然后将签名和server_params发送给客户端
3.client->server
客户端验证服务端证书和server_params签名,通过后将client_params传递给服务器,此时客户端通过client_params+server_params生成预主密钥(因ECDHE计算基于椭圆曲线离散对数通过这两个DH参数就能计算出pre_random),客户端根据预主密钥+client_random+server_random生成主密钥,
告诉服务端它后续将切换到使用协商好的加密密钥对数据进行加密再传输
4.client<-server
通过client_params+server_params生成预主密钥,预主密钥+client_random+server_random生成主密钥,告诉客户端后续将切换到使用协商好的加密密钥对数据进行加密再传输

TLS 1.3: 耗时1-RTT
前向安全性: 指的是过去的通信的安全性不会受到未来的密钥泄露事件的影响
DHE/ECDHE算法: ECC椭圆曲线离散对数,ECDHE用于密钥交换,ECDSA用于数字签名
双方事先确定好使用什么椭圆曲线,和曲线上的基点G,两个参数都是公开的
双方各自随机生成私钥d,将G乘以私钥d得到公钥Q(Q=Gd),客户端的公私钥为d1和Q1,服务器的公私钥为d2和Q2
双方交换公钥,客户端计算d1Q2,服务器计算d2Q1,由乘法交换律和结合律得d2Q1 = d2d1G = d1d2G = d1Q2,双方的坐标都是一样的,实现了共享密钥
1.client->server
加密套件列表+TLS版本+client_random+client_params
2.client<-server
确认的加密套件+TLS版本+证书+server_random+server_params
服务端/客户端通过client_params+server_params生成预主密钥,再通过预主密钥+client_random+server_random生成主密钥

PSK: Pre-share key 0-RTT

websocket:
GET http://a.com HTTP/1.1
Host: http://a.com
Upgrade: websocket
Connection: Upgrade
Sec-WebSocket-Key: xxx
Origin: http://a.com
Sec-WebSocket-Version: 13
Sec-WebSocket-Protocol: a,b

HTTP/1.1 101 Switching Protocols
Upgrade: websocket
Connection: Upgrade
Sec-WebSocket-Accept: xxx
Sec-WebSocket-Protocol: a

HTTP2.0:
https://httpwg.org/specs/rfc9113.html https://httpwg.org/specs/rfc7541.html
HTTP2.0和HTTP1.1区别:
多路复用/二进制分帧层/首部压缩/HTTP2支持服务器推送,HTTP2.0是在SPDY基础上形成的下一代HTTP,目的是通过支持请求与响应的多路复用来较少延迟,通过压缩HTTPS首部字段将协议开销降低,同时增加请求优先级和服务器端推送的支持,二进制分帧层将所有的传输信息分割为更小的消息和帧,进行二进制格式编码
frame:
帧首部(帧长度24+帧类型8+flags8)+流标识符31+优先值31+帧净荷
帧类型:
DATA(0x0):用于传输HTTP消息体
HEADERS(0x1):用于传输首部字段
PRIORITY(0x2):用于指定或重新指定引用资源的优先级
RST_STREAM(0x3):用于通知流的非正常终止,StreamID是一个正常流的StreamID,载荷是4字节的ErrCode,服务端handler遇到panic会给客户端发RST_STREAM
SETTINGS(0x4):用于约定客户端和服务端的配置数据比如设置初始的双向流量控制窗口大小/HPACK动态表大小/是否允许push/最大帧大小1MB/同一个链接最大流数250,StreamID是0,载荷是2ID+4value字节的倍数,收到消息的一方要返回ack
PUSH_PROMISE(0x5):服务端推送许可,客户端的一个请求除了正常响应外还有可能收到一个PUSH_PROMISE消息,使用关联请求的StreamID,载荷是PromiseID+头部数据,如果头部数据过大则继续发送Continuation帧,再发送Data帧数据,此时的Data帧把PromiseID当成StreamID
PING(0x6):用于测量来自发送方的最小往返时间以及确定空闲连接是否仍然有效,StreamID是0,有效载荷8字节,Ping请求->Ping响应携带Ack flag
GOAWAY(0x7):用于通知对端停止在当前连接中创建流,启动连接关闭或发出严重错误状态信号,StreamID是0,载荷:LastStreamID+ErrCode+debugData,客户端收到后比LastStreamID大的流都会被abort,然后从链接池删除链接;服务端收到goaway会返回一个goaway给客户端并携带LastStreamID,服务端所有流都执行完后服务端优雅退出关闭链接
WINDOW_UPDATE(0x8):用于调整个别流或个别连接的流量,streamID如果是0则应用于整个链接,否则应用于某个流,载荷是4字节表示增量
客户端链接cc.flow 初始2^16/WindowUpdate更新
客户端流cs.flow 初始2^16或SETTINGS设置/WindowUpdate更新 writeRequestBody减少
客户端链接cc.inflow 初始2^16+2^30/readResponseBody时小于2^29就增加到2^30,并发送WindowUpdate更新服务端的sc.flow
客户端流cs.inflow 初始4MB/readResponseBody时小于4MB-4KB就增加大4MB,并发送WindowUpdate更新服务端的st.flow 接收Data数据减少
服务端链接sc.flow 初始2^16/WindowUpdate更新
服务端流st.flow 初始2^16或SETTINGS设置/WindowUpdate更新 scheduleFrameWrite减少
服务端链接sc.inflow 初始2^16/noteBodyRead时更新并发送WindowUpdate给客户端cc.flow
服务端流st.inflow 初始2^20/noteBodyRead时更新并发送WindowUpdate给客户端cs.flow 接收Data数据减少
CONTINUATION(0x9):header过大时拆分成多个帧,第一个帧是HEADERS类型,从第二个帧是Continuation类型
flags:
用于不同的帧类型定义特定的消息标志,比如DATA帧就可以使用End Stream:true表示该条消息通信完毕,Data:EndStream(0x1)/Padded(0x8);Headers:EndStream(0x1)/EndHeaders(0x4)/Padded(0x8)/Priority(0x20);Settings:Ack(0x1);Ping:Ack(0x1)
流标识位:
表示帧所属的流ID
优先值:
用于HEADERS帧表示请求优先级,流可以带有一个31bit的优先级,0表示最高优先级
消息:
一系列DATA帧和HEADERS帧组成了请求消息
stream:
是连接中的一个虚拟信道,可以承载双向消息传输,每个流有唯一整数标识符,为了防止两端流ID冲突,客户端发起的流具有奇数ID,服务器端发起的流具有偶数ID,所有HTTP2.0通信都在一个TCP连接上完成, 这个连接可以承载任意数量的双向数据流Stream,每个数据流以消息的形式发送而消息由一或多个帧组成,这些帧可以乱序发送,然后根据每个帧首部的流标识符重新组装;流状态:Idle/Open/HalfClosedLocal/HalfClosedRemote/Closed
多路复用:
HTTP2.0成功解决了HTTP1.x的队首阻塞问题(TCP层的阻塞仍无法解决)
服务端推送:
服务端可以根据客户端的请求,提前返回多个响应,推送额外的资源给客户端,PUSH_PROMISE帧是服务端向客户端有意推送资源的信号,如果客户端不需要服务端Push,可在SETTINGS帧中设定服务端流的值为0禁用此功能;PUSH_PROMISE帧中只包含预推送资源的首部,如果客户端对PUSH_PROMISE帧没有意见,服务端在PUSH_PROMISE帧后发送响应的DATA帧开始推送资源,如果客户端已经缓存该资源,不需要再推送,可以选择拒绝PUSH_PROMISE帧;PUSH_PROMISE必须遵循请求-响应原则,只能借着对请求的响应推送资源
首部压缩:
首部压缩技术,压缩算法HPACK,在客户端和服务端之间使用首部表来跟踪和存储之前发送的kv,首部表在连接过程中始终存在,新增的kv会更新到表尾,不需要每次通信都需要再携带首部,静态表(从1开始计数,一共61个)/动态表(从62开始计数),SETTINGS可以设置动态表size,kv采用哈夫曼编码,编码:操作码/在表中的索引(这个索引可能是hearder中key值的索引也可能是整个键值对的索引)/是否使用哈夫曼编码/key的长度/key的编码/value的长度/value的编码
HPACK编码:
只有index:1xxx xxxx(x代表index的值),如果index>=127,1111 1111 0/1xxx xxxx(0代表后面没值了,1代表后面还有值)每个字节存7位
index+value:01xx xxxx(x代表index的值),如果index>=63,0111 1111 同上
key+value:0100 0000 0xxx xxxx(x代表字符串长度),后面直接跟字符串
sensitive:0001
不修改index:0000
更新动态表size:0010
SPDY:
DEFLATE压缩头部字段,有CRIME漏洞(Compression Ratio Info-leak Made Easy)
基于ALPN的协商过程:
支持HTTP2.0的浏览器可以在TLS会话层自发完成和服务端的协议协商以确定是否使用HTTP2.0通信,TLS1.2中引入了扩展字段以允许协议的扩展,ALPN协议(Application Layer Protocol Negotiation,应用层协议协商,前身是NPN)
基于HTTP的协商过程: HTTP Upgrade机制
HTTP Upgrade request
GET / HTTP/1.1
host: xxx
connection: Upgrade, HTTP2-Setting
upgrade: h2c
http2-settings: xxx

HTTP Upgrade request
HTTP/1.1 101 Switching Protocols
Connection: Upgrade
Upgrade: h2c

QUIC:


8.Docker Kubernetes
kube-apiserver: 对外提供restful接口,唯一连接etcd服务,将对etcd的操作封装成接口供其它服务调用;有认证/鉴权/准入/限流的作用,

kube-scheduler: 调度器
Watch机制来发现集群中新创建且尚未被调度到Node上的Pod,scheduler会将发现的每一个未调度的Pod调度到一个合适的Node上来运行
scheduler维护待调度的podQueue并监听apiserver
创建Pod时通过apiserver将Pod元数据写入etcd
scheduler通过Informer监听Pod状态
添加新的Pod时会将Pod添加到podQueue
主程序不断从podQueue中提取Pods并按照一定的算法将节点分配给Pods
节点上的kubelet也侦听apiserver,如果发现有新的Pod已调度到该节点,则将通过CRI调用高级容器运行时来运行容器
如果scheduler无法调度Pod,则如果启用了优先级和抢占功能则首先进行抢占尝试,删除节点上具有低优先级的Pod,然后将要调度的Pod调度到该节点,如果未启用抢占或抢占尝试失败,则相关信息将记录在日志中,并且Pod将添加到podQueue的末尾
预选,输入是所有节点,输出是满足预选条件的节点,如检查候选Node的可用资源能否满足Pod的资源要求,Node的label必须与Pod的Selector一致
优选,输入是预选阶段筛选出的节点,优选会根据优先策略为通过预选的Nodes进行打分排名,选择得分最高的Node,例如资源越富裕负载越小的Node可能具有越高的排名,如果存在多个得分最高的Node,scheduler会从中随机选取一个

kube-controller-manager: 控制器
它通过apiserver监控整个集群的状态并确保集群处于预期的工作状态
Replication Controller/Node Controller/CronJob Controller/Daemon Controller/Deployment Controller/Endpoint Controller/Garbage Collector/Namespace Controller/Job Controller/Pod AutoScaler/ReplicaSet Controller/Service Controller/ServiceAccount Controller/StatefulSet Controller/Volume Controller/Resource quota Controller

kubelet:
Pod被调度到对应的宿主机,创建这个Pod,管理这个Pod的生命周期
通过Watch机制监听了与自己相关的Pod对象的变化
调用下层容器运行时,不会直接调用Docker的API,通过CRI(容器运行时接口)的gRPC接口来间接执行
CAdvisor集成在Kubelet中的容器监控工具用于收集本节点和容器的监控信息
GCManager清理未使用的镜像和容器
CPUManager
ProberManager实现对容器的健康检查
StatusManager将pod状态信息同步到apiserver

kube-proxy:
service组件的虚拟IP服务
User space模式/iptables模式/IPVS模式

coredns
flannel

Node
Pod/PodTemplate
Deployment
Service/Endpoints: ExternalName/ClusterIP(None)/NodePort/LoadBalancer
Ingress/IngressClass/NetworkPolicy
DaemonSet
StatefulSet
ReplicaSet/ReplicationController
Job CronJob
Label Namespace ConfigMap Secret
Volume PersistentVolume PersistentVolumeClaim StorageClass CSI
RBAC/ClusterRoleBinding/ClusterRole/RoleBinding/Role/ServiceAccount/Binding
Operator
CustomResourceDefinition
affinity
ResourceQuota/PriorityClass
HorizontalPodAutoscaler
LimitRange
CSIDriver/CSINode/CSIStorageCapacity/VolumeAttachment
LocalSubjectAccessReview/SelfSubjectAccessReview/SelfSubjectRulesReview/SubjectAccessReview
TokenReview
ControllerRevision
APIService
EndpointSlice
MutatingWebhookConfiguration/ValidatingWebhookConfiguration
ComponentStatus
Lease
CertificateSigningRequest
Event
kubectl rollout/scale/autoscale
kubectl top
kubectl cordon/uncordon/drain/taint
kubectl port-forward/proxy/expose
kubectl cp
kubectl edit
kubectl kustomize
kubectl plugin
安全: Kata Containers
监控: gVisor
日志: kubectl logs
CNI

Docker:
Dockerfile:
cgroup: cgroupfs/systemd/cgroup v2
control group控制组,控制进程组对某种资源的使用,这些资源包括但不限于内存/CPU/I/O和网络
cgroup提供了将进程组织成控制组的能力,然后通过使用资源控制子系统cgroup_subsys来对控制组进行资源使用的控制,cgroup支持的资源控制子系统有以下几种
cpu子系统(限制CPU的使用),memory子系统(限制内存使用),cpuset子系统(可以为进程组分配单独的CPU或者内存节点),cpuacct子系统(统计CPU group的使用情况),blkio子系统(限制I/O,一般用于磁盘),devices子系统(限制进程使用的设备),freezer子系统(可以挂起和恢复进程组),net_cls子系统(可以标记进程组的网络数据包,使用tc模块traffic control对数据包进行控制)
控制组: 进程组,内核使用了虚拟文件系统来进行管理控制组
Namespace:
mount命名空间
UTS命名空间
IPC namespaces
PID namespaces
Network namespaces
User namespaces
images/containers/rootfs/networks/volumes

docker engine: dockerd
containerd: 容器运行时,管理完整的容器生命周期,容器镜像的传输和存储/容器的执行和管理/存储/网络,调用runC运行容器
docker-shim
runc
CRI: Container Runtime Interface,容器运行时
CRI-O
pause
volume

Mesos marathon dcos

服务网格
Istio/Serverless


9.分布式 微服务
CAP
高并发
高可用
事务

唯一ID:
Snowflake,64位,第1位默认为0,接下来前41位是毫秒数时间戳,接下来的10位代表计算机ID,其余12位代表每台机器上生成ID的序列号
Uidgenerator
Leaf

限流:
固定窗口计数法:
一定时间T内只允许N个请求,如果在这个时间的开始阶段N就用完了,那么后面的时间请求只能被抛弃;假设限流阀值为5个请求单位时间窗口是1s,如果在单位时间内的前0.8-1s和1-1.2s分别并发5个请求,虽然都没有超过阀值,但是如果算0.8-1.2s,则并发数高达10,已经超过单位时间1s不超过5阀值的定义
滑动窗口算法:
任意时间窗口内都不会超过阈值,除了需要引入计数器之外还需要记录时间窗口内每个请求到达的时间点,假设时间窗口为1s,记录每次请求的时间,统计每次请求的时间至往前推1s这个时间窗口内请求数,并且1秒前的数据可以删除,统计的请求数小于阈值就记录这个请求的时间并允许通过反之拒绝,滑动窗口当流量到达阈值时会瞬间掐断流量,所以导致流量不够平滑
漏桶算法:
水(请求)先进入到漏桶里,漏桶以一定的速度出水,当水流入速度过大会直接溢出,漏桶算法能强行限制数据的传输速率
令牌桶算法:
按照一定速率往桶里添加令牌,当桶满时新添加的令牌就被丢弃,拿到令牌才执行请求,允许突发的请求

熔断
降级
灾备
异地多活
Sentinel
秒杀
2PC/3PC/TCC
Raft/Paxos
CDN
SLB

微服务:
服务注册发现
链路追踪


10.操作系统
Reactor线程模型
汇编

linux:
sysconf/fpathconf/pathconf/confstr
gettimeofday/settimeofday
date/time/ctime/ftime
adjtime/adjtimex/clock_adjtime/ntp_adjtime
clock_gettime/clock_settime/clock_getres:根据clockid获取时间/设置时间/获取精确度
clock_getcpuclockid/pthread_getcpuclockid
getrlimit/setrlimit/prlimit

进程:
栈、堆
fork/vfork/clone
进程地址空间
进程池
execl/execlp/execle/execv/execvp/execvpe/execve
wait/waitpid/waitid/wait3/wait4
exit/_exit/_Exit/exit_group/on_exit/atexit
gdb/strace/ptrace
prctl/seccomp
getrusage
system
getpid/getppid
getcontext/setcontext/makecontext/swapcontext

进程调度:

线程:
轻量级进程,PCB/TCB,task_struct/thread_info/内核栈,slab分配器,线程有自己独立的内核栈
创建进程和线程底层都是调用clone系统调用,fork创建进程时clone不传参数则创建一个完整的进程,pthread_create创建线程时clone会传一些参数,共享地址空间
线程池
线程私有变量,pthread_key_create/pthread_setspecific/pthread_getspecific/pthread_key_delete
gettid
pthread_self

内存管理:
malloc/realloc/calloc/free/mmap
内存碎片
内存池
虚拟内存
页缓存和块缓存,页面回收和页交换,缺页中断
物理内存管理
MMU
slab分配器
多级cache L1 L2 L3

进程间通信IPC:
管道 命名管道FIFO 共享内存 消息队列 信号 UNIX域 socket DBUS
eventfd:把内存当文件,实际内部是一个8字节的计数器,read之后计数会清零,write则会递增计数器,如果计数器是0则不会通知可读

同步机制:
信号量 互斥量 条件变量 读写锁 自旋锁

futex: Fast userspace mutexes, 是一种用户态和内核态混合的同步机制,同步的进程间通过mmap共享一段内存,futex变量就位于这段共享的内存中且操作是原子的,当进程尝试进入互斥区或者退出互斥区的时候,先去查看共享内存中的futex变量,如果没有竞争发生则只修改futex而不用再执行系统调用了,当通过访问futex变量告诉进程有竞争发生,则还是得执行系统调用去完成相应的处理

文件系统:
vfs
ext3/ext4
fuse
statfs/fstatfs/stat/fstat/lstat/fstatat/statvfs/fstatvfs
readlink/readlinkat/symlink/symlinkat
access
chmod/fchmod/fchmodat/chown/fchown/lchown/fchownat
utime/utimes
realpath/getcwd/getwd/get_current_dir_name
chroot/chdir
open/read/write

IO多路复用:
poll select epoll
libuv/libevent

网络协议栈:
netfilter

设备驱动:
字符设备
块设备
网卡设备

系统调用

信号:
SIGINT:ctrl+c,默认反应是进程终止,可以捕捉
SIGQUIT:ctrl+\
SIGTERM:kill 1234,可以捕捉
SIGKILL:kill -9 1234,终止程序,不可捕捉
SIGSTOP:暂停进程,非终端来的停止信号,不可捕获
SIGTSTP:暂停进程,Ctrl+Z,终端来的停止信号
SIGCONT:继续运行
SIGHUP:终端退出时给子进程发的信号,默认终止进程,可捕捉

软中断 kill -l
对于需要处理的信号,进程可以指定处理函数,由该函数来处理;也可以忽略某个信号;也可以对该信号的处理保留系统的默认值,大部分的信号缺省操作是使得进程终止
通过系统调用signal来指定进程对某个信号的处理行为
SIGSTOP只是要求进程暂时停下手头的工作,休息一下,直到听到SIGCONT的召唤
SIGKILL/SIGSTOP不能捕捉和忽略
SIGCHLD默认忽略
两个信号同时到达,同一种信号只能等前面的先执行完再执行后到的且相同的信号只保留一个,不同信号可以同时执行
fork子进程可以继承父进程的信号,execve时会把信号恢复到默认行为,已忽略的信号则可以完全地继承

当内核接收到信号后,会将其放到对应进程的信号队列中,同时向进程发送一个中断,使其陷入内核态
进程从内核态返回到用户态前进行信号检测,或者进程在内核态中,从睡眠状态被唤醒的时候进行信号检测
内核将当前内核栈的内容拷贝到用户栈上,并且修改指令寄存器eip将其指向信号处理函数
接下来进程返回到用户态中,执行相应的信号处理函数
信号处理函数执行完成后,还需要返回内核态,检查是否还有其它信号未处理
如果所有信号都处理完成,就会将内核栈恢复,从用户栈拷贝回来,同时恢复指令寄存器eip将其指向中断前的运行位置,最后回到用户态继续执行进程

设置信号处理函数,signal/sigaction,发送信号kill,向自己发信号raise,向线程发送信号,tkill,tgkill
signal:第一个参数是信号值1-64,第二个参数可以设置三种行为SIG_IGN/SIG_DFL/handler
signalfd:文件描述符接收信号,不接收SIGKILL/SIGSTOP
alarm/ualarm:定时多少秒后发送信号SIGALRM,默认终止进程,返回值是上一个alarm剩余的秒数,后一个alarm覆盖前一个alarm,alarm(0)会清除之前所有的alarm
sleep/usleep/nanosleep/clock_nanosleep:调用线程进入睡眠直到指定秒之后,如果有未忽略的信号到来则提前退出并返回剩余睡眠的秒数,如果是忽略的信号到来则不影响sleep,如果是信号的默认行为则取决于默认行为是什么
pause:调用进程/线程进入睡眠直到捕捉到信号并且信号处理函数返回
abort:即使捕捉信号进程也会终止
pthread_kill:类似kill,给线程发信号
sigaction:signal的升级版
sigprocmask/pthread_sigmask:阻塞信号;如果当前是阻塞状态,并且同一个信号发送了多次,当阻塞解除时只响应一个信号;函数本身不阻塞
sigpending:查询当前哪些信号处于pending状态
sigemptyset/sigfillset/sigaddset/sigdelset/sigismember:对sigset_t进行操作
sigsuspend:阻塞指定信号,即使接收到该信号也不返回,接收到其它信号才会返回,当sigsuspend返回后自动恢复mask成原来的值,指定信号在阻塞解除后会响应一次,保护不希望由信号中断的代码临界区
sigqueue/pthread_sigqueue:发送信号给指定pid,可以携带数据,sigqueue函数对不可靠信号不做排队,会丢失信号,kill只是单纯的递送对谁都不排队
sigwait/sigwaitinfo/sigtimedwait:阻塞指定信号,直到发现该信号是pending则返回,收到其它信号不返回
setitimer/getitimer:设置定时器,可重复执行定时任务,三种类型ITIMER_REAL/ITIMER_VIRTUAL统计进程的用户时间/ITIMER_PROF统计进程的用户时间和内核时间,对应信号SIGALRM/SIGVTALRM/SIGPROF
timer_create/timer_settime/timer_gettime/timer_getoverrun/timer_delete:创建定时器,通过信号来通知定时器到来
timerfd_create/timerfd_settime/timerfd_gettime:定时器,不会被信号影响
sigsetjmp/siglongjmp/longjmp/setjmp:调用setjmp的函数返回了上下文将变成无效,longjmp第二个参数成为setjmp的返回值
sigaltstack:设置额外的信号栈,用于执行信号处理函数
siginterrupt:系统调用被信号中断,可以重新开始(默认)/返回EINTR/如果有数据传输就返回传输成功的字节数
sigreturn:从信号处理函数返回,并清除栈帧

中断

常用命令:
cd mkdir rm grep find ln
netstat tcpdump lsof ifconfig
iostat fdisk du df iotop
free vmstat sar
top htop strace perf 


11.算法
数组

链表:
单项链表 双向链表 双向循环链表

栈:
后进先出 LIFO,Last In First Out

队列:
先进先出 FIFO,First In First Out

堆:
最大堆: 父结点的键值总是大于或等于任何一个子节点的键值
最小堆: 父结点的键值总是小于或等于任何一个子节点的键值
斐波那契堆
二项式堆
优先队列

二分查找

排序:
冒泡排序: 两层循环,外循环每轮找出未排序序列中的最大值放在已排序序列的最前面,优化(在一轮循环里判断是否有数据交换,没有的话说明已经是有序的了),稳定,O(n2),O(1)
选择排序: 在未排序序列中找到最小元素存放到已排序序列的末尾,只找最小值不进行数据交换,不稳定,O(n2),O(1)
插入排序: 取出未排序序列的第一个元素,使用这个元素去已排序序列的尾部开始对比,直到找到比这个元素小的位置,稳定,O(n2),O(1)
希尔排序: 一种插入排序,先将整个待排序的序列分割成若干子序列分别进行直接插入排序,待整个序列中的记录基本有序时再对全体记录进行依次直接插入排序,稳定,最佳O(nlogn)最差O(n2),O(1)
归并排序: 分治法,将两个有序的数组合并成一个数组,稳定,O(nlogn),O(n)
快速排序: 选择一个元素作为基准,左边序列的元素均比基准小,右边序列的元素均比基准大,分别对这两个子序列继续进行排序以达到整个序列有序,不稳定,最佳O(nlogn)最差O(n2),O(nlogn),空间复杂度O(nlogn)
堆排序: 子结点的值总是小于它的父节点,构建大顶堆(从倒数第二层开始构建,循环直到堆顶),将堆顶元素与数组最后一个值交换,重新调整大顶堆,重复此步骤,节点i的左节点2i+1,右节点2i+2,不稳定,O(nlogn),O(1)
计数排序: 计数排序要求输入的数据必须是有确定范围的整数,它只能对整数进行排序,不适合最大值和最小值相差太大的情况,新建一个长度为max-min+1的数组,遍历原数组,将原数组的值-min当成新数组的索引,新数组的值是原数组值的重复个数,稳定,O(n+k),O(k)
桶排序: 假设输入数据服从均匀分布,将数据分到有限数量的桶里,每个桶再分别排序,稳定,O(n+k),O(k)
基数排序: 先按照个位数排序,再按照十位数排序,以此类推,稳定,O(n×k),O(n+k)

二叉树:
前序遍历(中左右)/中序遍历(左中右)/后续遍历(左右中)
二叉查找树:
BST/二叉搜索树/二叉排序树;若它的左子树不空则左子树上所有结点的值均小于它的根结点的值;若它的右子树不空则右子树上所有结点的值均大于它的根结点的值;它的左右子树也分别为二叉排序树;中序遍历的结果是有序的
平衡二叉查找树:
AVL树:
每个结点的左右子树的高度之差的绝对值(平衡因子)最多为1
红黑树

加权平衡树
伸展树
AA树
R树
四叉树/八叉树
笛卡尔树
B树/B+树/B*树/2-3树
Trie树/前缀树/后缀树/基数树(radix tree)
跳跃表
区间树
线段树

动态规划:
回溯 贪心 分治 摊还分析

图:
顶点/边/度
无向图/有向图
深度遍历/广度遍历

字符串:
KMP算法 BM模式匹配算法

加密算法 openssl
hash函数
NP完全
最短路径

哈希表:
开放寻址法: 写入新的数据时如果发生了冲突就会将键值对写入到下一个索引为空的位置
拉链法: 数组加上链表,引入红黑树以优化性能
合并散列: 开放寻址和单独链接的混合,新key存放的位置和开放寻址一样,每个bucket增加一个nextidx成员用于指向下一个冲突元素的位置,从第一个冲突的bucket开始遍历寻找nextidx没有被赋值的bucket,把新key存放的位置赋值给这个bucket的nextidx
杜鹃散列: 布谷鸟哈希(Cuckoo hashing),通过两个散列函数和两组哈希表解决索引冲突问题,插入元素x到T1数组的hash1(x)位置,如果该位置为空则直接插入x,如果该位置被y占据,则将x插入到该位置后再把y插入到T2的hash2(y)位置,如果该位置为空则直接插入y,如果该位置被z占据,则将y插入到该位置后再把z插入到T1的hash1(z)位置,以此类推直到插入完成;对读性能要求高对写性能相对低
跳房子散列: Hopscotch hashing,基于开放寻址,结合了杜鹃散列/线性探测和链接的元素,桶邻域,任何给定占用桶周围的后续桶也称为虚拟桶,在哈希表的负载因子增长超过90%时提供更好的性能,适合实现可调整大小的并发哈希表;使用一个包含n个桶的数组,对于每个桶它的邻域是H个连续桶的小集合,邻域的期望属性是在邻域的桶中找到一个元素的成本接近于在桶本身中找到它的成本,在最坏的情况下邻域的大小必须足以容纳对数个项目,但平均只能是一个常数,如果某个桶的邻域被填满则调整表的大小
罗宾汉哈希: 基于开放寻址,冲突是通过偏向从其原始位置(即项目被散列到的存储桶),最远或最长探测序列长度(PSL)的元素的位移来解决的

并查集
缓存LRU/LFU


12.其它
utf-8:
Unicode只是一个符号集,它只规定了符号的二进制代码,却没有规定这个二进制代码应该如何存储,“严”的unicode是十六进制数U+4E25
utf-8是变长的编码方式,使用1~4个字节表示一个符号,utf-8编码方式:
0xxxxxxx
110xxxxx 10xxxxxx
1110xxxx 10xxxxxx 10xxxxxx
11110xxx 10xxxxxx 10xxxxxx 10xxxxxx

protobuf:
syntax = "proto3";
package helloworld;
required/optional
default

repeated: marshalList,packed=true:tag+size+value1+value2;packed=false:tag+value1+tag+value2;[]string类型使用unpacked
map: marshalMap,tag+size1+key1+value1+tag+size2+key2+value2
bool: 转成1/0,AppendVarint
enum: AppendVarint
int32/uint32/int64/uint64: AppendVarint
sint32/sint64: EncodeZigZag,AppendVarint
sfixed32/fixed32/float: AppendFixed32
sfixed64/fixed64/double: AppendFixed64
string/bytes: AppendString/AppendBytes,tag+length+value
message
group

message HelloRequest {
  string name = 1;
}
service Greeter {
  rpc SayHello (HelloRequest) returns (HelloReply) {}
}
Varint编码:
tag:1bit标志位(0表示已读取完不需要读取下个字节,1表示还需要读取下个字节)+4bit标识号(字段后面的数字)+3位wire_type(VarintType:0;Fixed32Type:5;Fixed64Type:1;BytesType:2;StartGroupType:3;EndGroupType:4)
zigzag编码:
Input:  {…, -3, -2, -1,  0, +1, +2, +3, …}
Output: {…,  5,  3,  1,  0,  2,  4,  6, …}
负数:|x|*2-1;正数:x*2
当整数是0/bool是false则不传输
在proto2版本中packed功能默认没有启用;在proto3版本中packed功能默认是启用的用户不需要做设置(用户如果想禁止使用的话可以使用packed=false)

设计模式:
设计模式的六大原则:
开闭原则: 软件实体(类、模块、函数等)应该对扩展开放但对修改关闭,这样的实体可以允许在不修改源代码的情况下对其行为进行扩展
里氏代换原则: 子类型必须能够替换掉它们的父类型
依赖倒转原则: 高层模块不应该依赖低层模块,二者都应该依赖其抽象,相对于细节的多变性抽象的东西要稳定的多,以抽象为基础搭建的架构比以细节为基础的架构要稳定的多
接口隔离原则: 客户端不应该依赖它不需要的接口,一个类对另一个类的依赖应该建立在最小的接口上
迪米特法则(最少知道原则): 一个类对于其它类知道的越少越好,降低类之间的耦合,缺点:会造成系统中存在大量的中介类(为了传递类之间的相互调用关系)
合成复用原则: 在软件复用时,要尽量先使用组合或者聚合等关联关系来实现,其次才考虑使用继承关系来实现,如果要使用继承关系,则必须严格遵循里氏代换原则,合成复用原则同里氏代换原则相辅相成的,两者都是开闭原则的具体实现规范

创建型模式:
工厂模式(Factory Pattern): 简单工厂,提供一个方法返回指定的对象,如NewXXX("product1"),函数的返回类型是抽象产品,根据传入的产品名返回具体产品(具体的结构体),缺点是当需要增加一个产品时要在NewXXX中增加一个case,产品数量过多显得臃肿
工厂方法: 多态性工厂模式,定义一个创建对象的接口,但由实现这个接口的工厂类来决定实例化哪个产品类,工厂方法把类的实例化推迟到子类中进行,当增加一个产品时只需增加一个相应的工厂类的子类
抽象工厂模式(Abstract Factory Pattern): 围绕一个超级工厂创建其他工厂,每个工厂有相同的产品族
单例模式(Singleton Pattern): 饿汉:在该类初始化的时候就创建实例对象,懒汉:首次使用单例实例的时候创建
建造者模式(Builder Pattern): 使用多个简单的对象一步一步构建成一个复杂的对象,一个Builder类会一步一步构造最终的对象,该Builder类是独立于其它对象的
原型模式(Prototype Pattern):用于创建重复的对象同时又能保证性能,这种模式是实现了一个原型接口,该接口用于创建当前对象的克隆,当直接创建对象的代价比较大时,则采用这种模式

结构型模式:
适配器模式(Adapter Pattern): 作为两个不兼容的接口之间的桥梁,这种模式涉及到一个单一的类,该类负责加入独立的或不兼容的接口功能
桥接模式(Bridge Pattern): 把抽象化与实现化解耦,过提供抽象化和实现化之间的桥接结构,来实现二者的解耦
过滤器模式(Filter、Criteria Pattern): 允许开发人员使用不同的标准来过滤一组对象,过逻辑运算以解耦的方式把它们连接起来
组合模式(Composite Pattern): 用于把一组相似的对象当作一个单一的对象,依据树形结构来组合对象,用来表示部分以及整体层次,创建了一个包含自己对象组的类
装饰器模式(Decorator Pattern): 允许向一个现有的对象添加新的功能同时又不改变其结构,这种模式创建了一个装饰类,用来包装原有的类,并在保持类方法签名完整性的前提下,提供了额外的功能
外观模式(Facade Pattern): 隐藏系统的复杂性并向客户端提供了一个客户端可以访问系统的接口,这种模式涉及到一个单一的类,该类提供了客户端请求的简化方法和对现有系统类方法的委托调用,为子系统中的一组接口提供一个一致的界面,外观模式定义了一个高层接口,这个接口使得这一子系统更加容易使用
享元模式(Flyweight Pattern): 主要用于减少创建对象的数量,尝试重用现有的同类对象,如果未找到匹配的对象则创建新对象
代理模式(Proxy Pattern): 一个类代表另一个类的功能,在直接访问对象时带来的问题(对象创建开销很大),

行为型模式:
责任链模式(Chain of Responsibility Pattern): 为请求创建了一个接收者对象的链,常每个接收者都包含对另一个接收者的引用
命令模式(Command Pattern): 请求以命令的形式包裹在对象中,并传给调用对象,调用对象寻找可以处理该命令的合适的对象,并把该命令传给相应的对象,该对象执行命令,将对象中的多个方法封装成多个命令
解释器模式(Interpreter Pattern): 提供了评估语言的语法或表达式的方式,这种模式实现了一个表达式接口,该接口解释一个特定的上下文
迭代器模式(Iterator Pattern): 用于顺序访问集合对象的元素,hasNext/next
中介者模式(Mediator Pattern): 用来降低多个对象和类之间的通信复杂性,这种模式提供了一个中介类,该类通常处理不同类之间的通信,A1和A2交互,通过中介类B,A1/A2类中要调用B的方法
备忘录模式(Memento Pattern): 保存一个对象的某个状态,以便在适当的时候恢复对象
观察者模式(Observer Pattern): 当一个对象被修改时,则会自动通知依赖它的对象
状态模式(State Pattern): 类的行为是基于它的状态改变的,创建表示各种状态的对象和一个行为随着状态对象改变而改变的对象
空对象模式(Null Object Pattern): 一个空对象取代NULL对象实例的检查,Null对象不是检查空值而是反应一个不做任何动作的关系
策略模式(Strategy Pattern): 符合开闭原则,类的行为或其算法可以在运行时更改,主要解决在有多种算法相似的情况下使用if else所带来的复杂和难以维护
模板模式(Template Pattern): 抽象类定义了执行它的方法的方式(模板),它的子类可以按需要重写方法实现,但调用将以抽象类中定义的方式进行,主要解决一些方法通用却在每一个子类都重新写了这一方法
访问者模式(Visitor Pattern): 将数据结构与数据操作分离,稳定的数据结构和易变的操作耦合问题;被访问类A1/A2实现Accept接口(在Accept方法内调用访问者的Visit方法),类B包含被访问类数组(数组存储A1/A2),B也实现Accept接口(在方法内遍历数组,调用每个对象的Accept方法),访问者类C实现Visit接口(在Visit方法内去操作A1/A2),将C对象传给B对象的Accept方法

操作系统 计算机系统 数据库原理 编译原理 汇编 数据结构与算法 网络 分布式 音视频
前端 PC/手机/平板/嵌入式 小程序 React/Vue/Angular/JQuery/AJAX/Bootstrap/ionic HTML5/CSS3/JS/TypeScript/node.js Gulp
桌面 PC/嵌入式 windows:MFC/Mac/Linux GTK/GTK+/Xen/wxWidgets/QT electron/nw.js GNOME/KDE X Window/X11/Wayland
移动端 手机/平板 Android/iOS flutter ReactNative Dart
服务端
操作系统 linux RTOS/uCos/FreeRTOS
编程语言/编译原理
Golang go-zero kratos gRPC Thrift Gin Beego iris echo fiber chi macaron revel martini go-kit go-micro goa go-chassis dubbo-go
Java Spring/Spring boot/Spring cloud J2SE/J2EE EJB Servlets JSP JDBC Applet JSF JVM Swing/AWT/SWT Tomcat Mybatis Struts/Struts2 Hibernate Eureka Ribbon Hystrix Zuul Feign Dubbo
Scala Kotlin
Ruby Ruby on Rails/Redmine
Groovy
Swift/Objective-C
PHP Magento/Drupal/joomla/Typecho/laravel
Python Django/Tornado/flask/CMS/Mezzanine/Scrapy SQLAlchemy
C++ STL boost cocos2d Lua rust Boost.Asio libevent libev libuv libco Boost.Beast
C glibc/coreutils/Webbench/Tinyhttpd/cJSON/CMockery/Libev bzip2 OpenSSL/SSH libevent
Linux shell makefile/cmake signal network/NetLink 进程/线程 线程池 安全 IPC(共享内存/管道/FIFO/消息队列/unix域套接字/mmap/dbus) 同步(信号量/互斥锁/读写锁/条件变量/自旋锁) socket(tcp/udp) 文件io(fopen/fclose/fread/fwrite/open/create/close/lseek/read/write/stat/fstat) io多路复用(epoll/select/poll) fcntl ioctl dup/dup2 sendfile
文件系统 VFS/OpenZFS/XFS/EXT2/EXT3/EXT4/NFS/CIFS/FUSE Ramdisk/tmpfs/ramfs UnionFS/AUFS/Overlay2/DeviceMapper/Btrfs SMB
数据库 MySQL/MariaDB/PostgreSQL/sqlite/TiDB Redis MongoDB
Prometheus Grafana InfluxDB OpenTSDB pushgateway alertmanager
ElasticSearch Logstash Kibana FileBeat Flume Fluentd loki
Etcd/Consul/Nomad/Zookeeper
Kafka/RabbitMQ/RocketMQ/NSQ/MQTT/ActiveMQ/ZeroMQ/CMQ/Pulsar strimzi-kafka-operator 
Ceph/GlusterFS/MinIO/ChubaoFS/SeaweedFS/FastDFS/MogileFS/S3/MooseFS/Lustre/GFS/Juicefs/alluxio
Graphql Promethues CockroachDB rqlite dqlite yugabyte vitess Cassandra TiKV FoundationDB GreenPlum ClickHouse Neo4j Dgraph Cayley nebula rook OpenEBS Longhorn LevelDB goleveldb RocksDB Pebble BadgerDB BoltDB BuntDB nutsdb CouchDB Couchbase OceanBase BigTable pika ssdb tidis ramsql memsql summitdb Genji go-memdb
Nginx Envoy MOSN KrakenD lura ingress-nginx Ambassador Gloo HAProxy Ingress Kong Traefik Ingress Controller LVS(NAT/DR/TUN) IPVS Keepalived
网络 IP TCP UDP HTTP HTTPS HTTP/2 HTTP/3 QUIC socks5 Socket JSON/Protobuf RESTful DNS session oauth2 casbin netlink netfilter websocket VPP DHCP 路由器 交换机 iptables LAN VLAN VxLAN IPsec SMTP FTP TFTP Telnet SNMP IGMP 广播 多播 组播 RIP CIDR ICMP ARP RARP BGP OSPF NAT VPN SDN NFV Overlay Openvswitch OpenDaylight OpenFlow DPDK SPDK NUMA RDMA frp P2P
容器 Docker/Docker Compose/Docker Swarm/Mesos
容器网络 Flannel Calico Canal Cilium Weave Kube-OVN CoreDNS NATS cni eBPF
容器运行时 cri-o kata container containerd rkt frakti
容器镜像 Makisu Kaniko Img Podman Buildah
容器监控 Thanos/VictoriaMetrics/Cortex/Open-Falcon/OpenMetrics/cAdvisor
Kubernetes Rancher/Terraform/Kops/kind/sealos/minikube/k3s/microk8s Helm/Kubernetes Dashboard/Harbor/Portainer KubeSphere/KubeVirt/KubeEdge/Kubeflow/KubeOperator/Kubeless Volcano Fargate CloudEvents Notary TUF falco Cloudtask Chaos Mesh CRD OpenYurt journalctl -u kubelet KUDO Keptn KEDA in-toto Flux Doris Fluid Karmada OpenPitrix
服务网格 Istio/linkerd2/Kuma
Serverless/Fission/Knative/faas Firecracker Dapr 边缘计算 PaaS
微服务 Jaeger Kiali OpenTracing SkyWalking OpenTelemetry Dragonfly Open Policy Agent Zipkin
分布式 架构 高并发 高可用 主从 分布式一致性 分布式事务 2PC 3PC TCC Paxos ZAB Raft CAP ACID CAP BASE理论 Gossip 共识算法:POW/POS/DPOS/PBFT 秒杀(库存,超卖现象,redis乐观锁watch,redis悲观锁 阻塞式(超时) 非阻塞式 setnx expire,mysql乐观锁version,mysql悲观锁select for update用到索引)
算法 字符串:KMP/BM/Rabin-Karp/Sunday 排序算法:冒泡排序/选择排序/插入排序/希尔排序/快速排序/堆排序/归并排序/桶排序/基数排序/计数排序 压缩算法:霍夫曼压缩 加密算法:aes/rsa/ecc hash算法:crc32/md5/sha256 正则算法 图:DAG有向无环图/无向图/有向图/最小生成树/最短路径/广度优先搜索/深度优先搜索/拓扑排序 树:AVL树/红黑树/B树/B+树/B*树/斐波那契堆/二项树/二项队列/哈夫曼树/Trie树/R-tree/splay树/AA树 算法方法:动态规划/贪心算法/回溯法/分治算法/分支限界算法/摊还分析/NP完全性/子集和问题/旅行商问题/顶点覆盖问题/随机森林 其它:线段树/树状数组/并查集/跳跃表 倒排索引 LRU 布隆过滤器
运维 CI/CD Drone Jenkins Argo Argo CD Tekton DevOps Ansible Nagios Zabbix
浏览器内核 Chrome
音视频/流媒体 直播 FFmpeg webrtc Dolby DTS H.264 H.265 RTSP RTMP RTP RTCP VOIP SIP FLV MP4 HLV HLS WebRTC MPEG-4 AAC MP3
推荐系统
搜索引擎
大数据 Hadoop/HDFS/MapReduce/Storm/HBase/Hive/Flink/Spark bigquery Kylin
人工智能 机器学习/深度学习 人脸识别 OpenCV OpenGL Openvx/Tiovx WebGL/Three.js GLSL Vulkan 数据挖掘 TensorFlow/PyTorch Numpy Pandas Matplotlib Caffe Keras Scikit-learn Theano MXNet
机器人 ROS/rviz SLAM
自动驾驶
物联网/智能家居
3D deepmind
云计算 OpenStack CDN KVM QEMU SLB XEN libvirt
区块链 Bitcoin IPFS web3
AR/VR
GPU/CUDA
嵌入式 I2C/SPI/UART OTA
网络安全 web安全 密码学
磁盘 IDE SATA mSATA M.2 SCSI PCIe 机械硬盘 SSD AHCI NVMe iSCSI SAN NAS RAID

机器人:
ROS/ROS2
地图/导航
人工智能 LLM/RAG/TTS 向量数据库
视频采集
opengl/opencv
libav/libopus/libsrtp
QT WxWidget
QNX
